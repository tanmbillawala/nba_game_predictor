{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbd09ee-9206-4948-9ae6-e42e7d20976a",
   "metadata": {},
   "source": [
    "# NBA Game Predictor\n",
    "### CMPE 257 Project\n",
    "Authors: Kaushika Uppu, Miranda Billawala, Yun Ei Hlaing, Iris Cheung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f5cbd-6516-49cf-9271-94878f5f9d0c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030921a-827d-4a1f-af9b-104e618da8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28abb9c-228a-49bb-9721-215d0f183617",
   "metadata": {},
   "source": [
    "## NBA Game Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2dae76-eb39-4b8e-b8c2-9c1cc8d16cca",
   "metadata": {},
   "source": [
    "First, we load in all of the NBA game data from the CSV file. Exact code for gathering data is in a separate file and use the nba_api file. Only games from the 1985-1986 season and afterward are loaded in as the seasons before that are missing a very significant portion of the game statistics' data. We also want to be able to map from team id to abbreviation and back easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f17e2e-851c-444d-bdb4-a1b63b594be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats_cleaned = pd.read_csv('all_stats_cleaned.csv')\n",
    "all_stats_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd29527d-1036-4422-b002-364145da7151",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07c67a-bf0d-4553-a46e-d05ffba3f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to datetime object\n",
    "all_stats_cleaned['GAME_DATE'] = pd.to_datetime(all_stats_cleaned['GAME_DATE'], format='ISO8601')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfbde50-7bdd-478c-b816-96eb9d8beeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_id_to_abb = {} # dictionary to convert from team_id to team_abbreviation\n",
    "team_abb_to_id = {} # dictionary to convert from team_abbreviation to team_id\n",
    "\n",
    "teams = (all_stats_cleaned[['TEAM_ID', 'TEAM_ABBREVIATION']]).drop_duplicates()\n",
    "\n",
    "for index, row in teams.iterrows() :\n",
    "    if row['TEAM_ID'] not in team_id_to_abb.keys():\n",
    "        team_id_to_abb[row['TEAM_ID']] = []\n",
    "    team_id_to_abb[row['TEAM_ID']].append(row['TEAM_ABBREVIATION'])\n",
    "    team_abb_to_id[row['TEAM_ABBREVIATION']] = row['TEAM_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f8db0b-eb67-41f9-8287-676aeed18b2a",
   "metadata": {},
   "source": [
    "### Merging Home and Away Team Stats Into One Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c3044-4f7f-4516-8850-32da043a2f56",
   "metadata": {},
   "source": [
    "Currently, each game is represented by two separate rows in the dataset - one for the home team and one for the away team. To make the data more clear, we decided to combine the two rows into a single row with statistics for both teams. Since predicting with our model will pass one set order of team one and team two (i.e. Lakers as Team One, Warriors as Team Two), we want to make sure that the model realizes games with the Lakers as Team Two and Warriors as Team One are more similar than may appear by the data. To do this, we will duplicate the rows and flip the teams. Then, we will have each game listed twice with the teams flipped. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f167431-5cca-4d38-befc-a7e832eaebdc",
   "metadata": {},
   "source": [
    "Firstly, we split the dataset into two : home games and away games. Then, we performed a join on these two datasets, matching each home team with its corresponding opponent based on the same dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a9b9a-9667-4f37-be8c-27b1c74ef6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = all_stats_cleaned[all_stats_cleaned.HOME == 1]\n",
    "away = all_stats_cleaned[all_stats_cleaned.HOME == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8f695-c8b8-423d-b2f1-e6273b6e3284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_stats_home = pd.merge(home, away, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "combined_stats_away = pd.merge(away, home, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "\n",
    "combined_stats = pd.concat([combined_stats_home, combined_stats_away], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f448b5f0-f44c-4957-945d-f57bf5fd5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cde485-a219-4de4-923f-3815f6bbdb2d",
   "metadata": {},
   "source": [
    "Comparing the number of rows in the combined dataset to the original shows that the dataset row have been reduced by half, as each game is now represented by a single row instead of two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6eadb-8c9e-4edd-bba7-267512d7ee49",
   "metadata": {},
   "source": [
    "After merging the rows, there are some columns that appear twice or are now unneccessary to the dataset. These columns include `MIN_ONE`/`MIN_TWO` (length of game in minutes), `SEASON_YEAR_ONE`/`SEASON_YEAR_TWO`, `OPPONENT_ONE` and `OPPONENT_TWO`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f79796-bfd6-4991-8b7e-d835e758d8ee",
   "metadata": {},
   "source": [
    "We first checked if the `MIN_ONE` and `MIN_TWO` for each row has the same values. As seen below, there are 24 games where the minutes differed slightly. However, since the difference did not seem to be significant, we decided to retain one column and rename it `MIN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d683d2-7e36-4979-9e74-54f7457ea220",
   "metadata": {},
   "outputs": [],
   "source": [
    "(combined_stats['MIN_ONE'] != combined_stats['MIN_TWO']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e20896-7388-4ad1-ae28-4557f980c77c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_stats[combined_stats['MIN_ONE'] != combined_stats['MIN_TWO']][['MIN_ONE','MIN_TWO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1749d449-34c6-4964-af4e-9113a32a9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats = combined_stats.drop(columns = ['MIN_TWO', 'OPPONENT_ONE', 'OPPONENT_TWO', 'SEASON_YEAR_ONE'])\n",
    "combined_stats.rename(columns={'MIN_ONE': 'MIN', 'SEASON_YEAR_TWO': 'SEASON_YEAR'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89436d9-ca4e-49aa-b927-437d58bb4459",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d0f7c-13b5-46e4-b97a-6cde4b4585b5",
   "metadata": {},
   "source": [
    "Features to add : \n",
    "1) Win streak\n",
    "2) Win percentage\n",
    "3) ELO Scores\n",
    "4) EFG%\n",
    "5) TS%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a20f7-6604-4c09-9106-e24b5e23849a",
   "metadata": {},
   "source": [
    "### Win Streak and Win Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54849da8-424f-4e25-aaf5-d9ff3ccc30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_win_streak_and_percentage(df, combined=False):\n",
    "    \"\"\"\n",
    "    Input: Dataframe with team one and team two data for each game and boolean to check if dataframe is combined with both team data\n",
    "    Output: New dataframe with added win streak and win percentage for both teams\n",
    "    \"\"\"\n",
    "    team_date_stats = all_stats_cleaned[['TEAM_ID', 'GAME_DATE', 'WIN']].sort_values(by=['TEAM_ID', 'GAME_DATE']).reset_index(drop=True)\n",
    "    team_date_stats['WIN_STREAK'] = 0\n",
    "    team_date_stats['WIN_PERCENTAGE'] = 0.0\n",
    "    \n",
    "    for team_id, group in team_date_stats.groupby('TEAM_ID'):\n",
    "        streak = 0\n",
    "        wins = 0\n",
    "        total_games = 0\n",
    "        indices = group.index\n",
    "    \n",
    "        for i in range(len(indices)):\n",
    "            idx = indices[i]\n",
    "    \n",
    "            # WIN STREAK\n",
    "            team_date_stats.at[idx, 'WIN_STREAK'] = streak\n",
    "    \n",
    "            if team_date_stats.at[idx, 'WIN'] == 1:\n",
    "                streak += 1\n",
    "            else: \n",
    "                streak = 0\n",
    "    \n",
    "            # WIN PERCENTAGE\n",
    "            if total_games == 0:\n",
    "                team_date_stats.at[idx, 'WIN_PERCENTAGE'] = 0.0\n",
    "            else: \n",
    "                team_date_stats.at[idx, 'WIN_PERCENTAGE'] = wins / total_games\n",
    "    \n",
    "            total_games += 1\n",
    "            if team_date_stats.at[idx, 'WIN'] == 1:\n",
    "                wins += 1\n",
    "\n",
    "    if combined:\n",
    "    # Join Win streak and Win percentage of team one and team two into the merged table\n",
    "        team_date_stats.drop('WIN', axis=1, inplace=True)\n",
    "        df = pd.merge(df, team_date_stats,\n",
    "                              how='left', \n",
    "                              left_on = ['TEAM_ID_ONE', 'GAME_DATE'],\n",
    "                              right_on=['TEAM_ID', 'GAME_DATE'])\n",
    "        df.drop('TEAM_ID', axis=1, inplace=True)\n",
    "        df.rename(columns = {'WIN_STREAK': 'WIN_STREAK_ONE',\n",
    "                                     'WIN_PERCENTAGE': 'WIN_PERCENTAGE_ONE'}, inplace=True)\n",
    "        df = pd.merge(df, team_date_stats,\n",
    "                              how='left', \n",
    "                              left_on = ['TEAM_ID_TWO', 'GAME_DATE'],\n",
    "                              right_on=['TEAM_ID', 'GAME_DATE'])\n",
    "        df.drop('TEAM_ID', axis=1, inplace=True)\n",
    "        df.rename(columns = {'WIN_STREAK': 'WIN_STREAK_TWO',\n",
    "                                     'WIN_PERCENTAGE': 'WIN_PERCENTAGE_TWO'}, inplace=True)\n",
    "    else:\n",
    "        # Join Win streak and Win percentage into the dataframe\n",
    "        team_date_stats.drop('WIN', axis=1, inplace=True)\n",
    "        df = pd.merge(df, team_date_stats,\n",
    "                              how='left', \n",
    "                              on = ['TEAM_ID', 'GAME_DATE'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e014a30-619f-4b87-b757-e444d91b5a9e",
   "metadata": {},
   "source": [
    "### ELO Score Before Current Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835ead9-c09c-4961-9e78-35c7213cb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_opponent_points(df):\n",
    "    df_opp = df[['TEAM_ABBREVIATION', 'GAME_DATE', 'PTS', 'TEAM_ID']].copy()\n",
    "    merged_df = pd.merge(df, df_opp, \n",
    "                         how='left',\n",
    "                          left_on=['GAME_DATE', 'OPPONENT'],\n",
    "                            right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('', '_OPPONENT'))\n",
    "    merged_df.drop(columns=['TEAM_ABBREVIATION_OPPONENT'], inplace=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865af94b-e088-4e1b-bf03-a0029008eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elo_score(df, combined=False):\n",
    "    \"\"\"\n",
    "    Input: Dataframe with team one and team two data for each game and boolean to check if dataframe is combined with both team data\n",
    "    Output: New dataframe with elo scores for both teams added \n",
    "    \"\"\"\n",
    "    if combined:\n",
    "        df['GAME_ID'] = df.apply(\n",
    "        lambda row: '_'.join(sorted([str(row['TEAM_ID_ONE']), str(row['TEAM_ID_TWO'])]) + [str(row['GAME_DATE'])]),\n",
    "        axis=1\n",
    "    )\n",
    "        df['ELO_ONE'] = np.nan\n",
    "        df['ELO_TWO'] = np.nan\n",
    "    else:\n",
    "        df = merge_opponent_points(df)\n",
    "        df['ELO'] = np.nan\n",
    "        df['GAME_ID'] = df.apply(\n",
    "        lambda row: '_'.join(sorted([str(row['TEAM_ID']), str(row['TEAM_ID_OPPONENT'])]) + [str(row['GAME_DATE'])]),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    team_elos = {} # to use for checking if a team has appeared and track team last elo scores\n",
    "    team_last_season = {} # to track last seasons of teams\n",
    "    processed_games = set() # to track game id - handle duplicate game columns\n",
    "    elo_map = {} # for faster computation\n",
    "    df = df.sort_values(by='GAME_DATE').reset_index(drop=True)\n",
    "    \n",
    "    for i,row in df.iterrows():\n",
    "        season = row['SEASON_YEAR']\n",
    "        game_id = row['GAME_ID']\n",
    "\n",
    "        if game_id in processed_games:\n",
    "            continue\n",
    "        processed_games.add(game_id)\n",
    "\n",
    "        if combined:\n",
    "            team_one, team_two = row['TEAM_ID_ONE'], row['TEAM_ID_TWO']\n",
    "            points_one, points_two = row['PTS_ONE'], row['PTS_TWO']\n",
    "            home_one = row['HOME_ONE']\n",
    "        \n",
    "            # Season adjustment formula for ELO : New Season ELO = 0.75 * Last Season ELO + 0.25 * Mean ELO, Mean ELO = 1505\n",
    "            for team in [team_one, team_two]:\n",
    "                # check if team has not appeared yet in the dataset\n",
    "                if team not in team_elos:\n",
    "                    team_elos[team] = 1505 \n",
    "                    team_last_season[team] = season\n",
    "                # check for new season, if yes, apply season adjustment\n",
    "                elif team_last_season[team] != season:\n",
    "                    team_elos[team] = 0.75 * team_elos[team] + 0.25 * 1505\n",
    "                    team_last_season[team] = season\n",
    "        \n",
    "            # elo scores before game\n",
    "            elo_one = team_elos[team_one]\n",
    "            elo_two = team_elos[team_two]\n",
    "        \n",
    "            # Add 100 score to home team\n",
    "            if home_one == 1:\n",
    "                elo_one_after_home_adv = elo_one + 100 \n",
    "                elo_two_after_home_adv = elo_two\n",
    "            else:\n",
    "                elo_one_after_home_adv = elo_one \n",
    "                elo_two_after_home_adv = elo_two + 100\n",
    "        \n",
    "            # Expected score of game formula : exp = 1/ (1+10^((ELO two after home advantage - ELO one after home advantage) / 400))\n",
    "            exp = 1/ (1+10**((elo_two_after_home_adv - elo_one_after_home_adv) / 400))\n",
    "        \n",
    "            actual = 1 if points_one > points_two else 0\n",
    "            margin_of_victory = abs(points_one - points_two)\n",
    "        \n",
    "            # Margin of Victory Multiplier formula : ((MOV + 3) ** 0.8) / (7.5 + 0.006 * (Elo team one - Elo team two))\n",
    "            MOVM = ((margin_of_victory + 3) ** 0.8) / (7.5 + 0.006 * (elo_one - elo_two))\n",
    "        \n",
    "            # change in ELO: K * MOVM * (actual - exp), k -> attenuation factor -> higher means elo score adjusts quickly to changes in strength of team\n",
    "            K = 20 # 20 is optimal for nba \n",
    "            change = K * MOVM * (actual - exp)\n",
    "    \n",
    "            # Update data for ELO ratings\n",
    "            team_elos[team_one] += change\n",
    "            team_elos[team_two] -= change\n",
    "        \n",
    "            # store elo score for game id at the table\n",
    "            # df.at[i, 'ELO_ONE'] = elo_one\n",
    "            # df.at[i, 'ELO_TWO'] = elo_two\n",
    "            # df.loc[(df['GAME_ID'] == game_id) & df['TEAM_ID_ONE'] == team_two, 'ELO_ONE'] = elo_two\n",
    "            # df.loc[(df['GAME_ID'] == game_id) & df['TEAM_ID_TWO'] == team_one, 'ELO_TWO'] = elo_one\n",
    "\n",
    "            # store elo scores in dictionary\n",
    "            elo_map[(game_id, team_one, team_two)] = elo_one\n",
    "            elo_map[(game_id, team_two, team_one)] = elo_two\n",
    "     \n",
    "        else:\n",
    "            team, team_opp = row['TEAM_ID'], row['TEAM_ID_OPPONENT']\n",
    "            points_team, points_opp = row['PTS'], row['PTS_OPPONENT']\n",
    "            home = row['HOME']\n",
    "        \n",
    "            # Season adjustment formula for ELO : New Season ELO = 0.75 * Last Season ELO + 0.25 * Mean ELO, Mean ELO = 1505\n",
    "            for t in [team, team_opp]:\n",
    "                # check if team has not appeared yet in the dataset\n",
    "                if t not in team_elos:\n",
    "                    team_elos[t] = 1505 \n",
    "                    team_last_season[t] = season\n",
    "                # check for new season, if yes, apply season adjustment\n",
    "                elif team_last_season[t] != season:\n",
    "                    team_elos[t] = 0.75 * team_elos[t] + 0.25 * 1505\n",
    "                    team_last_season[t] = season\n",
    "        \n",
    "            # elo scores before game\n",
    "            elo_team = team_elos[team]\n",
    "            elo_opponent = team_elos[team_opp]\n",
    "        \n",
    "            # Add 100 score to home team\n",
    "            if home == 1:\n",
    "                elo_team_home = elo_team + 100 \n",
    "                elo_opp_home = elo_opponent\n",
    "            else:\n",
    "                elo_team_home = elo_team \n",
    "                elo_opp_home = elo_opponent + 100\n",
    "        \n",
    "            # Expected score of game formula : exp = 1/ (1+10^((ELO two after home advantage - ELO one after home advantage) / 400))\n",
    "            exp = 1/ (1+10**((elo_opp_home - elo_team_home) / 400))\n",
    "        \n",
    "            actual = 1 if points_team > points_opp else 0\n",
    "            margin_of_victory = abs(points_team - points_opp)\n",
    "        \n",
    "            # Margin of Victory Multiplier formula : ((MOV + 3) ** 0.8) / (7.5 + 0.006 * (Elo team one - Elo team two))\n",
    "            MOVM = ((margin_of_victory + 3) ** 0.8) / (7.5 + 0.006 * (elo_team - elo_opponent))\n",
    "        \n",
    "            # change in ELO: K * MOVM * (actual - exp), k -> attenuation factor -> higher means elo score adjusts quickly to changes in strength of team\n",
    "            K = 20 # 20 is optimal for nba \n",
    "            change = K * MOVM * (actual - exp)\n",
    "\n",
    "            # Update data for ELO ratings\n",
    "            team_elos[team] += change\n",
    "            team_elos[team_opp] -= change\n",
    "        \n",
    "            # store elo score for both row of game at the table\n",
    "            # df.at[i, 'ELO'] = elo_team\n",
    "            # df.loc[(df['GAME_ID'] == game_id) & df['TEAM_ID'] == team_opp, 'ELO'] = elo_opponent\n",
    "            elo_map[(game_id, team)] = elo_team\n",
    "            elo_map[(game_id, team_opp)] = elo_opponent\n",
    "\n",
    "    # add data from elo dictionary into dataframe\n",
    "    if not combined:\n",
    "        df['ELO'] = df.apply(lambda x: elo_map.get((x['GAME_ID'], x['TEAM_ID']), np.nan), axis=1)\n",
    "        df.drop(columns=['PTS_OPPONENT', 'TEAM_ID_OPPONENT'], axis=1, inplace=True)\n",
    "    else: \n",
    "        df['ELO_ONE'] = df.apply(lambda x: elo_map.get((x['GAME_ID'], x['TEAM_ID_ONE'], x['TEAM_ID_TWO']), np.nan), axis=1)\n",
    "        df['ELO_TWO'] = df.apply(lambda x: elo_map.get((x['GAME_ID'], x['TEAM_ID_TWO'], x['TEAM_ID_ONE']), np.nan), axis=1)\n",
    "    df.drop(columns=['GAME_ID'], axis=1, inplace=True)\n",
    "    \n",
    "            \n",
    "    return df                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79ba04-8bdd-4a9e-9ee7-3b08aca53fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for single team data\n",
    "test_1 = add_win_streak_and_percentage(all_stats_cleaned)\n",
    "test_1 = add_elo_score(test_1)\n",
    "print(test_1.columns)\n",
    "test_1[test_1['TEAM_ID'] == 14].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d55a3-2551-4a4d-9951-4fb1f40aa6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for combined team and opponent data\n",
    "test_2 = add_win_streak_and_percentage(combined_stats, True)\n",
    "test_2 = add_elo_score(test_2, True)\n",
    "test_2[test_2['TEAM_ID_ONE'] == 14].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d137f-3bc0-43e8-879b-c9bc2d9f6c2e",
   "metadata": {},
   "source": [
    "### Effective Field Goal Percentage and True Shooting Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c4746-bd69-4cb4-94fe-e60c5305b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shooting_percentages(df, combined=False):\n",
    "    if combined: \n",
    "        df['EFG%_ONE'] = (df['FGM_ONE'] + 1.5 * df['FG3M_ONE']) / df['FGA_ONE']\n",
    "        df['EFG%_TWO'] = (df['FGM_TWO'] + 1.5 * df['FG3M_TWO']) / df['FGA_TWO']\n",
    "        df['TS%_ONE'] = df['PTS_ONE'] / (2 * (df['FGA_ONE'] + 0.44 * df['FTA_ONE']))\n",
    "        df['TS%_TWO'] = df['PTS_TWO'] / (2 * (df['FGA_TWO'] + 0.44 * df['FTA_TWO']))\n",
    "    else:\n",
    "        df['EFG%'] = (df['FGM'] + 1.5 * df['FG3M']) / df['FGA']\n",
    "        df['TS%'] = df['PTS'] / (2 * (df['FGA'] + 0.44 * df['FTA']))\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00c976-ab01-41a6-b666-66e189e26c6b",
   "metadata": {},
   "source": [
    "### Point Differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6763f10a-955f-43d1-b952-33eaecf5f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_point_differential(df, window = 5, combined=False):\n",
    "        #  add opponent points to all_stats_cleaned table\n",
    "    #for team_id in all_stats_cleaned['TEAM_ID'].unique() :\n",
    "    #    team_data = all_stats_cleaned[all_stats_cleaned['TEAM_ID'] == team_id].sort_values(by='GAME_DATE')\n",
    "    #    for col in cols :\n",
    "    #        shift = team_data[col].shift(1)\n",
    "    #        team_data[col] = shift.rolling(window = n).mean()\n",
    "    #    if result is None :\n",
    "    #        result = team_data\n",
    "    #    else :\n",
    "    #        result = pd.concat([result, team_data])\n",
    "    \n",
    "    \n",
    "    if combined:\n",
    "        df['PTS_DIFF_ONE'] = df['PTS_ONE'] - df['PTS_TWO']\n",
    "        df['PTS_DIFF_TWO'] = df['PTS_TWO'] - df['PTS_ONE']\n",
    "    else:\n",
    "        df = merge_opponent_points(df)\n",
    "        df['PTS_DIFF'] = df['PTS'] - df['PTS_OPPONENT']\n",
    "        df.drop(columns=['PTS_OPPONENT', 'TEAM_ID_OPPONENT'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f693e-e6da-44e5-8a60-28bf24d618d8",
   "metadata": {},
   "source": [
    "### Win for Last Matchup Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5764ba-ac0d-4209-9965-470f0ebd5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_win_last_game(df, combined=False):\n",
    "    if combined:\n",
    "        sorted_df = df.sort_values(by=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'])\n",
    "        sorted_df['WIN_LAST_ONE'] = sorted_df.groupby(['TEAM_ID_ONE', 'TEAM_ID_TWO'])['WIN_ONE'].shift(1)\n",
    "        sorted_df['WIN_LAST_TWO'] = sorted_df.groupby(['TEAM_ID_ONE', 'TEAM_ID_TWO'])['WIN_TWO'].shift(1)\n",
    "        df = df.merge(sorted_df[['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE', 'WIN_LAST_ONE', 'WIN_LAST_TWO']],\n",
    "                      on=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'],\n",
    "                      how = 'left')\n",
    "    else:\n",
    "        sorted_df = df.sort_values(by=['TEAM_ID', 'OPPONENT', 'GAME_DATE'])\n",
    "        sorted_df['WIN_LAST'] = sorted_df.groupby(['TEAM_ID', 'OPPONENT'])['WIN'].shift(1)\n",
    "        df = df.merge(sorted_df[['TEAM_ID', 'OPPONENT', 'GAME_DATE', 'WIN_LAST']],\n",
    "                      on=['TEAM_ID', 'OPPONENT', 'GAME_DATE'],\n",
    "                      how = 'left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2917da54-7a54-41ba-8c7a-fb56695c400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_4 = add_win_last_game(all_stats_cleaned)\n",
    "print(test_4.columns)\n",
    "test_4[(test_4['TEAM_ID'] == 14) & (test_4['OPPONENT'] == 'BOS')].sort_values(by='GAME_DATE').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7accc128-6ab8-428f-a434-f7132d710372",
   "metadata": {},
   "source": [
    "## Building Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc546d-dc67-4a39-bc03-15ac864d31b5",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "Since our data follows a time-series format, we are implementing a different method of testing as follows:\n",
    "1. Save the last 4 years of games as a test set.\n",
    "2. Choose a few days from each season, except the last four, for our validation set.\n",
    "3. Run a GridSearchCV for each day of validation games to find best parameters.\n",
    "4. Test the model with best parameters on the test set.\n",
    "\n",
    "We need to retrain the model for each different day we test because we input into the model the number of days since a game occurred as a way to convert the timestamp into a numerical variable that is understandable to the model. \n",
    "\n",
    "For validating and choosing proper parameters, we will test on three days from each season: beginning, after the trade-deadline (middle), and near playoffs. This way, we can see how the model handles different times of the season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a044cf0-6065-4397-99a9-0aeb1a798565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_set (first_season, last_season, n = 1) :\n",
    "    dates = []\n",
    "    for season in range(first_season, last_season) :\n",
    "        season_data = all_stats_cleaned[all_stats_cleaned['SEASON_YEAR'] == season]\n",
    "        start_date = season_data['GAME_DATE'].min()\n",
    "        end_date = season_data['GAME_DATE'].max()\n",
    "\n",
    "        # day around the beginning of the season\n",
    "        beg = season_data[season_data['GAME_DATE'].between(start_date, start_date + timedelta(weeks = 4))]\n",
    "\n",
    "        # day around trade deadline (after about 2/3 of the season)\n",
    "        delta = round((2/3)*(end_date-start_date).days)\n",
    "        approx_deadline = start_date + timedelta(days = delta)\n",
    "        mid = season_data[season_data['GAME_DATE'].between(approx_deadline, approx_deadline + timedelta(weeks = 4))]\n",
    "        \n",
    "        # day around the end of the season\n",
    "        end = season_data[season_data['GAME_DATE'].between(end_date - timedelta(weeks = 4), end_date)]\n",
    "\n",
    "        dates.extend(list(pd.concat([beg.sample(n)['GAME_DATE'], mid.sample(n)['GAME_DATE'], end.sample(n)['GAME_DATE']])))\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2ee46-f9f8-4d26-9e53-5d7996f97182",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_season = all_stats_cleaned['SEASON_YEAR'].min() + 1\n",
    "last_season = all_stats_cleaned['SEASON_YEAR'].max() - 4\n",
    "val_set = get_val_set(first_season, last_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f5829c-b7b8-4af1-aa40-18ce24556674",
   "metadata": {},
   "source": [
    "We attempt two different methods for predicting game statistics. As a baseline, we use a regular rolling window. Then, we implement a model which predicts a team's statistics. We use both of these values to test an outcome predictor model after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e48fa-aa5b-46c1-8dd5-0ad3546a43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added shooting percentage\n",
    "all_stats_cleaned = add_shooting_percentages(all_stats_cleaned)\n",
    "# added win streak and win percentage\n",
    "all_stats_cleaned = add_win_streak_and_percentage(all_stats_cleaned)\n",
    "# added ELO score\n",
    "all_stats_cleaned = add_elo_score(all_stats_cleaned)\n",
    "# added point differential\n",
    "# all_stats_cleaned = add_point_differential(all_stats_cleaned)\n",
    "# added win for last game\n",
    "all_stats_cleaned = add_win_last_game(all_stats_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59bdf1e-4808-4599-a5d0-7f9f2155fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(n, cols) :\n",
    "    pred = None\n",
    "    for team_id in all_stats_cleaned['TEAM_ID'].unique() :\n",
    "        team_data = all_stats_cleaned[all_stats_cleaned['TEAM_ID'] == team_id].sort_values(by='GAME_DATE')\n",
    "        for col in cols :\n",
    "            shift = team_data[col].shift(1)\n",
    "            team_data[col] = shift.rolling(window = n).mean()\n",
    "        if pred is None :\n",
    "            pred = team_data\n",
    "        else :\n",
    "            pred = pd.concat([pred, team_data])\n",
    "    pred = pred.dropna(axis = 0)\n",
    "\n",
    "    home = pred[pred['HOME'] == 1]\n",
    "    away = pred[pred['HOME'] == 0]\n",
    "\n",
    "    combined_pred_stats_home = pd.merge(home, away, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "    combined_pred_stats_away = pd.merge(away, home, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "\n",
    "    combined_pred_stats = pd.concat([combined_pred_stats_home, combined_pred_stats_away], ignore_index = True)\n",
    "    combined_pred_stats.rename(columns={'MIN_ONE': 'MIN', 'SEASON_YEAR_TWO': 'SEASON_YEAR'}, inplace=True)\n",
    "    combined_pred_stats = combined_pred_stats.drop(columns = ['MIN_TWO', 'OPPONENT_ONE', 'OPPONENT_TWO', 'SEASON_YEAR_ONE', \n",
    "                                                              'TEAM_ABBREVIATION_ONE', 'TEAM_NAME_ONE', 'MIN', 'FGM_ONE', \n",
    "                                                              'FGA_ONE', 'FG3M_ONE', 'FG3A_ONE', 'FTM_ONE', 'FTA_ONE', 'PTS_ONE', \n",
    "                                                              'PLUS_MINUS_ONE', 'TEAM_ABBREVIATION_TWO', 'TEAM_NAME_TWO', 'HOME_TWO',\n",
    "                                                              'WIN_TWO', 'FGM_TWO', 'FGA_TWO', 'FG3M_TWO', 'FG3A_TWO', 'FTM_TWO', \n",
    "                                                              'FTA_TWO', 'PTS_TWO', 'PLUS_MINUS_TWO'])\n",
    "\n",
    "    return combined_pred_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57f63bd-ac90-4416-9ce4-116cc772b48e",
   "metadata": {},
   "source": [
    "### Rolling Window Statistics (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593ec6f-a148-48f7-b768-f13759e6949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['FG_PCT', 'FG3_PCT', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'EFG%', 'TS%']\n",
    "combined_pred_stats = rolling_window(5, cols)\n",
    "combined_pred_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deef007-5859-40a0-8fb3-a6b6b093dc1f",
   "metadata": {},
   "source": [
    "### Predicting Using ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f5b240-0232-4634-bde4-e9e16bbe02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get actual stats\n",
    "combined_stats_training = add_shooting_percentages(combined_stats, combined = True)\n",
    "combined_stats_training = combined_stats[['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE', 'FG_PCT_ONE',\n",
    "                                          'FG3_PCT_ONE','FT_PCT_ONE', 'OREB_ONE', 'DREB_ONE', 'REB_ONE',\n",
    "                                          'AST_ONE', 'STL_ONE', 'BLK_ONE', 'TOV_ONE', 'PF_ONE', 'EFG%_ONE', 'TS%_ONE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c29ad-1005-4391-abd8-6d8f512f19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rolling window stats\n",
    "cols = ['FG_PCT', 'FG3_PCT', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'EFG%', 'TS%']\n",
    "rolling_stats_training = rolling_window(5, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856efbbe-221c-4fc8-babf-7607c3039029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine \n",
    "model_training_set = pd.merge(rolling_stats_training, combined_stats_training, \n",
    "                          left_on=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'], \n",
    "                          right_on=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'],\n",
    "                          suffixes=('_PRED', '_ACT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb949716-047f-43d1-b30a-ee6484b2e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_cols = ['FG_PCT_ONE_ACT', 'FG3_PCT_ONE_ACT', 'FT_PCT_ONE_ACT', 'OREB_ONE_ACT', 'DREB_ONE_ACT', \n",
    "                'REB_ONE_ACT','AST_ONE_ACT', 'STL_ONE_ACT', 'BLK_ONE_ACT', 'TOV_ONE_ACT', \n",
    "                'PF_ONE_ACT', 'EFG%_ONE_ACT', 'TS%_ONE_ACT'] \n",
    "\n",
    "def train_model(df, team_id, game_date, model_params = None):\n",
    "    \"\"\"\n",
    "    Trains a model to predict team stats for a given game using past rolling averages of both teams.\n",
    "    Features: past performance of TEAM_ONE and TEAM_TWO.\n",
    "    Targets: actual stats of TEAM_ONE in the current game.\n",
    "    \"\"\"\n",
    "    df = df[(df['GAME_DATE'] < game_date) & (df['TEAM_ID_ONE'] == team_id)]\n",
    "    X = df.drop(columns = act_cols+['GAME_DATE'])\n",
    "\n",
    "    # fitting a XGBoost model for each stat\n",
    "    models = {}\n",
    "    for col in act_cols:\n",
    "        y = df[col]\n",
    "        if model_params is None :\n",
    "            model = XGBRegressor(n_estimators = 100, random_state = 33)\n",
    "        else :\n",
    "            model = XGBRegressor(**model_params[col], random_state = 33)\n",
    "        model.fit(X, y)\n",
    "        models[col] = model\n",
    "\n",
    "    return models\n",
    "\n",
    "def predict_game_stats(df, team_id, game_date, model_params = None) :\n",
    "    \"\"\"\n",
    "    Predicts the statistics for given game.\n",
    "    \"\"\"\n",
    "    df = pd.get_dummies(df, columns=['TEAM_ID_TWO'], drop_first=True)\n",
    "    if model_params is None :\n",
    "        models = train_model(df, team_id, game_date)\n",
    "    else :\n",
    "        models = train_model(df, team_id, game_date, model_params)\n",
    "\n",
    "    pred = df[(df['GAME_DATE'] == game_date) & (df['TEAM_ID_ONE'] == team_id)].drop(columns = act_cols+['GAME_DATE'])\n",
    "    \n",
    "    prediction = {}\n",
    "    for stat, model in models.items():\n",
    "        prediction[stat] = model.predict(pred)[0]\n",
    "   \n",
    "    return prediction\n",
    "\n",
    "def evaluate_stats_model(df, test_set, model_params = None):\n",
    "    \"\"\"\n",
    "    Evaluates predicting stats model by testing on last `test_seasons` seasons using RMSE.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    for day in test_set :\n",
    "        print(\"Predicting...\", day)\n",
    "        games_on_day = df[df['GAME_DATE'] == day]\n",
    "        for index, row in games_on_day.iterrows() :\n",
    "            if model_params is None :\n",
    "                pred = predict_game_stats(df, row['TEAM_ID_ONE'], day)\n",
    "            else :\n",
    "                pred = predict_game_stats(df, row['TEAM_ID_ONE'], day, model_params)\n",
    "            pred = [pred[col] for col in act_cols]\n",
    "            act = [row[col] for col in act_cols]\n",
    "            predictions.append(pred)\n",
    "            actuals.append(act)\n",
    "\n",
    "    # evaluating model's predictions\n",
    "    y_true = np.array(actuals)\n",
    "    y_pred = np.array(predictions)\n",
    "    total_rmse = np.sqrt(mean_squared_error(y_true.flatten(), y_pred.flatten()))\n",
    "    return total_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426780d5-531f-4f00-9311-33a0376d8fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse = evaluate_stats_model(model_training_set, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc97e59-3df7-461a-ae5e-dbd999d9a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse # np.float64(3.7292723986015033)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c890aa-a66f-41aa-92f0-8bddb088e6a5",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "To perform hyperparameter tuning, we are going to look at only a small subset of the validation set since each game to be predicted requires fitting a number of different models. For computational efficiency, we are going to make the validation subset include only dates from 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590aca16-2129-4559-93fc-4d5a7894d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test_set = [d for d in val_set if d.year == 2018]\n",
    "param_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41069b5f-c3fd-4cc1-be67-962dbae294b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hyperparameter_tuning (df, params, test_set) :\n",
    "    index = 1\n",
    "    param_perf = None\n",
    "    for p in params :\n",
    "        print(f\"Iteration {index} / {len(params)}\")\n",
    "        predictions = None \n",
    "        actual = None\n",
    "        for day in test_set :\n",
    "            games_on_day = df[df['GAME_DATE'] == day]\n",
    "            for _, row in games_on_day.iterrows() :\n",
    "                model_params = {col : p for col in act_cols}\n",
    "                pred = pd.DataFrame([predict_game_stats(df, row['TEAM_ID_ONE'], day, model_params)])\n",
    "                act = pd.DataFrame([{col : row[col] for col in act_cols}])\n",
    "                predictions = pred if predictions is None else pd.concat([predictions, pred], ignore_index = True)\n",
    "                actual = act if predictions is None else pd.concat([actual, act], ignore_index = True)\n",
    "\n",
    "        scores = {'params': p}\n",
    "        for col in act_cols :\n",
    "            scores[col] = np.sqrt(mean_squared_error(predictions[col], actual[col]))\n",
    "        scores = pd.DataFrame([scores])\n",
    "        param_perf = scores if param_perf is None else pd.concat([param_perf, scores], ignore_index = True)\n",
    "        index += 1\n",
    "\n",
    "    best_params = {}\n",
    "    for col in act_cols :\n",
    "        best_params[col] = param_perf.loc[param_perf[col].idxmin(), 'params']\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a458b16-6bed-4605-aebf-d4c335f1bdb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 150],\n",
    "    \"eta\": [0.01, 0.05, 0.1], # learning_rate\n",
    "    \"max_depth\": [4, 6, 8], # maximum depth of a tree\n",
    "    \"subsample\": [0.5, 0.7, 1], # fraction of observation to be radnomly sampled for each tree\n",
    "    \"colsample_bytree\": [0.5, 0.7, 1], # fraction of columns to be random samples for each tree\n",
    "    }\n",
    "\n",
    "params = []\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for values in itertools.product(*param_grid.values()):\n",
    "    params.append(dict(zip(param_grid.keys(), values)))\n",
    "\n",
    "best_params = hyperparameter_tuning(model_training_set, params, param_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4cb0dc-2ca3-4be0-98f0-024ca48c534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in best_params.items():\n",
    "    print(k,v)\n",
    "\n",
    "#FG_PCT_ONE_ACT {'n_estimators': 50, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.7, 'colsample_bytree': 0.5}\n",
    "#FG3_PCT_ONE_ACT {'n_estimators': 50, 'eta': 0.1, 'max_depth': 6, 'subsample': 0.7, 'colsample_bytree': 1}\n",
    "#FT_PCT_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 4, 'subsample': 0.5, 'colsample_bytree': 0.5}\n",
    "#OREB_ONE_ACT {'n_estimators': 50, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.5}\n",
    "#DREB_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 4, 'subsample': 0.5, 'colsample_bytree': 1}\n",
    "#REB_ONE_ACT {'n_estimators': 150, 'eta': 0.05, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.7}\n",
    "#AST_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.5}\n",
    "#STL_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.5}\n",
    "#BLK_ONE_ACT {'n_estimators': 150, 'eta': 0.1, 'max_depth': 6, 'subsample': 0.7, 'colsample_bytree': 1}\n",
    "#TOV_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 6, 'subsample': 0.7, 'colsample_bytree': 1}\n",
    "#PF_ONE_ACT {'n_estimators': 150, 'eta': 0.05, 'max_depth': 4, 'subsample': 0.7, 'colsample_bytree': 1}\n",
    "#EFG%_ONE_ACT {'n_estimators': 50, 'eta': 0.05, 'max_depth': 8, 'subsample': 0.7, 'colsample_bytree': 1}\n",
    "#TS%_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 6, 'subsample': 1, 'colsample_bytree': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f31df-7462-4509-9527-f2e397ccd0a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse_tuned = evaluate_stats_model(model_training_set, val_set, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1701a792-28cb-498a-96b2-f3d210c6adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d48c5-dd66-4f51-873b-61df603d01e3",
   "metadata": {},
   "source": [
    "### Predict Training Set for Outcome Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819871b5-df51-4f5f-8c85-25a6675836cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_cols = ['TEAM_ID_ONE', 'SEASON_YEAR', 'HOME_ONE', 'WIN_ONE', 'ELO_ONE', 'WIN_STREAK_ONE', 'WIN_PERCENTAGE_ONE', 'WIN_LAST_ONE']\n",
    "def pred_training_set (df, first_season, last_season, model_params) :\n",
    "    all_predictions = None\n",
    "    days = all_stats_cleaned[all_stats_cleaned['SEASON_YEAR'].between(first_season, last_season)]['GAME_DATE'].unique()\n",
    "    rows = []\n",
    "    current_day = 1\n",
    "    total_days = len(days)\n",
    "    for d in days:\n",
    "        print(f\"Predicting Day {current_day} / {total_days} \")\n",
    "        games_on_day = df[df['GAME_DATE'] == d]\n",
    "        for _, row in games_on_day.iterrows() :\n",
    "            pred = predict_game_stats(df, row['TEAM_ID_ONE'], d, model_params)\n",
    "            pred['GAME_DATE'] = d\n",
    "            pred['OPP'] = row['TEAM_ID_TWO']\n",
    "            for s in static_cols :\n",
    "                pred[s] = row[s]\n",
    "            rows.append(pred)\n",
    "        current_day += 1\n",
    "            \n",
    "    all_predictions = pd.DataFrame(rows)\n",
    "    all_predictions.rename(columns=lambda col: col.replace('_ONE', ''), inplace=True)\n",
    "    all_predictions.rename(columns=lambda col: col.replace('_ACT', ''), inplace=True)\n",
    "\n",
    "    home = all_predictions[all_predictions.HOME == 1]\n",
    "    away = all_predictions[all_predictions.HOME == 0]\n",
    "\n",
    "    combined_pred_home = pd.merge(home, away, \n",
    "                          left_on=['GAME_DATE', 'OPP'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ID'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "    combined_pred_away = pd.merge(away, home, \n",
    "                          left_on=['GAME_DATE', 'OPP'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ID'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "\n",
    "    combined_pred = pd.concat([combined_pred_home, combined_pred_away], ignore_index = True)\n",
    "    combined_pred = combined_pred.drop(columns = ['OPP_ONE', 'OPP_TWO', 'HOME_TWO', 'WIN_TWO', 'SEASON_YEAR_TWO'])\n",
    "    combined_pred.rename(columns = {'SEASON_YEAR_ONE': 'SEASON_YEAR'}, inplace=True)\n",
    "\n",
    "    return combined_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165661b8-1f7a-460b-be29-614cf888c706",
   "metadata": {},
   "source": [
    "## Outcome Model\n",
    "Since it is computationally expensive to run the second model to predict all the values in the dataset, we will perform feature selection and hyperparameter tuning on the model trained on the basic rolling statistics. Then, we will predict on the test set with both types of models to see which performs better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f171fa-25f9-4805-9c4d-c8c93d2a576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_horizon = 5\n",
    "df_rolling = combined_pred_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff14a18-705e-4ac2-a905-2236e8193257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set (df, date, num_seasons) :\n",
    "    \"\"\"\n",
    "    Input: Date of games and number of seasons to include in dataset\n",
    "    Output: All rows from the last num_seasons and all games in the current season up till the given date\n",
    "    \"\"\"\n",
    "    # determine season of the game\n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "    \n",
    "    # get games for training\n",
    "    data = df[df['SEASON_YEAR'].between(season - num_seasons, season)].copy()\n",
    "    data['DAYS_SINCE_GAME'] = [(date-game_day).days for game_day in data['GAME_DATE']]\n",
    "    data = data[data['DAYS_SINCE_GAME'] > 0]\n",
    "\n",
    "    data = data.sort_values(by = 'DAYS_SINCE_GAME')\n",
    "\n",
    "    # split into X and y and only look at relevant columns\n",
    "    X = data.drop(columns = ['WIN_ONE', 'GAME_DATE'])\n",
    "    y = data['WIN_ONE']\n",
    "\n",
    "    return (X,y)\n",
    "\n",
    "def pred_by_date (df, model, date) :\n",
    "    \"\"\"\n",
    "    Predict the outcome of all games on the given date. \n",
    "    \"\"\"\n",
    "    n = time_horizon # how many years in the past for training\n",
    "    \n",
    "    # determine season of the game\n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "\n",
    "    # get data in relevant time frame\n",
    "    X, y = get_training_set(df, date, n)\n",
    "\n",
    "    #df = pd.DataFrame(columns=X.columns)\n",
    "\n",
    "    games_on_day = df[df['GAME_DATE'] == date].copy()\n",
    "    games_on_day['DAYS_SINCE_GAME'] = np.zeros(len(games_on_day))\n",
    "\n",
    "    test = games_on_day.drop(columns = ['WIN_ONE', 'GAME_DATE'])\n",
    "\n",
    "    model.fit(X,y)\n",
    "    pred = model.predict(test)\n",
    "    correct = np.sum(pred == games_on_day['WIN_ONE'])\n",
    "    games = len(pred)\n",
    "    return correct, games\n",
    "\n",
    "def test_model(df, model, dates) :\n",
    "    total_correct = total_games = 0\n",
    "\n",
    "    for d in dates:\n",
    "        correct, games = pred_by_date(df, model, d)\n",
    "\n",
    "        total_correct += correct\n",
    "        total_games += games\n",
    "    return total_correct, total_games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c3431-cb1a-47b1-99fb-17512003a020",
   "metadata": {},
   "source": [
    "### Initial Model With Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09fe6eb-edc7-4a39-be13-7273f0d10de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective='binary:logistic', base_score = 0.5, random_state = 33)\n",
    "correct,games = test_model(df_rolling, model, val_set)\n",
    "correct / games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8aebd-1a13-4d39-a7e1-503eec967d90",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609c627-f25c-4a53-bcc4-8e51b475b336",
   "metadata": {},
   "source": [
    "The average feature importance scores is calculated for the three games for each season using XG Boost built-in feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce81c4-0431-49bb-af42-1e3acfc80164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_by_date_with_importance(model, date):\n",
    "    n = 5 \n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "    X, y = get_training_set(date, n)\n",
    "    # one hot encoding on the Home feature \n",
    "    games_on_day = df[df['GAME_DATE'] == date].copy()\n",
    "    games_on_day['DAYS_SINCE_GAME'] = np.zeros(len(games_on_day))\n",
    "\n",
    "    test = games_on_day.drop(columns = ['WIN_ONE', 'GAME_DATE'])\n",
    "\n",
    "    model.fit(X,y)\n",
    "    pred = model.predict(test)\n",
    "    correct = np.sum(pred == games_on_day['WIN_ONE'])\n",
    "    games = len(pred)\n",
    "    importance_scores = model.get_booster().get_score(importance_type='gain')\n",
    "    return correct, games, importance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a114ef-e7ea-48f4-9eb9-8df973cb1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_with_importance(model) :\n",
    "    \"\"\"\n",
    "    Outputs the average feature importance scores of game predictions\n",
    "    \"\"\"\n",
    "    total_correct = total_games = 0\n",
    "    feature_scores = {}\n",
    "    for t in test:\n",
    "        correct, games, importance_scores = pred_by_date_with_importance(model, t)\n",
    "        \n",
    "        for feature, score in importance_scores.items():\n",
    "            if feature not in feature_scores:\n",
    "                feature_scores[feature] = []\n",
    "            feature_scores[feature].append(score)\n",
    "            \n",
    "\n",
    "        total_correct += correct\n",
    "        total_games += games\n",
    "\n",
    "    average_importance = {features: sum(scores)/len(scores) for features, scores in feature_scores.items()}  \n",
    "    sorted_features = sorted(average_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10a8ee-6096-4371-8dd7-b27b2edb2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective='binary:logistic')\n",
    "importance_scores = test_model_with_importance(model)\n",
    "print(importance_scores)Testing the model with the feature importance scores by iteratively removing the least important features and comparing the accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a819828-a7f5-49e1-a494-3a41dff88335",
   "metadata": {},
   "source": [
    "Testing the model with the feature importance scores by iteratively removing the least important features and comparing the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef51f5e-aa1b-4105-a3f9-610da7bfe9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set_with_features (date, num_seasons, features) :\n",
    "    \"\"\"\n",
    "    Input: Date of games, number of seasons and feature subset to include in dataset\n",
    "    Output: All rows from the last num_seasons and all games in the current season up till the given date\n",
    "    \"\"\"\n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "    data = df[df['SEASON_YEAR'].between(season - num_seasons, season)].copy()\n",
    "    data['DAYS_SINCE_GAME'] = [(date-game_day).days for game_day in data['GAME_DATE']]\n",
    "    data = data[data['DAYS_SINCE_GAME'] > 0]\n",
    "\n",
    "    data = data.sort_values(by = 'DAYS_SINCE_GAME')\n",
    "\n",
    "    X = data[features]\n",
    "    y = data['WIN_ONE']\n",
    "\n",
    "    return (X,y)\n",
    "\n",
    "def pred_by_date_with_features (model, date, features) :\n",
    "    n = 5 \n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "\n",
    "    X, y = get_training_set_with_features(date, n, features)\n",
    "\n",
    "    games_on_day = df[df['GAME_DATE'] == date].copy()\n",
    "    games_on_day['DAYS_SINCE_GAME'] = np.zeros(len(games_on_day))\n",
    "\n",
    "    test = games_on_day[features]\n",
    "    model.fit(X,y)\n",
    "    pred = model.predict(test)\n",
    "    correct = np.sum(pred == games_on_day['WIN_ONE'])\n",
    "    games = len(pred)\n",
    "    return correct, games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b97d1c-1e87-428a-9bf3-06f9f99a1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_with_importance(model, current_features, min_subset_size, top_n) :\n",
    "    \"\"\"\n",
    "    Iterates through the feature importance scores and iteratively remove the least importance features\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # current_features = [f[0] for f in feature_importance]\n",
    "    \n",
    "    while len(current_features) >= min_subset_size:\n",
    "        total_correct = total_games = 0\n",
    "        print(f\"Evaluating with {len(current_features)} features...\")\n",
    "        for t in test:    \n",
    "            correct, games = pred_by_date_with_features(model, t, features = current_features)\n",
    "        \n",
    "            total_correct += correct\n",
    "            total_games += games\n",
    "        print(current_features, ':', total_correct/total_games)\n",
    "        results.append((current_features.copy(), total_correct/total_games))\n",
    "        current_features.pop(-1)\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c115eae-4217-49c6-a0a1-67cd4d393b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective='binary:logistic')\n",
    "sorted_features = [f[0] for f in importance_scores]\n",
    "print(sorted_features)\n",
    "top_subsets = feature_selection_with_importance(model, sorted_features, min_subset_size=20, top_n=10)\n",
    "\n",
    "for i, (subset, acc) in enumerate(top_subsets, 1):\n",
    "    print(f\"#{i}: Features = {subset}, Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15196ee5-051c-460c-8e03-2a90839ee184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best performing feature subset\n",
    "best_feature_subset = top_subsets[0][0]\n",
    "print('Best feature subset: ', best_feature_subset)\n",
    "total_correct = total_games = 0\n",
    "for t in test:\n",
    "    correct, games = pred_by_date_with_features(model, t, best_feature_subset)\n",
    "\n",
    "    total_correct += correct\n",
    "    total_games += games\n",
    "print('Accuracy:', total_correct / total_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021aa82-c054-4cf9-a75d-822827baf620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "# def feature_selection(model, feature_names, min_subset_size, max_subset_size, top_n) :\n",
    "#     \"\"\"\n",
    "#     Iterates through the feature subsets and returns the top n subsets that gives the best scores\n",
    "#     \"\"\"\n",
    "#     print('start')\n",
    "#     results = []\n",
    "#     for n in range(min_subset_size, max_subset_size + 1):\n",
    "#         print(n)\n",
    "#         for subset in combinations(feature_names, n):\n",
    "#             print(subset)\n",
    "#             total_correct = total_games = 0\n",
    "#             for t in test:\n",
    "#                 print('test')\n",
    "#                 correct, games = pred_by_date_with_features(model, t, features = list(subset))\n",
    "        \n",
    "#                 total_correct += correct\n",
    "#                 total_games += games\n",
    "#             print(subset, ':', total_correct/total_games)\n",
    "#             results.append((subset, correct/games))\n",
    "#     results.sort(key=lambda x: x[1], reverse=True)\n",
    "#     return results[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae0524-0f30-49a1-aa25-581150e0e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through every combinations of size 40; takes too long (5+ hours)\n",
    "# model = XGBClassifier(objective='binary:logistic')\n",
    "# all_features = [col for col in df.columns if col not in ['WIN_ONE', 'GAME_DATE', 'SEASON_YEAR']]\n",
    "# top_subsets = feature_selection(model, all_features, min_subset_size=40, max_subset_size=40, top_n=10)\n",
    "\n",
    "# for i, (subset, acc, total) in enumerate(top_subsets, 1):\n",
    "#     print(f\"#{i}: Features = {subset}, Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c35db0f-dfd9-4878-8913-ff46cb83fb49",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162a6dd-8bfe-4f6f-bdeb-909b7bcb9f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_by_date_multiple_models (models_dict, date) :\n",
    "    \"\"\"\n",
    "    Predict the outcome of all games on the given date for all models given. Used specifically to make\n",
    "    cross validation more efficient\n",
    "    \"\"\"\n",
    "    n = 5 # how many years in the past for training\n",
    "    \n",
    "    # determine season of the game\n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "\n",
    "    # get data in relevant time frame\n",
    "    X, y = get_training_set(date, n)\n",
    "\n",
    "    games_on_day = df[df['GAME_DATE'] == date].copy()\n",
    "    games_on_day['DAYS_SINCE_GAME'] = np.zeros(len(games_on_day))\n",
    "\n",
    "    test = games_on_day.drop(columns = ['WIN_ONE', 'GAME_DATE'])\n",
    "\n",
    "    scores = np.zeros(len(models_dict))\n",
    "    for k, v in models_dict.items() :\n",
    "        v.fit(X,y)\n",
    "        pred = v.predict(val_set)\n",
    "        scores[k] = np.sum(pred == games_on_day['WIN_ONE'])\n",
    "    return scores, len(games_on_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024d2de-3105-4756-82cb-a22e0e083d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XGBoost parameters\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200, 400],\n",
    "    \"eta\": [0.01, 0.05, 0.1, 0.2], # learning_rate\n",
    "    \"max_depth\": [4, 6, 8, 10], # maximum depth of a tree\n",
    "    \"subsample\": [0.5, 0.7, 1], # fraction of observation to be radnomly sampled for each tree\n",
    "    \"colsample_bytree\": [0.5, 0.7, 1], # fraction of columns to be random samples for each tree\n",
    "    \"alpha\": [0.5, 1, 2, 5] # lasso regression\n",
    "}\n",
    "\n",
    "param_dict = {} # store params with key corresponding to index of score in np.array\n",
    "index = 0\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for values in itertools.product(*param_grid.values()):\n",
    "    param_dict[index] = XGBClassifier(objective='binary:logistic', random_state = 33, **dict(zip(param_grid.keys(), values)))\n",
    "    index += 1\n",
    "\n",
    "scores = np.zeros(len(param_dict))\n",
    "total_games = 0\n",
    "\n",
    "first_season = df['SEASON_YEAR'].min()\n",
    "last_season = df['SEASON_YEAR'].max()-4\n",
    "\n",
    "for t in test:\n",
    "    s, g = pred_by_date_multiple_models(param_dict, t)\n",
    "\n",
    "    scores += s\n",
    "    total_games += g\n",
    "    print(scores / total_games)\n",
    "\n",
    "print('final scores: ', scores / total_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a27693-7bba-4722-81f5-d49cd64b6a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_scores = scores / total_games\n",
    "best_model = param_dict[all_scores.argmax()]\n",
    "best_model.get_params() #'n_estimators': 400, eta: 0.01, max_depth: 4, subsample: 0.7, colsample_bytree: 0.7, alpha: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a830931-febe-453a-bd08-44b895bb871a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_five_models = np.argpartition(all_scores, -5)[-5:]\n",
    "top_five_models = top_five_models[np.argsort(-all_scores[top_five_models])]\n",
    "top_five_scores = all_scores[top_five_models]\n",
    "print(top_five_scores)\n",
    "for i in top_five_models : \n",
    "    p = param_dict[i].get_params()\n",
    "    print(f\"n_estimators = {p['n_estimators']}, eta = {p['eta']}, max_depth = {p['max_depth']}, subsample = {p['subsample']}, colsample_bytree = {p['colsample_bytree']}, alpha = {p['alpha']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e40c97f-7d78-4d1e-aa63-8f3e93ad668f",
   "metadata": {},
   "source": [
    "### Test Models\n",
    "We want to test the model trained on rolling averages and the predicted statistics from the second model. We will predict every game in the last 4 seasons. This means we need to predict all the statistics for the games in the last 9 seasons using the second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30da327-732d-4884-87f7-6a8b0fc21bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test_season = all_stats_cleaned['SEASON_YEAR'].max() - 4\n",
    "last_test_season =  all_stats_cleaned['SEASON_YEAR'].max()\n",
    "test_set = all_stats_cleaned[all_stats_cleaned['SEASON_YEAR'] >= first_test_season]['GAME_DATE'].unique()\n",
    "train_set = all_stats_cleaned[all_stats_cleaned['SEASON_YEAR'] >= first_test_season - 5]['GAME_DATE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b2a6b-66c1-4d04-932c-0f72c2a5d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = df_rolling[df_rolling['SEASON_YEAR'] >= first_test_season]['GAME_DATE'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a4596-4fee-4043-adb9-1fc6bdcb5431",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ce56d-7d83-40b4-851f-c6051a9ef775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if import in from csv\n",
    "#df_model = pd.read_csv('df_model_basic_parameters.csv')\n",
    "#df_model['GAME_DATE'] = pd.to_datetime(df_model['GAME_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b076c223-6d4d-4bf1-86af-e7d0efc378cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_model = pred_training_set(model_training_set, first_test_season - time_horizon, last_test_season, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5606d9-16d9-4fcf-a437-9d7508829091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.to_csv('df_model_tuned.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea790fe5-3f47-46ce-b9a8-6003157f28cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556b094-3627-4ed1-bc43-f5ad9a1625f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = XGBClassifier(n_estimators = 100, eta = 0.05, max_depth = 4, subsample = 0.5, colsample_bytree = 0.5, alpha = 1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd0f0aa-0345-455c-b469-3a4989c02c30",
   "metadata": {},
   "source": [
    "#### Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a4476-ea51-44f9-bb59-70823f83ce8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_horizon = 2\n",
    "test_set = all_stats_cleaned[all_stats_cleaned['SEASON_YEAR'] >= first_test_season-3]['GAME_DATE'].unique()\n",
    "correct, games = test_model(df_rolling, final_model, test_set)\n",
    "print(\"Score:\", correct / games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c373a6-8414-46e2-baa5-61c801b9802e",
   "metadata": {},
   "source": [
    "#### ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbb170-3761-48c7-94ec-345883c6bf9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct, games = test_model(df_model, final_model, test_set)\n",
    "print(\"Score:\", correct / games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c742f-7046-41ba-8aa8-c49b4999a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe0764-937c-4c8a-bb9f-08f4f03d2aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model[df_model['SEASON_YEAR'].between(2019,2024)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd41b0-d7d9-4f9b-be78-4704eb241a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
