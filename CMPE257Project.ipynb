{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbd09ee-9206-4948-9ae6-e42e7d20976a",
   "metadata": {},
   "source": [
    "# NBA Game Predictor Model\n",
    "### CMPE 257 Project\n",
    "Authors: Kaushika Uppu, Miranda Billawala, Yun Ei Hlaing, Iris Cheung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f5cbd-6516-49cf-9271-94878f5f9d0c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030921a-827d-4a1f-af9b-104e618da8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28abb9c-228a-49bb-9721-215d0f183617",
   "metadata": {},
   "source": [
    "## NBA Game Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2dae76-eb39-4b8e-b8c2-9c1cc8d16cca",
   "metadata": {},
   "source": [
    "First, we load in all of the NBA game data from the CSV file. Exact code for gathering data is in a separate file and use the nba_api file. Only games from the 1985-1986 season and afterward are loaded in as the seasons before that are missing a very significant portion of the game statistics' data. We also want to be able to map from team id to abbreviation and back easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f17e2e-851c-444d-bdb4-a1b63b594be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats_cleaned = pd.read_csv('all_stats_cleaned.csv')\n",
    "all_stats_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd29527d-1036-4422-b002-364145da7151",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfbde50-7bdd-478c-b816-96eb9d8beeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_id_to_abb = {} # dictionary to convert from team_id to team_abbreviation\n",
    "team_abb_to_id = {} # dictionary to convert from team_abbreviation to team_id\n",
    "\n",
    "teams = (all_stats_cleaned[['TEAM_ID', 'TEAM_ABBREVIATION']]).drop_duplicates()\n",
    "\n",
    "for index, row in teams.iterrows() :\n",
    "    if row['TEAM_ID'] not in team_id_to_abb.keys():\n",
    "        team_id_to_abb[row['TEAM_ID']] = []\n",
    "    team_id_to_abb[row['TEAM_ID']].append(row['TEAM_ABBREVIATION'])\n",
    "    team_abb_to_id[row['TEAM_ABBREVIATION']] = row['TEAM_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f8db0b-eb67-41f9-8287-676aeed18b2a",
   "metadata": {},
   "source": [
    "### Merging Home and Away Team Stats Into One Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c3044-4f7f-4516-8850-32da043a2f56",
   "metadata": {},
   "source": [
    "Currently, each game is represented by two separate rows in the dataset - one for the home team and one for the away team. To make the data more clear, we decided to combine the two rows into a single row with statistics for both teams. Since predicting with our model will pass one set order of team one and team two (i.e. Lakers as Team One, Warriors as Team Two), we want to make sure that the model realizes games with the Lakers as Team Two and Warriors as Team One are more similar than may appear by the data. To do this, we will duplicate the rows and flip the teams. Then, we will have each game listed twice with the teams flipped. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f167431-5cca-4d38-befc-a7e832eaebdc",
   "metadata": {},
   "source": [
    "Firstly, we split the dataset into two : home games and away games. Then, we performed a join on these two datasets, matching each home team with its corresponding opponent based on the same dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a9b9a-9667-4f37-be8c-27b1c74ef6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = all_stats_cleaned[all_stats_cleaned.HOME == 1]\n",
    "away = all_stats_cleaned[all_stats_cleaned.HOME == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8f695-c8b8-423d-b2f1-e6273b6e3284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_stats_home = pd.merge(home, away, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "combined_stats_away = pd.merge(away, home, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "\n",
    "combined_stats = pd.concat([combined_stats_home, combined_stats_away], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f448b5f0-f44c-4957-945d-f57bf5fd5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cde485-a219-4de4-923f-3815f6bbdb2d",
   "metadata": {},
   "source": [
    "Comparing the number of rows in the combined dataset to the original shows that the dataset row have been reduced by half, as each game is now represented by a single row instead of two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6eadb-8c9e-4edd-bba7-267512d7ee49",
   "metadata": {},
   "source": [
    "After merging the rows, there are some columns that appear twice or are now unneccessary to the dataset. These columns include `MIN_ONE`/`MIN_TWO` (length of game in minutes), `SEASON_YEAR_ONE`/`SEASON_YEAR_TWO`, `OPPONENT_ONE` and `OPPONENT_TWO`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f79796-bfd6-4991-8b7e-d835e758d8ee",
   "metadata": {},
   "source": [
    "We first checked if the `MIN_ONE` and `MIN_TWO` for each row has the same values. As seen below, there are 24 games where the minutes differed slightly. However, since the difference did not seem to be significant, we decided to retain one column and rename it `MIN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d683d2-7e36-4979-9e74-54f7457ea220",
   "metadata": {},
   "outputs": [],
   "source": [
    "(combined_stats['MIN_ONE'] != combined_stats['MIN_TWO']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e20896-7388-4ad1-ae28-4557f980c77c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_stats[combined_stats['MIN_ONE'] != combined_stats['MIN_TWO']][['MIN_ONE','MIN_TWO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1749d449-34c6-4964-af4e-9113a32a9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats = combined_stats.drop(columns = ['MIN_TWO', 'OPPONENT_ONE', 'OPPONENT_TWO', 'SEASON_YEAR_ONE'])\n",
    "combined_stats.rename(columns={'MIN_ONE': 'MIN', 'SEASON_YEAR_TWO': 'SEASON_YEAR'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89436d9-ca4e-49aa-b927-437d58bb4459",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d0f7c-13b5-46e4-b97a-6cde4b4585b5",
   "metadata": {},
   "source": [
    "Features to add : \n",
    "1) Win streak\n",
    "2) Win percentage\n",
    "3) ELO Scores\n",
    "4) EFG%\n",
    "5) TS%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a20f7-6604-4c09-9106-e24b5e23849a",
   "metadata": {},
   "source": [
    "### Win Streak and Win Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54849da8-424f-4e25-aaf5-d9ff3ccc30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_win_streak_and_percentage(df, combined=False):\n",
    "    \"\"\"\n",
    "    Input: Dataframe with team one and team two data for each game and boolean to check if dataframe is combined with both team data\n",
    "    Output: New dataframe with added win streak and win percentage for both teams\n",
    "    \"\"\"\n",
    "    team_date_stats = all_stats_cleaned[['TEAM_ID', 'GAME_DATE', 'WIN']].sort_values(by=['TEAM_ID', 'GAME_DATE']).reset_index(drop=True)\n",
    "    team_date_stats['WIN_STREAK'] = 0\n",
    "    team_date_stats['WIN_PERCENTAGE'] = 0.0\n",
    "    \n",
    "    for team_id, group in team_date_stats.groupby('TEAM_ID'):\n",
    "        streak = 0\n",
    "        wins = 0\n",
    "        total_games = 0\n",
    "        indices = group.index\n",
    "    \n",
    "        for i in range(len(indices)):\n",
    "            idx = indices[i]\n",
    "    \n",
    "            # WIN STREAK\n",
    "            team_date_stats.at[idx, 'WIN_STREAK'] = streak\n",
    "    \n",
    "            if team_date_stats.at[idx, 'WIN'] == 1:\n",
    "                streak += 1\n",
    "            else: \n",
    "                streak = 0\n",
    "    \n",
    "            # WIN PERCENTAGE\n",
    "            if total_games == 0:\n",
    "                team_date_stats.at[idx, 'WIN_PERCENTAGE'] = 0.0\n",
    "            else: \n",
    "                team_date_stats.at[idx, 'WIN_PERCENTAGE'] = wins / total_games\n",
    "    \n",
    "            total_games += 1\n",
    "            if team_date_stats.at[idx, 'WIN'] == 1:\n",
    "                wins += 1\n",
    "\n",
    "    if combined:\n",
    "    # Join Win streak and Win percentage of team one and team two into the merged table\n",
    "        team_date_stats.drop('WIN', axis=1, inplace=True)\n",
    "        df = pd.merge(df, team_date_stats,\n",
    "                              how='left', \n",
    "                              left_on = ['TEAM_ID_ONE', 'GAME_DATE'],\n",
    "                              right_on=['TEAM_ID', 'GAME_DATE'])\n",
    "        df.drop('TEAM_ID', axis=1, inplace=True)\n",
    "        df.rename(columns = {'WIN_STREAK': 'WIN_STREAK_ONE',\n",
    "                                     'WIN_PERCENTAGE': 'WIN_PERCENTAGE_ONE'}, inplace=True)\n",
    "        df = pd.merge(df, team_date_stats,\n",
    "                              how='left', \n",
    "                              left_on = ['TEAM_ID_TWO', 'GAME_DATE'],\n",
    "                              right_on=['TEAM_ID', 'GAME_DATE'])\n",
    "        df.drop('TEAM_ID', axis=1, inplace=True)\n",
    "        df.rename(columns = {'WIN_STREAK': 'WIN_STREAK_TWO',\n",
    "                                     'WIN_PERCENTAGE': 'WIN_PERCENTAGE_TWO'}, inplace=True)\n",
    "    else:\n",
    "        # Join Win streak and Win percentage into the dataframe\n",
    "        team_date_stats.drop('WIN', axis=1, inplace=True)\n",
    "        df = pd.merge(df, team_date_stats,\n",
    "                              how='left', \n",
    "                              on = ['TEAM_ID', 'GAME_DATE'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e014a30-619f-4b87-b757-e444d91b5a9e",
   "metadata": {},
   "source": [
    "### ELO Score Before Current Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835ead9-c09c-4961-9e78-35c7213cb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_opponent_points(df):\n",
    "    df_opp = df[['TEAM_ABBREVIATION', 'GAME_DATE', 'PTS', 'TEAM_ID']].copy()\n",
    "    merged_df = pd.merge(df, df_opp, \n",
    "                         how='left',\n",
    "                          left_on=['GAME_DATE', 'OPPONENT'],\n",
    "                            right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('', '_OPPONENT'))\n",
    "    merged_df.drop(columns=['TEAM_ABBREVIATION_OPPONENT'], inplace=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865af94b-e088-4e1b-bf03-a0029008eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elo_score(df, combined=False):\n",
    "    \"\"\"\n",
    "    Input: Dataframe with team one and team two data for each game and boolean to check if dataframe is combined with both team data\n",
    "    Output: New dataframe with elo scores for both teams added \n",
    "    \"\"\"\n",
    "    if combined:\n",
    "        df['GAME_ID'] = df.apply(\n",
    "        lambda row: '_'.join(sorted([str(row['TEAM_ID_ONE']), str(row['TEAM_ID_TWO'])]) + [str(row['GAME_DATE'])]),\n",
    "        axis=1\n",
    "    )\n",
    "        df['ELO_ONE'] = np.nan\n",
    "        df['ELO_TWO'] = np.nan\n",
    "    else:\n",
    "        df = merge_opponent_points(df)\n",
    "        df['ELO'] = np.nan\n",
    "        df['GAME_ID'] = df.apply(\n",
    "        lambda row: '_'.join(sorted([str(row['TEAM_ID']), str(row['TEAM_ID_OPPONENT'])]) + [str(row['GAME_DATE'])]),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    team_elos = {} # to use for checking if a team has appeared and track team last elo scores\n",
    "    team_last_season = {} # to track last seasons of teams\n",
    "    processed_games = set() # to track game id - handle duplicate game columns\n",
    "    elo_map = {} # for faster computation\n",
    "    df = df.sort_values(by='GAME_DATE').reset_index(drop=True)\n",
    "    \n",
    "    for i,row in df.iterrows():\n",
    "        season = row['SEASON_YEAR']\n",
    "        game_id = row['GAME_ID']\n",
    "\n",
    "        if game_id in processed_games:\n",
    "            continue\n",
    "        processed_games.add(game_id)\n",
    "\n",
    "        if combined:\n",
    "            team_one, team_two = row['TEAM_ID_ONE'], row['TEAM_ID_TWO']\n",
    "            points_one, points_two = row['PTS_ONE'], row['PTS_TWO']\n",
    "            home_one = row['HOME_ONE']\n",
    "        \n",
    "            # Season adjustment formula for ELO : New Season ELO = 0.75 * Last Season ELO + 0.25 * Mean ELO, Mean ELO = 1505\n",
    "            for team in [team_one, team_two]:\n",
    "                # check if team has not appeared yet in the dataset\n",
    "                if team not in team_elos:\n",
    "                    team_elos[team] = 1505 \n",
    "                    team_last_season[team] = season\n",
    "                # check for new season, if yes, apply season adjustment\n",
    "                elif team_last_season[team] != season:\n",
    "                    team_elos[team] = 0.75 * team_elos[team] + 0.25 * 1505\n",
    "                    team_last_season[team] = season\n",
    "        \n",
    "            # elo scores before game\n",
    "            elo_one = team_elos[team_one]\n",
    "            elo_two = team_elos[team_two]\n",
    "        \n",
    "            # Add 100 score to home team\n",
    "            if home_one == 1:\n",
    "                elo_one_after_home_adv = elo_one + 100 \n",
    "                elo_two_after_home_adv = elo_two\n",
    "            else:\n",
    "                elo_one_after_home_adv = elo_one \n",
    "                elo_two_after_home_adv = elo_two + 100\n",
    "        \n",
    "            # Expected score of game formula : exp = 1/ (1+10^((ELO two after home advantage - ELO one after home advantage) / 400))\n",
    "            exp = 1/ (1+10**((elo_two_after_home_adv - elo_one_after_home_adv) / 400))\n",
    "        \n",
    "            actual = 1 if points_one > points_two else 0\n",
    "            margin_of_victory = abs(points_one - points_two)\n",
    "        \n",
    "            # Margin of Victory Multiplier formula : ((MOV + 3) ** 0.8) / (7.5 + 0.006 * (Elo team one - Elo team two))\n",
    "            MOVM = ((margin_of_victory + 3) ** 0.8) / (7.5 + 0.006 * (elo_one - elo_two))\n",
    "        \n",
    "            # change in ELO: K * MOVM * (actual - exp), k -> attenuation factor -> higher means elo score adjusts quickly to changes in strength of team\n",
    "            K = 20 # 20 is optimal for nba \n",
    "            change = K * MOVM * (actual - exp)\n",
    "    \n",
    "            # Update data for ELO ratings\n",
    "            team_elos[team_one] += change\n",
    "            team_elos[team_two] -= change\n",
    "        \n",
    "            # store elo score for game id at the table\n",
    "            # df.at[i, 'ELO_ONE'] = elo_one\n",
    "            # df.at[i, 'ELO_TWO'] = elo_two\n",
    "            # df.loc[(df['GAME_ID'] == game_id) & df['TEAM_ID_ONE'] == team_two, 'ELO_ONE'] = elo_two\n",
    "            # df.loc[(df['GAME_ID'] == game_id) & df['TEAM_ID_TWO'] == team_one, 'ELO_TWO'] = elo_one\n",
    "\n",
    "            # store elo scores in dictionary\n",
    "            elo_map[(game_id, team_one, team_two)] = elo_one\n",
    "            elo_map[(game_id, team_two, team_one)] = elo_two\n",
    "     \n",
    "        else:\n",
    "            team, team_opp = row['TEAM_ID'], row['TEAM_ID_OPPONENT']\n",
    "            points_team, points_opp = row['PTS'], row['PTS_OPPONENT']\n",
    "            home = row['HOME']\n",
    "        \n",
    "            # Season adjustment formula for ELO : New Season ELO = 0.75 * Last Season ELO + 0.25 * Mean ELO, Mean ELO = 1505\n",
    "            for t in [team, team_opp]:\n",
    "                # check if team has not appeared yet in the dataset\n",
    "                if t not in team_elos:\n",
    "                    team_elos[t] = 1505 \n",
    "                    team_last_season[t] = season\n",
    "                # check for new season, if yes, apply season adjustment\n",
    "                elif team_last_season[t] != season:\n",
    "                    team_elos[t] = 0.75 * team_elos[t] + 0.25 * 1505\n",
    "                    team_last_season[t] = season\n",
    "        \n",
    "            # elo scores before game\n",
    "            elo_team = team_elos[team]\n",
    "            elo_opponent = team_elos[team_opp]\n",
    "        \n",
    "            # Add 100 score to home team\n",
    "            if home == 1:\n",
    "                elo_team_home = elo_team + 100 \n",
    "                elo_opp_home = elo_opponent\n",
    "            else:\n",
    "                elo_team_home = elo_team \n",
    "                elo_opp_home = elo_opponent + 100\n",
    "        \n",
    "            # Expected score of game formula : exp = 1/ (1+10^((ELO two after home advantage - ELO one after home advantage) / 400))\n",
    "            exp = 1/ (1+10**((elo_opp_home - elo_team_home) / 400))\n",
    "        \n",
    "            actual = 1 if points_team > points_opp else 0\n",
    "            margin_of_victory = abs(points_team - points_opp)\n",
    "        \n",
    "            # Margin of Victory Multiplier formula : ((MOV + 3) ** 0.8) / (7.5 + 0.006 * (Elo team one - Elo team two))\n",
    "            MOVM = ((margin_of_victory + 3) ** 0.8) / (7.5 + 0.006 * (elo_team - elo_opponent))\n",
    "        \n",
    "            # change in ELO: K * MOVM * (actual - exp), k -> attenuation factor -> higher means elo score adjusts quickly to changes in strength of team\n",
    "            K = 20 # 20 is optimal for nba \n",
    "            change = K * MOVM * (actual - exp)\n",
    "\n",
    "            # Update data for ELO ratings\n",
    "            team_elos[team] += change\n",
    "            team_elos[team_opp] -= change\n",
    "        \n",
    "            # store elo score for both row of game at the table\n",
    "            # df.at[i, 'ELO'] = elo_team\n",
    "            # df.loc[(df['GAME_ID'] == game_id) & df['TEAM_ID'] == team_opp, 'ELO'] = elo_opponent\n",
    "            elo_map[(game_id, team)] = elo_team\n",
    "            elo_map[(game_id, team_opp)] = elo_opponent\n",
    "\n",
    "    # add data from elo dictionary into dataframe\n",
    "    if not combined:\n",
    "        df['ELO'] = df.apply(lambda x: elo_map.get((x['GAME_ID'], x['TEAM_ID']), np.nan), axis=1)\n",
    "        df.drop(columns=['PTS_OPPONENT', 'TEAM_ID_OPPONENT'], axis=1, inplace=True)\n",
    "    else: \n",
    "        df['ELO_ONE'] = df.apply(lambda x: elo_map.get((x['GAME_ID'], x['TEAM_ID_ONE'], x['TEAM_ID_TWO']), np.nan), axis=1)\n",
    "        df['ELO_TWO'] = df.apply(lambda x: elo_map.get((x['GAME_ID'], x['TEAM_ID_TWO'], x['TEAM_ID_ONE']), np.nan), axis=1)\n",
    "    df.drop(columns=['GAME_ID'], axis=1, inplace=True)\n",
    "    \n",
    "            \n",
    "    return df                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79ba04-8bdd-4a9e-9ee7-3b08aca53fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for single team data\n",
    "test_1 = add_win_streak_and_percentage(all_stats_cleaned)\n",
    "test_1 = add_elo_score(test_1)\n",
    "print(test_1.columns)\n",
    "test_1[test_1['TEAM_ID'] == 14].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d55a3-2551-4a4d-9951-4fb1f40aa6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for combined team and opponent data\n",
    "test_2 = add_win_streak_and_percentage(combined_stats, True)\n",
    "test_2 = add_elo_score(test_2, True)\n",
    "test_2[test_2['TEAM_ID_ONE'] == 14].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d137f-3bc0-43e8-879b-c9bc2d9f6c2e",
   "metadata": {},
   "source": [
    "### Effective Field Goal Percentage and True Shooting Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c4746-bd69-4cb4-94fe-e60c5305b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shooting_percentages(df, combined=False):\n",
    "    if combined: \n",
    "        df['EFG%_ONE'] = (df['FGM_ONE'] + 1.5 * df['FG3M_ONE']) / df['FGA_ONE']\n",
    "        df['EFG%_TWO'] = (df['FGM_TWO'] + 1.5 * df['FG3M_TWO']) / df['FGA_TWO']\n",
    "        df['TS%_ONE'] = df['PTS_ONE'] / (2 * (df['FGA_ONE'] + 0.44 * df['FTA_ONE']))\n",
    "        df['TS%_TWO'] = df['PTS_TWO'] / (2 * (df['FGA_TWO'] + 0.44 * df['FTA_TWO']))\n",
    "    else:\n",
    "        df['EFG%'] = (df['FGM'] + 1.5 * df['FG3M']) / df['FGA']\n",
    "        df['TS%'] = df['PTS'] / (2 * (df['FGA'] + 0.44 * df['FTA']))\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00c976-ab01-41a6-b666-66e189e26c6b",
   "metadata": {},
   "source": [
    "### Point Differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6763f10a-955f-43d1-b952-33eaecf5f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_point_differential(df, window = 5, combined=False):\n",
    "        #  add opponent points to all_stats_cleaned table\n",
    "    for team_id in all_stats_cleaned['TEAM_ID'].unique() :\n",
    "        team_data = all_stats_cleaned[all_stats_cleaned['TEAM_ID'] == team_id].sort_values(by='GAME_DATE')\n",
    "        for col in cols :\n",
    "            shift = team_data[col].shift(1)\n",
    "            team_data[col] = shift.rolling(window = n).mean()\n",
    "        if result is None :\n",
    "            result = team_data\n",
    "        else :\n",
    "            result = pd.concat([result, team_data])\n",
    "    \n",
    "    \n",
    "    if combined:\n",
    "        df['PTS_DIFF_ONE'] = df['PTS_ONE'] - df['PTS_TWO']\n",
    "        df['PTS_DIFF_TWO'] = df['PTS_TWO'] - df['PTS_ONE']\n",
    "    else:\n",
    "        df = merge_opponent_points(df)\n",
    "        df['PTS_DIFF'] = df['PTS'] - df['PTS_OPPONENT']\n",
    "        df.drop(columns=['PTS_OPPONENT', 'TEAM_ID_OPPONENT'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f693e-e6da-44e5-8a60-28bf24d618d8",
   "metadata": {},
   "source": [
    "### Win for Last Matchup Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5764ba-ac0d-4209-9965-470f0ebd5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_win_last_game(df, combined=False):\n",
    "    if combined:\n",
    "        sorted_df = df.sort_values(by=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'])\n",
    "        sorted_df['WIN_LAST'] = sorted_df.groupby(['TEAM_ID_ONE', 'TEAM_ID_TWO'])['WIN_ONE'].shift(1)\n",
    "        df = df.merge(sorted_df[['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE', 'WIN_LAST']],\n",
    "                      on=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'],\n",
    "                      how = 'left')\n",
    "    else:\n",
    "        sorted_df = df.sort_values(by=['TEAM_ID', 'OPPONENT', 'GAME_DATE'])\n",
    "        sorted_df['WIN_LAST'] = sorted_df.groupby(['TEAM_ID', 'OPPONENT'])['WIN'].shift(1)\n",
    "        df = df.merge(sorted_df[['TEAM_ID', 'OPPONENT', 'GAME_DATE', 'WIN_LAST']],\n",
    "                      on=['TEAM_ID', 'OPPONENT', 'GAME_DATE'],\n",
    "                      how = 'left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2917da54-7a54-41ba-8c7a-fb56695c400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_4 = add_win_last_game(all_stats_cleaned)\n",
    "print(test_4.columns)\n",
    "test_4[(test_4['TEAM_ID'] == 14) & (test_4['OPPONENT'] == 'BOS')].sort_values(by='GAME_DATE').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7accc128-6ab8-428f-a434-f7132d710372",
   "metadata": {},
   "source": [
    "## Get Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7100d1b9-ddab-40f1-95bd-a25bbcd98016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_pred_stats.drop(columns = ['TEAM_ABBREVIATION_ONE', 'TEAM_NAME_ONE', 'MIN', 'FGM_ONE', \n",
    "                                             'FGA_ONE', 'FG3M_ONE', 'FG3A_ONE', 'FTM_ONE', 'FTA_ONE', 'PTS_ONE', \n",
    "                                             'PLUS_MINUS_ONE', 'TEAM_ABBREVIATION_TWO', 'TEAM_NAME_TWO', 'HOME_TWO',\n",
    "                                             'WIN_TWO', 'FGM_TWO', 'FGA_TWO', 'FG3M_TWO', 'FG3A_TWO', 'FTM_TWO', \n",
    "                                             'FTA_TWO', 'PTS_TWO', 'PLUS_MINUS_TWO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b06f53d-44bd-4ebb-b99c-95ddf672cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_set (first_season, last_season) :\n",
    "    dates = []\n",
    "    for season in range(first_season, last_season) :\n",
    "        season_data = df[df['SEASON_YEAR'] == season]\n",
    "        start_date = season_data['GAME_DATE'].min()\n",
    "        end_date = season_data['GAME_DATE'].max()\n",
    "\n",
    "        # day around the beginning of the season\n",
    "        beg = season_data[season_data['GAME_DATE'].between(start_date, start_date + timedelta(weeks = 4))]\n",
    "\n",
    "        # day around trade deadline (after about 2/3 of the season)\n",
    "        delta = round((2/3)*(end_date-start_date).days)\n",
    "        approx_deadline = start_date + timedelta(days = delta)\n",
    "        mid = season_data[season_data['GAME_DATE'].between(approx_deadline, approx_deadline + timedelta(weeks = 4))]\n",
    "        \n",
    "        # day around the end of the season\n",
    "        end = season_data[season_data['GAME_DATE'].between(end_date - timedelta(weeks = 4), end_date)]\n",
    "\n",
    "        dates.extend(list(pd.concat([beg.sample(2)['GAME_DATE'], mid.sample(2)['GAME_DATE'], end.sample(2)['GAME_DATE']])))\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c4ca9-749f-4899-8d44-14e086316ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_season = df['SEASON_YEAR'].min()\n",
    "last_season = df['SEASON_YEAR'].max() - 4\n",
    "val_set = get_val_set(first_season, last_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57f63bd-ac90-4416-9ce4-116cc772b48e",
   "metadata": {},
   "source": [
    "### Rolling Window Statistics (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e48fa-aa5b-46c1-8dd5-0ad3546a43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added shooting percentage\n",
    "all_stats_cleaned = add_shooting_percentages(all_stats_cleaned)\n",
    "# added win streak and win percentage\n",
    "all_stats_cleaned = add_win_streak_and_percentage(all_stats_cleaned)\n",
    "# added ELO score\n",
    "all_stats_cleaned = add_elo_score(all_stats_cleaned)\n",
    "# added point differential\n",
    "# all_stats_cleaned = add_point_differential(all_stats_cleaned)\n",
    "# added win for last game\n",
    "all_stats_cleaned = add_win_last_game(all_stats_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593ec6f-a148-48f7-b768-f13759e6949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['FG_PCT', 'FG3_PCT', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'EFG%', 'TS%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59640b54-e890-4dd3-b9bc-d0f1e1bb426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(n) :\n",
    "    cols = ['FG_PCT', 'FG3_PCT', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'EFG%', 'TS%']\n",
    "    result = None\n",
    "    for team_id in all_stats_cleaned['TEAM_ID'].unique() :\n",
    "        team_data = all_stats_cleaned[all_stats_cleaned['TEAM_ID'] == team_id].sort_values(by='GAME_DATE')\n",
    "        for col in cols :\n",
    "            shift = team_data[col].shift(1)\n",
    "            team_data[col] = shift.rolling(window = n).mean()\n",
    "        if result is None :\n",
    "            result = team_data\n",
    "        else :\n",
    "            result = pd.concat([result, team_data])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232938ad-a747-41a8-ba90-e44603653335",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_stats = rolling_window(5)\n",
    "print(pred_stats.shape)\n",
    "pred_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8daffde-15f8-4c50-a10a-cbf607a1ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = pred_stats[pred_stats['HOME'] == 1]\n",
    "away = pred_stats[pred_stats['HOME'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5447d9c2-88dc-4cb5-a7d9-cbc78ffda297",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pred_stats_home = pd.merge(home, away, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "combined_pred_stats_away = pd.merge(away, home, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "\n",
    "combined_pred_stats = pd.concat([combined_pred_stats_home, combined_pred_stats_away], ignore_index = True)\n",
    "\n",
    "combined_pred_stats = combined_pred_stats.drop(columns = ['MIN_TWO', 'OPPONENT_ONE', 'OPPONENT_TWO', 'SEASON_YEAR_ONE'])\n",
    "combined_pred_stats.rename(columns={'MIN_ONE': 'MIN', 'SEASON_YEAR_TWO': 'SEASON_YEAR'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498888db-65f5-4318-9536-3a113581bacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pred_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a8234-8cee-4b10-89f2-5f91d23f0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the first n*30 columns which have nan values because rolling window\n",
    "combined_pred_stats = combined_pred_stats.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a0eec-7ba0-4274-85c6-c4455c7b5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pred_stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deef007-5859-40a0-8fb3-a6b6b093dc1f",
   "metadata": {},
   "source": [
    "### Predicting Using ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6626f1fc-42c9-4ba6-867f-af334043bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df93f95-71e5-4943-8d16-873f8fac69bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adding shooting percentages to the game stats that need to be predicted\n",
    "combined_stats = add_shooting_percentages(combined_stats, combined=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a66648b-3aa3-4dc5-8b60-8f4a94998fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e84f6-9a5a-46c2-947f-5885e9663d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_columns = ['FG_PCT_ONE', 'FG3_PCT_ONE', 'FT_PCT_ONE', 'OREB_ONE', 'DREB_ONE', 'REB_ONE',\n",
    "                    'AST_ONE', 'STL_ONE', 'BLK_ONE', 'TOV_ONE', 'PF_ONE', 'EFG%_ONE', 'TS%_ONE']\n",
    "\n",
    "def get_rolling(team_id, games, prefix, rolling_window = 10):\n",
    "    \"\"\"\n",
    "    Gets rolling statistics for given team using given rolling window.\n",
    "    \"\"\"\n",
    "    stats = {stat: [] for stat in stat_columns}\n",
    "    for _, g in games.tail(rolling_window).iterrows():\n",
    "        if g['TEAM_ID_ONE'] == team_id:\n",
    "            for stat in stat_columns:\n",
    "                stats[stat].append(g[stat])\n",
    "        else:\n",
    "            for stat in stat_columns:\n",
    "                stats[stat].append(g[stat.replace('_ONE', '_TWO')])\n",
    "    return {f\"{prefix}_{stat}\": np.mean(vals) for stat, vals in stats.items()}\n",
    "\n",
    "def build_features_for_game(team_one_id, team_two_id, home_one, date, combined_stats, stat_columns, rolling_window):\n",
    "    \"\"\"\n",
    "    Builds feature vector for a single game using rolling averages and metadata.\n",
    "    \"\"\"\n",
    "    past_games = combined_stats[combined_stats['GAME_DATE'] < date].sort_values('GAME_DATE')\n",
    "\n",
    "    # getting past games for both teams and calculating rolling averages\n",
    "    team_one_games = past_games[\n",
    "        (past_games['TEAM_ID_ONE'] == team_one_id) | (past_games['TEAM_ID_TWO'] == team_one_id)\n",
    "    ]\n",
    "    team_two_games = past_games[\n",
    "        (past_games['TEAM_ID_ONE'] == team_two_id) | (past_games['TEAM_ID_TWO'] == team_two_id)\n",
    "    ]\n",
    "\n",
    "    if len(team_one_games) < rolling_window or len(team_two_games) < rolling_window:\n",
    "        return None\n",
    "\n",
    "    team_one_features = get_rolling(team_one_id, team_one_games, 'TEAM_ONE', rolling_window)\n",
    "    team_two_features = get_rolling(team_two_id, team_two_games, 'TEAM_TWO', rolling_window)\n",
    "\n",
    "    input_features = {\n",
    "        'TEAM_ID_ONE': team_one_id,\n",
    "        'TEAM_ID_TWO': team_two_id,\n",
    "        'HOME_ONE': home_one,\n",
    "        'SEASON_YEAR': date.year if date.month >= 10 else date.year - 1\n",
    "    }\n",
    "    input_features.update(team_one_features)\n",
    "    input_features.update(team_two_features)\n",
    "    return input_features\n",
    "\n",
    "    \n",
    "def train_model(combined_stats, stat_columns, rolling_window = 10):\n",
    "    \"\"\"\n",
    "    Trains a model to predict team stats for a given game using past rolling averages of both teams.\n",
    "    Features: past performance of TEAM_ONE and TEAM_TWO.\n",
    "    Targets: actual stats of TEAM_ONE in the current game.\n",
    "    \"\"\"\n",
    "    combined_stats = combined_stats.sort_values(by='GAME_DATE').reset_index(drop=True)\n",
    "    feature_rows = []\n",
    "    target_dict = {stat: [] for stat in stat_columns}\n",
    "\n",
    "    for idx, row in combined_stats.iterrows():\n",
    "        date = row['GAME_DATE']\n",
    "        team_one = row['TEAM_ID_ONE']\n",
    "        team_two = row['TEAM_ID_TWO']\n",
    "        home = row['HOME_ONE']\n",
    "\n",
    "        features = build_features_for_game(team_one, team_two, home, date, combined_stats, stat_columns, rolling_window)\n",
    "        if features is None:\n",
    "            continue\n",
    "            \n",
    "        feature_rows.append(features)\n",
    "\n",
    "        for stat in stat_columns:\n",
    "            target_dict[stat].append(row[stat])\n",
    "\n",
    "    X = pd.DataFrame(feature_rows)\n",
    "    X = pd.get_dummies(X, columns=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'HOME_ONE'], drop_first=True)\n",
    "\n",
    "    # fitting a XGBoost model for each stat\n",
    "    models = {}\n",
    "    for stat in stat_columns:\n",
    "        y = pd.Series(target_dict[stat])\n",
    "        model = XGBRegressor(n_estimators = 100)\n",
    "        model.fit(X, y)\n",
    "        models[stat] = model\n",
    "\n",
    "    return models, X.columns.tolist()\n",
    "\n",
    "def predict_game_stats(models, feature_cols, combined_stats, team_one_id, team_two_id, home_one, date,\n",
    "                       stat_columns, rolling_window = 10):\n",
    "    \"\"\"\n",
    "    Predicts the statistics for given game.\n",
    "    \"\"\"\n",
    "    features = build_features_for_game(team_one_id, team_two_id, home_one, date, combined_stats, stat_columns, rolling_window)\n",
    "    if features is None:\n",
    "        raise ValueError(\"Not enough past games to make prediction.\")\n",
    "\n",
    "    X_new = pd.DataFrame([features])\n",
    "    X_new = pd.get_dummies(X_new)\n",
    "    for col in feature_cols:\n",
    "        if col not in X_new.columns:\n",
    "            X_new[col] = 0\n",
    "    X_new = X_new[feature_cols]\n",
    "\n",
    "    # predict stats using previously fitted models\n",
    "    prediction = {}\n",
    "    for stat, model in models.items():\n",
    "        prediction[stat] = model.predict(X_new)[0]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d85c94-fc20-4b50-bf64-76848b2865b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stats_model(combined_stats, rolling_window = 10, test_seasons = 4, models = None, feature_cols = None):\n",
    "    \"\"\"\n",
    "    Evaluates predicting stats model by testing on last `test_seasons` seasons using RMSE.\n",
    "    \"\"\"\n",
    "    combined_stats = combined_stats.sort_values('GAME_DATE').reset_index(drop=True)\n",
    "    combined_stats['SEASON_YEAR'] = combined_stats['GAME_DATE'].apply(\n",
    "        lambda d: d.year if d.month >= 10 else d.year - 1\n",
    "    )\n",
    "\n",
    "    stat_columns = ['FG_PCT_ONE', 'FG3_PCT_ONE', 'FT_PCT_ONE', 'OREB_ONE', 'DREB_ONE', 'REB_ONE',\n",
    "                    'AST_ONE', 'STL_ONE', 'BLK_ONE', 'TOV_ONE', 'PF_ONE', 'EFG%_ONE', 'TS%_ONE']\n",
    "\n",
    "    # splitting into training and testing sets\n",
    "    all_seasons = sorted(combined_stats['SEASON_YEAR'].unique())\n",
    "    train_seasons = all_seasons[:-test_seasons]\n",
    "    test_seasons_list = all_seasons[-test_seasons:]\n",
    "    train_data = combined_stats[combined_stats['SEASON_YEAR'].isin(train_seasons)].copy()\n",
    "    test_data = combined_stats[combined_stats['SEASON_YEAR'].isin(test_seasons_list)].copy()\n",
    "\n",
    "    # if models and feature columns not given as parameters\n",
    "    if models is None and feature_cols is None:\n",
    "        models, feature_cols = train_model(train_data, stat_columns, rolling_window)\n",
    "    \n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    # predict stats for all games in testing set\n",
    "    for _, row in test_data.iterrows():\n",
    "        team_one_id = row['TEAM_ID_ONE']\n",
    "        team_two_id = row['TEAM_ID_TWO']\n",
    "        home = row['HOME_ONE']\n",
    "        date = row['GAME_DATE']\n",
    "\n",
    "        pred = predict_game_stats(\n",
    "                models, feature_cols, combined_stats,\n",
    "                team_one_id = team_one_id,\n",
    "                team_two_id = team_two_id,\n",
    "                home_one = home,\n",
    "                date = date,\n",
    "                stat_columns = stat_columns,\n",
    "                rolling_window = rolling_window\n",
    "            )\n",
    "\n",
    "        predictions.append([pred[stat] for stat in stat_columns])\n",
    "        actuals.append([row[stat] for stat in stat_columns])\n",
    "\n",
    "    # evaluating model's predictions\n",
    "    y_true = np.array(actuals)\n",
    "    y_pred = np.array(predictions)\n",
    "    total_rmse = np.sqrt(mean_squared_error(y_true.flatten(), y_pred.flatten()))\n",
    "    return total_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426780d5-531f-4f00-9311-33a0376d8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluate_stats_model(combined_stats, rolling_window = 10, test_seasons = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc97e59-3df7-461a-ae5e-dbd999d9a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c890aa-a66f-41aa-92f0-8bddb088e6a5",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (NEEDS TO BE FIXED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0cf6d7-68bf-4f5b-8e4d-2cc266c28034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41069b5f-c3fd-4cc1-be67-962dbae294b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_stats_model(X, y, n_iter = 5, cv = 3):\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [4, 6, 8, 10],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "        'subsample': [0.5, 0.5, 1.0],\n",
    "        'colsample_bytree': [0.5, 0.5, 1.0]\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor()\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator = model,\n",
    "        param_distributions = param_grid,\n",
    "        n_iter = n_iter,\n",
    "        cv = cv,\n",
    "        scoring = 'neg_root_mean_squared_error',\n",
    "        verbose = False,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    search.fit(X, y)\n",
    "    return search.best_estimator_, search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1202f-da1c-4069-b6cf-914ae49f82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mult_models(combined_stats, stat_columns, rolling_window = 10, n_iter = 5, cv = 3):\n",
    "    \"\"\"\n",
    "    Trains a model to predict team stats for a given game and does randomized hyperparameter tuning for each stat.\n",
    "    \"\"\"\n",
    "    combined_stats = combined_stats.sort_values(by='GAME_DATE').reset_index(drop=True)\n",
    "    feature_rows = []\n",
    "    target_dict = {stat: [] for stat in stat_columns}\n",
    "\n",
    "    for idx, row in combined_stats.iterrows():\n",
    "        date = row['GAME_DATE']\n",
    "        team_one = row['TEAM_ID_ONE']\n",
    "        team_two = row['TEAM_ID_TWO']\n",
    "        home = row['HOME_ONE']\n",
    "\n",
    "        features = build_features_for_game(team_one, team_two, home, date, combined_stats, stat_columns, rolling_window)\n",
    "        if features is None:\n",
    "            continue\n",
    "            \n",
    "        feature_rows.append(features)\n",
    "\n",
    "        for stat in stat_columns:\n",
    "            target_dict[stat].append(row[stat])\n",
    "\n",
    "    X = pd.DataFrame(feature_rows)\n",
    "    X = pd.get_dummies(X, columns=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'HOME_ONE'], drop_first=True)\n",
    "\n",
    "    # finding best hyperparameters for each stat\n",
    "    models = {}\n",
    "    best_params = {}\n",
    "    \n",
    "    for stat in stat_columns:\n",
    "        print(f\"Tuning model for {stat}...\")\n",
    "        y = pd.Series(target_dict[stat])\n",
    "        model, params = tune_stats_model(X, y, n_iter = 5, cv = 3)\n",
    "        models[stat] = model\n",
    "        best_params[stat] = params\n",
    "\n",
    "    return models, X.columns.tolist(), best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416bb92-c0be-4b7a-a0c1-a1585f7c89f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models, feature_cols, best_params = train_mult_models(\n",
    "    combined_stats,\n",
    "    stat_columns = stat_columns,\n",
    "    rolling_window = 5,\n",
    "    n_iter = 5,\n",
    "    cv = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62214c2d-6a89-47b0-82c1-e6212740edde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for stat in best_params:\n",
    "    print(f'Best parameters for {stat} :')\n",
    "    for p in best_params[stat]:\n",
    "        print(f'{p}: {best_params[stat][p]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f31df-7462-4509-9527-f2e397ccd0a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse_tuned = evaluate_stats_model(combined_stats, rolling_window = 10, test_seasons = 4,\n",
    "                                  models = best_models, feature_cols = feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1701a792-28cb-498a-96b2-f3d210c6adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165661b8-1f7a-460b-be29-614cf888c706",
   "metadata": {},
   "source": [
    "## Model Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d0197-3028-4b65-b2b4-99a158af3af7",
   "metadata": {},
   "source": [
    "### Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff14a18-705e-4ac2-a905-2236e8193257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set (date, num_seasons) :\n",
    "    \"\"\"\n",
    "    Input: Date of games and number of seasons to include in dataset\n",
    "    Output: All rows from the last num_seasons and all games in the current season up till the given date\n",
    "    \"\"\"\n",
    "    # determine season of the game\n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "    \n",
    "    # get games for training\n",
    "    data = df[df['SEASON_YEAR'].between(season - num_seasons, season)].copy()\n",
    "    data['DAYS_SINCE_GAME'] = [(date-game_day).days for game_day in data['GAME_DATE']]\n",
    "    data = data[data['DAYS_SINCE_GAME'] > 0]\n",
    "\n",
    "    data = data.sort_values(by = 'DAYS_SINCE_GAME')\n",
    "\n",
    "    # split into X and y and only look at relevant columns\n",
    "    X = data.drop(columns = ['WIN_ONE', 'GAME_DATE'])\n",
    "    y = data['WIN_ONE']\n",
    "\n",
    "    return (X,y)\n",
    "\n",
    "def pred_by_date (df, model, date) :\n",
    "    \"\"\"\n",
    "    Predict the outcome of all games on the given date. \n",
    "    \"\"\"\n",
    "    n = 5 # how many years in the past for training\n",
    "    \n",
    "    # determine season of the game\n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "\n",
    "    # get data in relevant time frame\n",
    "    X, y = get_training_set(date, n)\n",
    "\n",
    "    #df = pd.DataFrame(columns=X.columns)\n",
    "\n",
    "    games_on_day = df[df['GAME_DATE'] == date].copy()\n",
    "    games_on_day['DAYS_SINCE_GAME'] = np.zeros(len(games_on_day))\n",
    "\n",
    "    test = games_on_day.drop(columns = ['WIN_ONE', 'GAME_DATE'])\n",
    "\n",
    "    model.fit(X,y)\n",
    "    pred = model.predict(test)\n",
    "    correct = np.sum(pred == games_on_day['WIN_ONE'])\n",
    "    games = len(pred)\n",
    "    return correct, games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee16dcb-e4a8-4245-b8e4-81e051854767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing the model by choosing 3 days each season and checking score\n",
    "def test_model(df, model) :\n",
    "    total_correct = total_games = 0\n",
    "\n",
    "    for d in val_set:\n",
    "        correct, games = pred_by_date(df, model, d)\n",
    "\n",
    "        total_correct += correct\n",
    "        total_games += games\n",
    "    return total_correct, total_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16080c40-144f-4745-9d9b-d4b429cbb648",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective='binary:logistic', random_state = 33)\n",
    "correct,games = test_model(model)\n",
    "correct / games\n",
    "\n",
    "# before FE : 0.6298076923076923\n",
    "# didn't include point differential since accuracy is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8aebd-1a13-4d39-a7e1-503eec967d90",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609c627-f25c-4a53-bcc4-8e51b475b336",
   "metadata": {},
   "source": [
    "The average feature importance scores is calculated for the three games for each season using XG Boost built-in feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce81c4-0431-49bb-af42-1e3acfc80164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_by_date_with_importance(model, date):\n",
    "    n = 5 \n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "    X, y = get_training_set(date, n)\n",
    "    # one hot encoding on the Home feature \n",
    "    games_on_day = df[df['GAME_DATE'] == date].copy()\n",
    "    games_on_day['DAYS_SINCE_GAME'] = np.zeros(len(games_on_day))\n",
    "\n",
    "    test = games_on_day.drop(columns = ['WIN_ONE', 'GAME_DATE'])\n",
    "\n",
    "    model.fit(X,y)\n",
    "    pred = model.predict(test)\n",
    "    correct = np.sum(pred == games_on_day['WIN_ONE'])\n",
    "    games = len(pred)\n",
    "    importance_scores = model.get_booster().get_score(importance_type='gain')\n",
    "    return correct, games, importance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a114ef-e7ea-48f4-9eb9-8df973cb1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_with_importance(model) :\n",
    "    \"\"\"\n",
    "    Outputs the average feature importance scores of game predictions\n",
    "    \"\"\"\n",
    "    total_correct = total_games = 0\n",
    "    feature_scores = {}\n",
    "    for t in test:\n",
    "        correct, games, importance_scores = pred_by_date_with_importance(model, t)\n",
    "        \n",
    "        for feature, score in importance_scores.items():\n",
    "            if feature not in feature_scores:\n",
    "                feature_scores[feature] = []\n",
    "            feature_scores[feature].append(score)\n",
    "            \n",
    "\n",
    "        total_correct += correct\n",
    "        total_games += games\n",
    "\n",
    "    average_importance = {features: sum(scores)/len(scores) for features, scores in feature_scores.items()}  \n",
    "    sorted_features = sorted(average_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10a8ee-6096-4371-8dd7-b27b2edb2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective='binary:logistic')\n",
    "importance_scores = test_model_with_importance(model)\n",
    "print(importance_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a819828-a7f5-49e1-a494-3a41dff88335",
   "metadata": {},
   "source": [
    "Testing the model with the feature importance scores by iteratively removing the least important features and comparing the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef51f5e-aa1b-4105-a3f9-610da7bfe9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set_with_features (date, num_seasons, features) :\n",
    "    \"\"\"\n",
    "    Input: Date of games, number of seasons and feature subset to include in dataset\n",
    "    Output: All rows from the last num_seasons and all games in the current season up till the given date\n",
    "    \"\"\"\n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "    data = df[df['SEASON_YEAR'].between(season - num_seasons, season)].copy()\n",
    "    data['DAYS_SINCE_GAME'] = [(date-game_day).days for game_day in data['GAME_DATE']]\n",
    "    data = data[data['DAYS_SINCE_GAME'] > 0]\n",
    "\n",
    "    data = data.sort_values(by = 'DAYS_SINCE_GAME')\n",
    "\n",
    "    X = data[features]\n",
    "    y = data['WIN_ONE']\n",
    "\n",
    "    return (X,y)\n",
    "\n",
    "def pred_by_date_with_features (model, date, features) :\n",
    "    n = 5 \n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "\n",
    "    X, y = get_training_set_with_features(date, n, features)\n",
    "\n",
    "    games_on_day = df[df['GAME_DATE'] == date].copy()\n",
    "    games_on_day['DAYS_SINCE_GAME'] = np.zeros(len(games_on_day))\n",
    "\n",
    "    test = games_on_day[features]\n",
    "    model.fit(X,y)\n",
    "    pred = model.predict(test)\n",
    "    correct = np.sum(pred == games_on_day['WIN_ONE'])\n",
    "    games = len(pred)\n",
    "    return correct, games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b97d1c-1e87-428a-9bf3-06f9f99a1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_with_importance(model, current_features, min_subset_size, top_n) :\n",
    "    \"\"\"\n",
    "    Iterates through the feature importance scores and iteratively remove the least importance features\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # current_features = [f[0] for f in feature_importance]\n",
    "    \n",
    "    while len(current_features) >= min_subset_size:\n",
    "        total_correct = total_games = 0\n",
    "        print(f\"Evaluating with {len(current_features)} features...\")\n",
    "        for t in test:    \n",
    "            correct, games = pred_by_date_with_features(model, t, features = current_features)\n",
    "        \n",
    "            total_correct += correct\n",
    "            total_games += games\n",
    "        print(current_features, ':', total_correct/total_games)\n",
    "        results.append((current_features.copy(), total_correct/total_games))\n",
    "        current_features.pop(-1)\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c115eae-4217-49c6-a0a1-67cd4d393b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective='binary:logistic')\n",
    "sorted_features = [f[0] for f in importance_scores]\n",
    "print(sorted_features)\n",
    "top_subsets = feature_selection_with_importance(model, sorted_features, min_subset_size=20, top_n=10)\n",
    "\n",
    "for i, (subset, acc) in enumerate(top_subsets, 1):\n",
    "    print(f\"#{i}: Features = {subset}, Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15196ee5-051c-460c-8e03-2a90839ee184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best performing feature subset\n",
    "best_feature_subset = top_subsets[0][0]\n",
    "print('Best feature subset: ', best_feature_subset)\n",
    "total_correct = total_games = 0\n",
    "for t in test:\n",
    "    correct, games = pred_by_date_with_features(model, t, best_feature_subset)\n",
    "\n",
    "    total_correct += correct\n",
    "    total_games += games\n",
    "print('Accuracy:', total_correct / total_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021aa82-c054-4cf9-a75d-822827baf620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "# def feature_selection(model, feature_names, min_subset_size, max_subset_size, top_n) :\n",
    "#     \"\"\"\n",
    "#     Iterates through the feature subsets and returns the top n subsets that gives the best scores\n",
    "#     \"\"\"\n",
    "#     print('start')\n",
    "#     results = []\n",
    "#     for n in range(min_subset_size, max_subset_size + 1):\n",
    "#         print(n)\n",
    "#         for subset in combinations(feature_names, n):\n",
    "#             print(subset)\n",
    "#             total_correct = total_games = 0\n",
    "#             for t in test:\n",
    "#                 print('test')\n",
    "#                 correct, games = pred_by_date_with_features(model, t, features = list(subset))\n",
    "        \n",
    "#                 total_correct += correct\n",
    "#                 total_games += games\n",
    "#             print(subset, ':', total_correct/total_games)\n",
    "#             results.append((subset, correct/games))\n",
    "#     results.sort(key=lambda x: x[1], reverse=True)\n",
    "#     return results[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae0524-0f30-49a1-aa25-581150e0e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through every combinations of size 40; takes too long (5+ hours)\n",
    "# model = XGBClassifier(objective='binary:logistic')\n",
    "# all_features = [col for col in df.columns if col not in ['WIN_ONE', 'GAME_DATE', 'SEASON_YEAR']]\n",
    "# top_subsets = feature_selection(model, all_features, min_subset_size=40, max_subset_size=40, top_n=10)\n",
    "\n",
    "# for i, (subset, acc, total) in enumerate(top_subsets, 1):\n",
    "#     print(f\"#{i}: Features = {subset}, Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c35db0f-dfd9-4878-8913-ff46cb83fb49",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162a6dd-8bfe-4f6f-bdeb-909b7bcb9f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_by_date_multiple_models (models_dict, date) :\n",
    "    \"\"\"\n",
    "    Predict the outcome of all games on the given date for all models given. Used specifically to make\n",
    "    cross validation more efficient\n",
    "    \"\"\"\n",
    "    n = 5 # how many years in the past for training\n",
    "    \n",
    "    # determine season of the game\n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "\n",
    "    # get data in relevant time frame\n",
    "    X, y = get_training_set(date, n)\n",
    "\n",
    "    games_on_day = df[df['GAME_DATE'] == date].copy()\n",
    "    games_on_day['DAYS_SINCE_GAME'] = np.zeros(len(games_on_day))\n",
    "\n",
    "    test = games_on_day.drop(columns = ['WIN_ONE', 'GAME_DATE'])\n",
    "\n",
    "    scores = np.zeros(len(models_dict))\n",
    "    for k, v in models_dict.items() :\n",
    "        v.fit(X,y)\n",
    "        pred = v.predict(val_set)\n",
    "        scores[k] = np.sum(pred == games_on_day['WIN_ONE'])\n",
    "    return scores, len(games_on_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024d2de-3105-4756-82cb-a22e0e083d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# XGBoost parameters\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200, 400],\n",
    "    \"eta\": [0.01, 0.05, 0.1, 0.2], # learning_rate\n",
    "    \"max_depth\": [4, 6, 8, 10], # maximum depth of a tree\n",
    "    \"subsample\": [0.5, 0.7, 1], # fraction of observation to be radnomly sampled for each tree\n",
    "    \"colsample_bytree\": [0.5, 0.7, 1], # fraction of columns to be random samples for each tree\n",
    "    \"alpha\": [0.5, 1, 2, 5] # lasso regression\n",
    "}\n",
    "\n",
    "param_dict = {} # store params with key corresponding to index of score in np.array\n",
    "index = 0\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for values in itertools.product(*param_grid.values()):\n",
    "    param_dict[index] = XGBClassifier(objective='binary:logistic', random_state = 33, **dict(zip(param_grid.keys(), values)))\n",
    "    index += 1\n",
    "\n",
    "scores = np.zeros(len(param_dict))\n",
    "total_games = 0\n",
    "\n",
    "first_season = df['SEASON_YEAR'].min()\n",
    "last_season = df['SEASON_YEAR'].max()-4\n",
    "\n",
    "for t in test:\n",
    "    s, g = pred_by_date_multiple_models(param_dict, t)\n",
    "\n",
    "    scores += s\n",
    "    total_games += g\n",
    "    print(scores / total_games)\n",
    "\n",
    "print('final scores: ', scores / total_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a27693-7bba-4722-81f5-d49cd64b6a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_scores = scores / total_games\n",
    "best_model = param_dict[all_scores.argmax()]\n",
    "best_model.get_params() #'n_estimators': 400, eta: 0.01, max_depth: 4, subsample: 0.7, colsample_bytree: 0.7, alpha: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a830931-febe-453a-bd08-44b895bb871a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_five_models = np.argpartition(all_scores, -5)[-5:]\n",
    "top_five_models = top_five_models[np.argsort(-all_scores[top_five_models])]\n",
    "top_five_scores = all_scores[top_five_models]\n",
    "print(top_five_scores)\n",
    "for i in top_five_models : \n",
    "    p = param_dict[i].get_params()\n",
    "    print(f\"n_estimators = {p['n_estimators']}, eta = {p['eta']}, max_depth = {p['max_depth']}, subsample = {p['subsample']}, colsample_bytree = {p['colsample_bytree']}, alpha = {p['alpha']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a4476-ea51-44f9-bb59-70823f83ce8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_model = XGBClassifier(n_estimators = 50, eta = 0.05, max_depth = 4, subsample = 0.5, colsample_bytree = 0.5, alpha = 1)\n",
    "correct, games = test_model(df_rolling, final_model)\n",
    "print(\"Score:\", correct / games)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
