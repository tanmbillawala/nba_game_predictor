{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbd09ee-9206-4948-9ae6-e42e7d20976a",
   "metadata": {},
   "source": [
    "# NBA Game Predictor Model\n",
    "### CMPE 257 Project\n",
    "Authors: Kaushika Uppu, Miranda Billawala, Yun Ei Hlaing, Iris Cheung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f5cbd-6516-49cf-9271-94878f5f9d0c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c030921a-827d-4a1f-af9b-104e618da8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28abb9c-228a-49bb-9721-215d0f183617",
   "metadata": {},
   "source": [
    "## NBA Game Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2dae76-eb39-4b8e-b8c2-9c1cc8d16cca",
   "metadata": {},
   "source": [
    "First, we load in all of the NBA game data from the CSV file. Exact code for gathering data is in a separate file and use the nba_api file. Only games from the 1985-1986 season and afterward are loaded in as the seasons before that are missing a very significant portion of the game statistics' data. We also want to be able to map from team id to abbreviation and back easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "42f17e2e-851c-444d-bdb4-a1b63b594be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>HOME</th>\n",
       "      <th>OPPONENT</th>\n",
       "      <th>WIN</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>...</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>SEASON_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>IND</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>38</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>59</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21</td>\n",
       "      <td>108</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-10</td>\n",
       "      <td>1</td>\n",
       "      <td>NJN</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>44</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26</td>\n",
       "      <td>126</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>52</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22</td>\n",
       "      <td>131</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-05</td>\n",
       "      <td>0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>40</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28</td>\n",
       "      <td>97</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>54</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37</td>\n",
       "      <td>129</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEAM_ID TEAM_ABBREVIATION      TEAM_NAME   GAME_DATE  HOME OPPONENT  WIN  \\\n",
       "0        0               ATL  Atlanta Hawks  1986-04-12     1      IND    1   \n",
       "1        0               ATL  Atlanta Hawks  1986-04-10     1      NJN    1   \n",
       "2        0               ATL  Atlanta Hawks  1986-04-08     1      CHI    1   \n",
       "3        0               ATL  Atlanta Hawks  1986-04-05     0      CHI    0   \n",
       "4        0               ATL  Atlanta Hawks  1986-04-04     0      WAS    0   \n",
       "\n",
       "     MIN  FGM  FGA  ...  DREB  REB  AST  STL  BLK   TOV  PF  PTS  PLUS_MINUS  \\\n",
       "0  240.0   38   88  ...    39   59   22    6    3  12.0  21  108        17.0   \n",
       "1  240.0   44   87  ...    27   42   30   15    5  22.0  26  126         9.0   \n",
       "2  240.0   52   98  ...    25   42   33   13    6  10.0  22  131        13.0   \n",
       "3  240.0   40   76  ...    25   38   17    7    7  21.0  28   97        -5.0   \n",
       "4  265.0   54  100  ...    28   45   24    6    7  14.0  37  129        -6.0   \n",
       "\n",
       "   SEASON_YEAR  \n",
       "0         1985  \n",
       "1         1985  \n",
       "2         1985  \n",
       "3         1985  \n",
       "4         1985  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stats_cleaned = pd.read_csv('all_stats_cleaned.csv')\n",
    "all_stats_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd29527d-1036-4422-b002-364145da7151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89542, 28)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stats_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ba07c67a-bf0d-4553-a46e-d05ffba3f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to datetime object\n",
    "all_stats_cleaned['GAME_DATE'] = pd.to_datetime(all_stats_cleaned['GAME_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1bfbde50-7bdd-478c-b816-96eb9d8beeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_id_to_abb = {} # dictionary to convert from team_id to team_abbreviation\n",
    "team_abb_to_id = {} # dictionary to convert from team_abbreviation to team_id\n",
    "\n",
    "teams = (all_stats_cleaned[['TEAM_ID', 'TEAM_ABBREVIATION']]).drop_duplicates()\n",
    "\n",
    "for index, row in teams.iterrows() :\n",
    "    if row['TEAM_ID'] not in team_id_to_abb.keys():\n",
    "        team_id_to_abb[row['TEAM_ID']] = []\n",
    "    team_id_to_abb[row['TEAM_ID']].append(row['TEAM_ABBREVIATION'])\n",
    "    team_abb_to_id[row['TEAM_ABBREVIATION']] = row['TEAM_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f8db0b-eb67-41f9-8287-676aeed18b2a",
   "metadata": {},
   "source": [
    "### Merging Home and Away Team Stats Into One Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c3044-4f7f-4516-8850-32da043a2f56",
   "metadata": {},
   "source": [
    "Currently, each game is represented by two separate rows in the dataset - one for the home team and one for the away team. To make the data more clear, we decided to combine the two rows into a single row with statistics for both teams. Since predicting with our model will pass one set order of team one and team two (i.e. Lakers as Team One, Warriors as Team Two), we want to make sure that the model realizes games with the Lakers as Team Two and Warriors as Team One are more similar than may appear by the data. To do this, we will duplicate the rows and flip the teams. Then, we will have each game listed twice with the teams flipped. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f167431-5cca-4d38-befc-a7e832eaebdc",
   "metadata": {},
   "source": [
    "Firstly, we split the dataset into two : home games and away games. Then, we performed a join on these two datasets, matching each home team with its corresponding opponent based on the same dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "373a9b9a-9667-4f37-be8c-27b1c74ef6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = all_stats_cleaned[all_stats_cleaned.HOME == 1]\n",
    "away = all_stats_cleaned[all_stats_cleaned.HOME == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "19c8f695-c8b8-423d-b2f1-e6273b6e3284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_stats_home = pd.merge(home, away, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "combined_stats_away = pd.merge(away, home, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "\n",
    "combined_stats = pd.concat([combined_stats_home, combined_stats_away], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f448b5f0-f44c-4957-945d-f57bf5fd5413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM_ID_ONE</th>\n",
       "      <th>TEAM_ABBREVIATION_ONE</th>\n",
       "      <th>TEAM_NAME_ONE</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>HOME_ONE</th>\n",
       "      <th>OPPONENT_ONE</th>\n",
       "      <th>WIN_ONE</th>\n",
       "      <th>MIN_ONE</th>\n",
       "      <th>FGM_ONE</th>\n",
       "      <th>FGA_ONE</th>\n",
       "      <th>...</th>\n",
       "      <th>DREB_TWO</th>\n",
       "      <th>REB_TWO</th>\n",
       "      <th>AST_TWO</th>\n",
       "      <th>STL_TWO</th>\n",
       "      <th>BLK_TWO</th>\n",
       "      <th>TOV_TWO</th>\n",
       "      <th>PF_TWO</th>\n",
       "      <th>PTS_TWO</th>\n",
       "      <th>PLUS_MINUS_TWO</th>\n",
       "      <th>SEASON_YEAR_TWO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>IND</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>38</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33</td>\n",
       "      <td>91</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-10</td>\n",
       "      <td>1</td>\n",
       "      <td>NJN</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>44</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30</td>\n",
       "      <td>117</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>52</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26</td>\n",
       "      <td>118</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>41</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22</td>\n",
       "      <td>91</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-03-29</td>\n",
       "      <td>1</td>\n",
       "      <td>CLE</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>36</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32</td>\n",
       "      <td>123</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEAM_ID_ONE TEAM_ABBREVIATION_ONE  TEAM_NAME_ONE  GAME_DATE  HOME_ONE  \\\n",
       "0            0                   ATL  Atlanta Hawks 1986-04-12         1   \n",
       "1            0                   ATL  Atlanta Hawks 1986-04-10         1   \n",
       "2            0                   ATL  Atlanta Hawks 1986-04-08         1   \n",
       "3            0                   ATL  Atlanta Hawks 1986-04-01         1   \n",
       "4            0                   ATL  Atlanta Hawks 1986-03-29         1   \n",
       "\n",
       "  OPPONENT_ONE  WIN_ONE  MIN_ONE  FGM_ONE  FGA_ONE  ...  DREB_TWO  REB_TWO  \\\n",
       "0          IND        1    240.0       38       88  ...        36       43   \n",
       "1          NJN        1    240.0       44       87  ...        30       44   \n",
       "2          CHI        1    240.0       52       98  ...        35       44   \n",
       "3          WAS        1    240.0       41       90  ...        30       46   \n",
       "4          CLE        0    240.0       36       84  ...        25       33   \n",
       "\n",
       "   AST_TWO  STL_TWO  BLK_TWO  TOV_TWO  PF_TWO  PTS_TWO  PLUS_MINUS_TWO  \\\n",
       "0       22        7        3     13.0      33       91           -17.0   \n",
       "1       25       10        1     24.0      30      117            -9.0   \n",
       "2       29        5        1     17.0      26      118           -13.0   \n",
       "3       19       10        6     17.0      22       91           -16.0   \n",
       "4       31        8        5     16.0      32      123            18.0   \n",
       "\n",
       "   SEASON_YEAR_TWO  \n",
       "0             1985  \n",
       "1             1985  \n",
       "2             1985  \n",
       "3             1985  \n",
       "4             1985  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_stats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cde485-a219-4de4-923f-3815f6bbdb2d",
   "metadata": {},
   "source": [
    "Comparing the number of rows in the combined dataset to the original shows that the dataset row have been reduced by half, as each game is now represented by a single row instead of two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6eadb-8c9e-4edd-bba7-267512d7ee49",
   "metadata": {},
   "source": [
    "After merging the rows, there are some columns that appear twice or are now unneccessary to the dataset. These columns include `MIN_ONE`/`MIN_TWO` (length of game in minutes), `SEASON_YEAR_ONE`/`SEASON_YEAR_TWO`, `OPPONENT_ONE` and `OPPONENT_TWO`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f79796-bfd6-4991-8b7e-d835e758d8ee",
   "metadata": {},
   "source": [
    "We first checked if the `MIN_ONE` and `MIN_TWO` for each row has the same values. As seen below, there are 24 games where the minutes differed slightly. However, since the difference did not seem to be significant, we decided to retain one column and rename it `MIN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "59d683d2-7e36-4979-9e74-54f7457ea220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(48)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(combined_stats['MIN_ONE'] != combined_stats['MIN_TWO']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "66e20896-7388-4ad1-ae28-4557f980c77c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIN_ONE</th>\n",
       "      <th>MIN_TWO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.637333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.906667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.517333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.357667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19857</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.599333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.813333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25946</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.456000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30645</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>52.906667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32173</th>\n",
       "      <td>47.881000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32176</th>\n",
       "      <td>47.700333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32177</th>\n",
       "      <td>47.706667</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32180</th>\n",
       "      <td>52.743333</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32206</th>\n",
       "      <td>47.443333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32208</th>\n",
       "      <td>57.716333</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32209</th>\n",
       "      <td>47.643333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32210</th>\n",
       "      <td>47.703333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32211</th>\n",
       "      <td>47.697000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32213</th>\n",
       "      <td>47.524000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35307</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35337</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.601333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36488</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.399667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38059</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42338</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.808333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57081</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61648</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>57.716333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63216</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.643333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69141</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.443333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73808</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.700333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75405</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.697000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76938</th>\n",
       "      <td>47.448000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76940</th>\n",
       "      <td>47.813333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76941</th>\n",
       "      <td>47.570000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76947</th>\n",
       "      <td>47.906667</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76951</th>\n",
       "      <td>47.517333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76964</th>\n",
       "      <td>47.599333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76965</th>\n",
       "      <td>47.808333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76967</th>\n",
       "      <td>47.456000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76968</th>\n",
       "      <td>47.399667</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76969</th>\n",
       "      <td>47.637333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76970</th>\n",
       "      <td>52.906667</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76972</th>\n",
       "      <td>47.601333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76973</th>\n",
       "      <td>47.707000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76975</th>\n",
       "      <td>47.357667</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78507</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>52.743333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80104</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.703333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82786</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.881000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83945</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.706667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MIN_ONE    MIN_TWO\n",
       "455    48.000000  47.448000\n",
       "3612   48.000000  47.637333\n",
       "6039   48.000000  47.906667\n",
       "7608   48.000000  47.517333\n",
       "12325  48.000000  47.357667\n",
       "19857  48.000000  47.599333\n",
       "24354  48.000000  47.813333\n",
       "25946  48.000000  47.456000\n",
       "30645  53.000000  52.906667\n",
       "32173  47.881000  48.000000\n",
       "32176  47.700333  48.000000\n",
       "32177  47.706667  48.000000\n",
       "32180  52.743333  53.000000\n",
       "32206  47.443333  48.000000\n",
       "32208  57.716333  58.000000\n",
       "32209  47.643333  48.000000\n",
       "32210  47.703333  48.000000\n",
       "32211  47.697000  48.000000\n",
       "32213  47.524000  48.000000\n",
       "35307  48.000000  47.570000\n",
       "35337  48.000000  47.601333\n",
       "36488  48.000000  47.399667\n",
       "38059  48.000000  47.707000\n",
       "42338  48.000000  47.808333\n",
       "57081  48.000000  47.524000\n",
       "61648  58.000000  57.716333\n",
       "63216  48.000000  47.643333\n",
       "69141  48.000000  47.443333\n",
       "73808  48.000000  47.700333\n",
       "75405  48.000000  47.697000\n",
       "76938  47.448000  48.000000\n",
       "76940  47.813333  48.000000\n",
       "76941  47.570000  48.000000\n",
       "76947  47.906667  48.000000\n",
       "76951  47.517333  48.000000\n",
       "76964  47.599333  48.000000\n",
       "76965  47.808333  48.000000\n",
       "76967  47.456000  48.000000\n",
       "76968  47.399667  48.000000\n",
       "76969  47.637333  48.000000\n",
       "76970  52.906667  53.000000\n",
       "76972  47.601333  48.000000\n",
       "76973  47.707000  48.000000\n",
       "76975  47.357667  48.000000\n",
       "78507  53.000000  52.743333\n",
       "80104  48.000000  47.703333\n",
       "82786  48.000000  47.881000\n",
       "83945  48.000000  47.706667"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_stats[combined_stats['MIN_ONE'] != combined_stats['MIN_TWO']][['MIN_ONE','MIN_TWO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1749d449-34c6-4964-af4e-9113a32a9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats = combined_stats.drop(columns = ['MIN_TWO', 'OPPONENT_ONE', 'OPPONENT_TWO', 'SEASON_YEAR_ONE'])\n",
    "combined_stats.rename(columns={'MIN_ONE': 'MIN', 'SEASON_YEAR_TWO': 'SEASON_YEAR'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89436d9-ca4e-49aa-b927-437d58bb4459",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d0f7c-13b5-46e4-b97a-6cde4b4585b5",
   "metadata": {},
   "source": [
    "Features to add : \n",
    "1) Win streak\n",
    "2) Win percentage\n",
    "3) ELO Scores\n",
    "4) EFG%\n",
    "5) TS%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a20f7-6604-4c09-9106-e24b5e23849a",
   "metadata": {},
   "source": [
    "### Win Streak and Win Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54849da8-424f-4e25-aaf5-d9ff3ccc30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_win_streak_and_percentage(df, combined=False):\n",
    "    \"\"\"\n",
    "    Input: Dataframe with team one and team two data for each game and boolean to check if dataframe is combined with both team data\n",
    "    Output: New dataframe with added win streak and win percentage for both teams\n",
    "    \"\"\"\n",
    "    team_date_stats = all_stats_cleaned[['TEAM_ID', 'GAME_DATE', 'WIN']].sort_values(by=['TEAM_ID', 'GAME_DATE']).reset_index(drop=True)\n",
    "    team_date_stats['WIN_STREAK'] = 0\n",
    "    team_date_stats['WIN_PERCENTAGE'] = 0.0\n",
    "    \n",
    "    for team_id, group in team_date_stats.groupby('TEAM_ID'):\n",
    "        streak = 0\n",
    "        wins = 0\n",
    "        total_games = 0\n",
    "        indices = group.index\n",
    "    \n",
    "        for i in range(len(indices)):\n",
    "            idx = indices[i]\n",
    "    \n",
    "            # WIN STREAK\n",
    "            team_date_stats.at[idx, 'WIN_STREAK'] = streak\n",
    "    \n",
    "            if team_date_stats.at[idx, 'WIN'] == 1:\n",
    "                streak += 1\n",
    "            else: \n",
    "                streak = 0\n",
    "    \n",
    "            # WIN PERCENTAGE\n",
    "            if total_games == 0:\n",
    "                team_date_stats.at[idx, 'WIN_PERCENTAGE'] = 0.0\n",
    "            else: \n",
    "                team_date_stats.at[idx, 'WIN_PERCENTAGE'] = wins / total_games\n",
    "    \n",
    "            total_games += 1\n",
    "            if team_date_stats.at[idx, 'WIN'] == 1:\n",
    "                wins += 1\n",
    "\n",
    "    if combined:\n",
    "    # Join Win streak and Win percentage of team one and team two into the merged table\n",
    "        team_date_stats.drop('WIN', axis=1, inplace=True)\n",
    "        df = pd.merge(df, team_date_stats,\n",
    "                              how='left', \n",
    "                              left_on = ['TEAM_ID_ONE', 'GAME_DATE'],\n",
    "                              right_on=['TEAM_ID', 'GAME_DATE'])\n",
    "        df.drop('TEAM_ID', axis=1, inplace=True)\n",
    "        df.rename(columns = {'WIN_STREAK': 'WIN_STREAK_ONE',\n",
    "                                     'WIN_PERCENTAGE': 'WIN_PERCENTAGE_ONE'}, inplace=True)\n",
    "        df = pd.merge(df, team_date_stats,\n",
    "                              how='left', \n",
    "                              left_on = ['TEAM_ID_TWO', 'GAME_DATE'],\n",
    "                              right_on=['TEAM_ID', 'GAME_DATE'])\n",
    "        df.drop('TEAM_ID', axis=1, inplace=True)\n",
    "        df.rename(columns = {'WIN_STREAK': 'WIN_STREAK_TWO',\n",
    "                                     'WIN_PERCENTAGE': 'WIN_PERCENTAGE_TWO'}, inplace=True)\n",
    "    else:\n",
    "        # Join Win streak and Win percentage into the dataframe\n",
    "        team_date_stats.drop('WIN', axis=1, inplace=True)\n",
    "        df = pd.merge(df, team_date_stats,\n",
    "                              how='left', \n",
    "                              on = ['TEAM_ID', 'GAME_DATE'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e014a30-619f-4b87-b757-e444d91b5a9e",
   "metadata": {},
   "source": [
    "### ELO Score Before Current Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6835ead9-c09c-4961-9e78-35c7213cb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_opponent_points(df):\n",
    "    df_opp = df[['TEAM_ABBREVIATION', 'GAME_DATE', 'PTS', 'TEAM_ID']].copy()\n",
    "    merged_df = pd.merge(df, df_opp, \n",
    "                         how='left',\n",
    "                          left_on=['GAME_DATE', 'OPPONENT'],\n",
    "                            right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('', '_OPPONENT'))\n",
    "    merged_df.drop(columns=['TEAM_ABBREVIATION_OPPONENT'], inplace=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "865af94b-e088-4e1b-bf03-a0029008eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elo_score(df, combined=False):\n",
    "    \"\"\"\n",
    "    Input: Dataframe with team one and team two data for each game and boolean to check if dataframe is combined with both team data\n",
    "    Output: New dataframe with elo scores for both teams added \n",
    "    \"\"\"\n",
    "    if combined:\n",
    "        df['GAME_ID'] = df.apply(\n",
    "        lambda row: '_'.join(sorted([str(row['TEAM_ID_ONE']), str(row['TEAM_ID_TWO'])]) + [str(row['GAME_DATE'])]),\n",
    "        axis=1\n",
    "    )\n",
    "        df['ELO_ONE'] = np.nan\n",
    "        df['ELO_TWO'] = np.nan\n",
    "    else:\n",
    "        df = merge_opponent_points(df)\n",
    "        df['ELO'] = np.nan\n",
    "        df['GAME_ID'] = df.apply(\n",
    "        lambda row: '_'.join(sorted([str(row['TEAM_ID']), str(row['TEAM_ID_OPPONENT'])]) + [str(row['GAME_DATE'])]),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    team_elos = {} # to use for checking if a team has appeared and track team last elo scores\n",
    "    team_last_season = {} # to track last seasons of teams\n",
    "    processed_games = set() # to track game id - handle duplicate game columns\n",
    "    elo_map = {} # for faster computation\n",
    "    df = df.sort_values(by='GAME_DATE').reset_index(drop=True)\n",
    "    \n",
    "    for i,row in df.iterrows():\n",
    "        season = row['SEASON_YEAR']\n",
    "        game_id = row['GAME_ID']\n",
    "\n",
    "        if game_id in processed_games:\n",
    "            continue\n",
    "        processed_games.add(game_id)\n",
    "\n",
    "        if combined:\n",
    "            team_one, team_two = row['TEAM_ID_ONE'], row['TEAM_ID_TWO']\n",
    "            points_one, points_two = row['PTS_ONE'], row['PTS_TWO']\n",
    "            home_one = row['HOME_ONE']\n",
    "        \n",
    "            # Season adjustment formula for ELO : New Season ELO = 0.75 * Last Season ELO + 0.25 * Mean ELO, Mean ELO = 1505\n",
    "            for team in [team_one, team_two]:\n",
    "                # check if team has not appeared yet in the dataset\n",
    "                if team not in team_elos:\n",
    "                    team_elos[team] = 1505 \n",
    "                    team_last_season[team] = season\n",
    "                # check for new season, if yes, apply season adjustment\n",
    "                elif team_last_season[team] != season:\n",
    "                    team_elos[team] = 0.75 * team_elos[team] + 0.25 * 1505\n",
    "                    team_last_season[team] = season\n",
    "        \n",
    "            # elo scores before game\n",
    "            elo_one = team_elos[team_one]\n",
    "            elo_two = team_elos[team_two]\n",
    "        \n",
    "            # Add 100 score to home team\n",
    "            if home_one == 1:\n",
    "                elo_one_after_home_adv = elo_one + 100 \n",
    "                elo_two_after_home_adv = elo_two\n",
    "            else:\n",
    "                elo_one_after_home_adv = elo_one \n",
    "                elo_two_after_home_adv = elo_two + 100\n",
    "        \n",
    "            # Expected score of game formula : exp = 1/ (1+10^((ELO two after home advantage - ELO one after home advantage) / 400))\n",
    "            exp = 1/ (1+10**((elo_two_after_home_adv - elo_one_after_home_adv) / 400))\n",
    "        \n",
    "            actual = 1 if points_one > points_two else 0\n",
    "            margin_of_victory = abs(points_one - points_two)\n",
    "        \n",
    "            # Margin of Victory Multiplier formula : ((MOV + 3) ** 0.8) / (7.5 + 0.006 * (Elo team one - Elo team two))\n",
    "            MOVM = ((margin_of_victory + 3) ** 0.8) / (7.5 + 0.006 * (elo_one - elo_two))\n",
    "        \n",
    "            # change in ELO: K * MOVM * (actual - exp), k -> attenuation factor -> higher means elo score adjusts quickly to changes in strength of team\n",
    "            K = 20 # 20 is optimal for nba \n",
    "            change = K * MOVM * (actual - exp)\n",
    "    \n",
    "            # Update data for ELO ratings\n",
    "            team_elos[team_one] += change\n",
    "            team_elos[team_two] -= change\n",
    "        \n",
    "            # store elo score for game id at the table\n",
    "            # df.at[i, 'ELO_ONE'] = elo_one\n",
    "            # df.at[i, 'ELO_TWO'] = elo_two\n",
    "            # df.loc[(df['GAME_ID'] == game_id) & df['TEAM_ID_ONE'] == team_two, 'ELO_ONE'] = elo_two\n",
    "            # df.loc[(df['GAME_ID'] == game_id) & df['TEAM_ID_TWO'] == team_one, 'ELO_TWO'] = elo_one\n",
    "\n",
    "            # store elo scores in dictionary\n",
    "            elo_map[(game_id, team_one, team_two)] = elo_one\n",
    "            elo_map[(game_id, team_two, team_one)] = elo_two\n",
    "     \n",
    "        else:\n",
    "            team, team_opp = row['TEAM_ID'], row['TEAM_ID_OPPONENT']\n",
    "            points_team, points_opp = row['PTS'], row['PTS_OPPONENT']\n",
    "            home = row['HOME']\n",
    "        \n",
    "            # Season adjustment formula for ELO : New Season ELO = 0.75 * Last Season ELO + 0.25 * Mean ELO, Mean ELO = 1505\n",
    "            for t in [team, team_opp]:\n",
    "                # check if team has not appeared yet in the dataset\n",
    "                if t not in team_elos:\n",
    "                    team_elos[t] = 1505 \n",
    "                    team_last_season[t] = season\n",
    "                # check for new season, if yes, apply season adjustment\n",
    "                elif team_last_season[t] != season:\n",
    "                    team_elos[t] = 0.75 * team_elos[t] + 0.25 * 1505\n",
    "                    team_last_season[t] = season\n",
    "        \n",
    "            # elo scores before game\n",
    "            elo_team = team_elos[team]\n",
    "            elo_opponent = team_elos[team_opp]\n",
    "        \n",
    "            # Add 100 score to home team\n",
    "            if home == 1:\n",
    "                elo_team_home = elo_team + 100 \n",
    "                elo_opp_home = elo_opponent\n",
    "            else:\n",
    "                elo_team_home = elo_team \n",
    "                elo_opp_home = elo_opponent + 100\n",
    "        \n",
    "            # Expected score of game formula : exp = 1/ (1+10^((ELO two after home advantage - ELO one after home advantage) / 400))\n",
    "            exp = 1/ (1+10**((elo_opp_home - elo_team_home) / 400))\n",
    "        \n",
    "            actual = 1 if points_team > points_opp else 0\n",
    "            margin_of_victory = abs(points_team - points_opp)\n",
    "        \n",
    "            # Margin of Victory Multiplier formula : ((MOV + 3) ** 0.8) / (7.5 + 0.006 * (Elo team one - Elo team two))\n",
    "            MOVM = ((margin_of_victory + 3) ** 0.8) / (7.5 + 0.006 * (elo_team - elo_opponent))\n",
    "        \n",
    "            # change in ELO: K * MOVM * (actual - exp), k -> attenuation factor -> higher means elo score adjusts quickly to changes in strength of team\n",
    "            K = 20 # 20 is optimal for nba \n",
    "            change = K * MOVM * (actual - exp)\n",
    "\n",
    "            # Update data for ELO ratings\n",
    "            team_elos[team] += change\n",
    "            team_elos[team_opp] -= change\n",
    "        \n",
    "            # store elo score for both row of game at the table\n",
    "            # df.at[i, 'ELO'] = elo_team\n",
    "            # df.loc[(df['GAME_ID'] == game_id) & df['TEAM_ID'] == team_opp, 'ELO'] = elo_opponent\n",
    "            elo_map[(game_id, team)] = elo_team\n",
    "            elo_map[(game_id, team_opp)] = elo_opponent\n",
    "\n",
    "    # add data from elo dictionary into dataframe\n",
    "    if not combined:\n",
    "        df['ELO'] = df.apply(lambda x: elo_map.get((x['GAME_ID'], x['TEAM_ID']), np.nan), axis=1)\n",
    "        df.drop(columns=['PTS_OPPONENT', 'TEAM_ID_OPPONENT'], axis=1, inplace=True)\n",
    "    else: \n",
    "        df['ELO_ONE'] = df.apply(lambda x: elo_map.get((x['GAME_ID'], x['TEAM_ID_ONE'], x['TEAM_ID_TWO']), np.nan), axis=1)\n",
    "        df['ELO_TWO'] = df.apply(lambda x: elo_map.get((x['GAME_ID'], x['TEAM_ID_TWO'], x['TEAM_ID_ONE']), np.nan), axis=1)\n",
    "    df.drop(columns=['GAME_ID'], axis=1, inplace=True)\n",
    "    \n",
    "            \n",
    "    return df                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e79ba04-8bdd-4a9e-9ee7-3b08aca53fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TEAM_ID', 'TEAM_ABBREVIATION', 'TEAM_NAME', 'GAME_DATE', 'HOME',\n",
      "       'OPPONENT', 'WIN', 'MIN', 'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A',\n",
      "       'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL',\n",
      "       'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS', 'SEASON_YEAR', 'WIN_STREAK',\n",
      "       'WIN_PERCENTAGE', 'ELO'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>HOME</th>\n",
       "      <th>OPPONENT</th>\n",
       "      <th>WIN</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>...</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>SEASON_YEAR</th>\n",
       "      <th>WIN_STREAK</th>\n",
       "      <th>WIN_PERCENTAGE</th>\n",
       "      <th>ELO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1985-10-25</td>\n",
       "      <td>1</td>\n",
       "      <td>BOS</td>\n",
       "      <td>1</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30</td>\n",
       "      <td>113</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1505.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1985-10-26</td>\n",
       "      <td>0</td>\n",
       "      <td>IND</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>31</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28</td>\n",
       "      <td>92</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1509.552723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1985-10-29</td>\n",
       "      <td>0</td>\n",
       "      <td>DET</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>40</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39</td>\n",
       "      <td>107</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1494.776564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1985-10-30</td>\n",
       "      <td>1</td>\n",
       "      <td>IND</td>\n",
       "      <td>1</td>\n",
       "      <td>315.0</td>\n",
       "      <td>55</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36</td>\n",
       "      <td>147</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1484.682913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1985-11-01</td>\n",
       "      <td>1</td>\n",
       "      <td>PHL</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>45</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20</td>\n",
       "      <td>106</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1492.848408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TEAM_ID TEAM_ABBREVIATION        TEAM_NAME  GAME_DATE  HOME OPPONENT  WIN  \\\n",
       "0        14               NJN  New Jersey Nets 1985-10-25     1      BOS    1   \n",
       "21       14               NJN  New Jersey Nets 1985-10-26     0      IND    0   \n",
       "54       14               NJN  New Jersey Nets 1985-10-29     0      DET    0   \n",
       "58       14               NJN  New Jersey Nets 1985-10-30     1      IND    1   \n",
       "82       14               NJN  New Jersey Nets 1985-11-01     1      PHL    1   \n",
       "\n",
       "      MIN  FGM  FGA  ...  STL  BLK   TOV  PF  PTS  PLUS_MINUS  SEASON_YEAR  \\\n",
       "0   265.0   44  101  ...   14    3  24.0  30  113         4.0         1985   \n",
       "21  240.0   31   79  ...   10    0  19.0  28   92       -27.0         1985   \n",
       "54  240.0   40   98  ...    6    4  20.0  39  107       -17.0         1985   \n",
       "58  315.0   55  121  ...   14    6  20.0  36  147         9.0         1985   \n",
       "82  240.0   45   86  ...   15    6  21.0  20  106         4.0         1985   \n",
       "\n",
       "    WIN_STREAK  WIN_PERCENTAGE          ELO  \n",
       "0            0        0.000000  1505.000000  \n",
       "21           1        1.000000  1509.552723  \n",
       "54           0        0.500000  1494.776564  \n",
       "58           0        0.333333  1484.682913  \n",
       "82           1        0.500000  1492.848408  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for single team data\n",
    "test_1 = add_win_streak_and_percentage(all_stats_cleaned)\n",
    "test_1 = add_elo_score(test_1)\n",
    "print(test_1.columns)\n",
    "test_1[test_1['TEAM_ID'] == 14].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a7d55a3-2551-4a4d-9951-4fb1f40aa6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM_ID_ONE</th>\n",
       "      <th>TEAM_ABBREVIATION_ONE</th>\n",
       "      <th>TEAM_NAME_ONE</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>HOME_ONE</th>\n",
       "      <th>WIN_ONE</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM_ONE</th>\n",
       "      <th>FGA_ONE</th>\n",
       "      <th>FG_PCT_ONE</th>\n",
       "      <th>...</th>\n",
       "      <th>PF_TWO</th>\n",
       "      <th>PTS_TWO</th>\n",
       "      <th>PLUS_MINUS_TWO</th>\n",
       "      <th>SEASON_YEAR</th>\n",
       "      <th>WIN_STREAK_ONE</th>\n",
       "      <th>WIN_PERCENTAGE_ONE</th>\n",
       "      <th>WIN_STREAK_TWO</th>\n",
       "      <th>WIN_PERCENTAGE_TWO</th>\n",
       "      <th>ELO_ONE</th>\n",
       "      <th>ELO_TWO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1985-10-25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44</td>\n",
       "      <td>101</td>\n",
       "      <td>0.436</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>109</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1505.000000</td>\n",
       "      <td>1505.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1985-10-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>31</td>\n",
       "      <td>79</td>\n",
       "      <td>0.392</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>119</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1509.552723</td>\n",
       "      <td>1505.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1985-10-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>40</td>\n",
       "      <td>98</td>\n",
       "      <td>0.408</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>124</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1494.776564</td>\n",
       "      <td>1504.443525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1985-10-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>315.0</td>\n",
       "      <td>55</td>\n",
       "      <td>121</td>\n",
       "      <td>0.455</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>138</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1484.682913</td>\n",
       "      <td>1519.776159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1985-11-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>45</td>\n",
       "      <td>86</td>\n",
       "      <td>0.523</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>102</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1492.848408</td>\n",
       "      <td>1520.826747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TEAM_ID_ONE TEAM_ABBREVIATION_ONE    TEAM_NAME_ONE  GAME_DATE  HOME_ONE  \\\n",
       "11           14                   NJN  New Jersey Nets 1985-10-25         1   \n",
       "16           14                   NJN  New Jersey Nets 1985-10-26         0   \n",
       "42           14                   NJN  New Jersey Nets 1985-10-29         0   \n",
       "59           14                   NJN  New Jersey Nets 1985-10-30         1   \n",
       "80           14                   NJN  New Jersey Nets 1985-11-01         1   \n",
       "\n",
       "    WIN_ONE    MIN  FGM_ONE  FGA_ONE  FG_PCT_ONE  ...  PF_TWO  PTS_TWO  \\\n",
       "11        1  265.0       44      101       0.436  ...      27      109   \n",
       "16        0  240.0       31       79       0.392  ...      27      119   \n",
       "42        0  240.0       40       98       0.408  ...      34      124   \n",
       "59        1  315.0       55      121       0.455  ...      35      138   \n",
       "80        1  240.0       45       86       0.523  ...      20      102   \n",
       "\n",
       "    PLUS_MINUS_TWO  SEASON_YEAR  WIN_STREAK_ONE  WIN_PERCENTAGE_ONE  \\\n",
       "11            -4.0         1985               0            0.000000   \n",
       "16            27.0         1985               1            1.000000   \n",
       "42            17.0         1985               0            0.500000   \n",
       "59            -9.0         1985               0            0.333333   \n",
       "80            -4.0         1985               1            0.500000   \n",
       "\n",
       "    WIN_STREAK_TWO  WIN_PERCENTAGE_TWO      ELO_ONE      ELO_TWO  \n",
       "11               0            0.000000  1505.000000  1505.000000  \n",
       "16               0            0.000000  1509.552723  1505.000000  \n",
       "42               0            0.500000  1494.776564  1504.443525  \n",
       "59               1            1.000000  1484.682913  1519.776159  \n",
       "80               1            0.666667  1492.848408  1520.826747  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for combined team and opponent data\n",
    "test_2 = add_win_streak_and_percentage(combined_stats, True)\n",
    "test_2 = add_elo_score(test_2, True)\n",
    "test_2[test_2['TEAM_ID_ONE'] == 14].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d137f-3bc0-43e8-879b-c9bc2d9f6c2e",
   "metadata": {},
   "source": [
    "### Effective Field Goal Percentage and True Shooting Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb2c4746-bd69-4cb4-94fe-e60c5305b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shooting_percentages(df, combined=False):\n",
    "    if combined: \n",
    "        df['EFG%_ONE'] = (df['FGM_ONE'] + 1.5 * df['FG3M_ONE']) / df['FGA_ONE']\n",
    "        df['EFG%_TWO'] = (df['FGM_TWO'] + 1.5 * df['FG3M_TWO']) / df['FGA_TWO']\n",
    "        df['TS%_ONE'] = df['PTS_ONE'] / (2 * (df['FGA_ONE'] + 0.44 * df['FTA_ONE']))\n",
    "        df['TS%_TWO'] = df['PTS_TWO'] / (2 * (df['FGA_TWO'] + 0.44 * df['FTA_TWO']))\n",
    "    else:\n",
    "        df['EFG%'] = (df['FGM'] + 1.5 * df['FG3M']) / df['FGA']\n",
    "        df['TS%'] = df['PTS'] / (2 * (df['FGA'] + 0.44 * df['FTA']))\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00c976-ab01-41a6-b666-66e189e26c6b",
   "metadata": {},
   "source": [
    "### Point Differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6763f10a-955f-43d1-b952-33eaecf5f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_point_differential(df, window = 5, combined=False):\n",
    "        #  add opponent points to all_stats_cleaned table\n",
    "    #for team_id in all_stats_cleaned['TEAM_ID'].unique() :\n",
    "    #    team_data = all_stats_cleaned[all_stats_cleaned['TEAM_ID'] == team_id].sort_values(by='GAME_DATE')\n",
    "    #    for col in cols :\n",
    "    #        shift = team_data[col].shift(1)\n",
    "    #        team_data[col] = shift.rolling(window = n).mean()\n",
    "    #    if result is None :\n",
    "    #        result = team_data\n",
    "    #    else :\n",
    "    #        result = pd.concat([result, team_data])\n",
    "    \n",
    "    \n",
    "    if combined:\n",
    "        df['PTS_DIFF_ONE'] = df['PTS_ONE'] - df['PTS_TWO']\n",
    "        df['PTS_DIFF_TWO'] = df['PTS_TWO'] - df['PTS_ONE']\n",
    "    else:\n",
    "        df = merge_opponent_points(df)\n",
    "        df['PTS_DIFF'] = df['PTS'] - df['PTS_OPPONENT']\n",
    "        df.drop(columns=['PTS_OPPONENT', 'TEAM_ID_OPPONENT'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f693e-e6da-44e5-8a60-28bf24d618d8",
   "metadata": {},
   "source": [
    "### Win for Last Matchup Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f5764ba-ac0d-4209-9965-470f0ebd5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_win_last_game(df, combined=False):\n",
    "    if combined:\n",
    "        sorted_df = df.sort_values(by=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'])\n",
    "        sorted_df['WIN_LAST_ONE'] = sorted_df.groupby(['TEAM_ID_ONE', 'TEAM_ID_TWO'])['WIN_ONE'].shift(1)\n",
    "        sorted_df['WIN_LAST_TWO'] = sorted_df.groupby(['TEAM_ID_ONE', 'TEAM_ID_TWO'])['WIN_TWO'].shift(1)\n",
    "        df = df.merge(sorted_df[['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE', 'WIN_LAST_ONE', 'WIN_LAST_TWO']],\n",
    "                      on=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'],\n",
    "                      how = 'left')\n",
    "    else:\n",
    "        sorted_df = df.sort_values(by=['TEAM_ID', 'OPPONENT', 'GAME_DATE'])\n",
    "        sorted_df['WIN_LAST'] = sorted_df.groupby(['TEAM_ID', 'OPPONENT'])['WIN'].shift(1)\n",
    "        df = df.merge(sorted_df[['TEAM_ID', 'OPPONENT', 'GAME_DATE', 'WIN_LAST']],\n",
    "                      on=['TEAM_ID', 'OPPONENT', 'GAME_DATE'],\n",
    "                      how = 'left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2917da54-7a54-41ba-8c7a-fb56695c400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TEAM_ID', 'TEAM_ABBREVIATION', 'TEAM_NAME', 'GAME_DATE', 'HOME',\n",
      "       'OPPONENT', 'WIN', 'MIN', 'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A',\n",
      "       'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL',\n",
      "       'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS', 'SEASON_YEAR', 'WIN_LAST'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>HOME</th>\n",
       "      <th>OPPONENT</th>\n",
       "      <th>WIN</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>...</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>SEASON_YEAR</th>\n",
       "      <th>WIN_LAST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41935</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1985-10-25</td>\n",
       "      <td>1</td>\n",
       "      <td>BOS</td>\n",
       "      <td>1</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30</td>\n",
       "      <td>113</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41916</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1985-12-04</td>\n",
       "      <td>1</td>\n",
       "      <td>BOS</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>46</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22</td>\n",
       "      <td>111</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41902</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1986-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>50</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19</td>\n",
       "      <td>117</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41860</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1986-03-30</td>\n",
       "      <td>0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>49</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22</td>\n",
       "      <td>117</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41856</th>\n",
       "      <td>14</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>1986-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>BOS</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>41</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22</td>\n",
       "      <td>108</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TEAM_ID TEAM_ABBREVIATION        TEAM_NAME  GAME_DATE  HOME OPPONENT  \\\n",
       "41935       14               NJN  New Jersey Nets 1985-10-25     1      BOS   \n",
       "41916       14               NJN  New Jersey Nets 1985-12-04     1      BOS   \n",
       "41902       14               NJN  New Jersey Nets 1986-01-03     0      BOS   \n",
       "41860       14               NJN  New Jersey Nets 1986-03-30     0      BOS   \n",
       "41856       14               NJN  New Jersey Nets 1986-04-09     1      BOS   \n",
       "\n",
       "       WIN    MIN  FGM  FGA  ...  REB  AST  STL  BLK   TOV  PF  PTS  \\\n",
       "41935    1  265.0   44  101  ...   52   17   14    3  24.0  30  113   \n",
       "41916    0  240.0   46   91  ...   38   23   10    1  21.0  22  111   \n",
       "41902    0  240.0   50   96  ...   43   34    9    5  20.0  19  117   \n",
       "41860    0  240.0   49  100  ...   49   32   10    2  13.0  22  117   \n",
       "41856    1  240.0   41   95  ...   57   20    9    1  10.0  22  108   \n",
       "\n",
       "       PLUS_MINUS  SEASON_YEAR  WIN_LAST  \n",
       "41935         4.0         1985       NaN  \n",
       "41916       -19.0         1985       1.0  \n",
       "41902       -12.0         1985       0.0  \n",
       "41860        -5.0         1985       0.0  \n",
       "41856        10.0         1985       0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "test_4 = add_win_last_game(all_stats_cleaned)\n",
    "print(test_4.columns)\n",
    "test_4[(test_4['TEAM_ID'] == 14) & (test_4['OPPONENT'] == 'BOS')].sort_values(by='GAME_DATE').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7accc128-6ab8-428f-a434-f7132d710372",
   "metadata": {},
   "source": [
    "## Building Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc546d-dc67-4a39-bc03-15ac864d31b5",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "Since our data follows a time-series format, we are implementing a different method of testing as follows:\n",
    "1. Save the last 4 years of games as a test set.\n",
    "2. Choose a few days from each season, except the last four, for our validation set.\n",
    "3. Run a GridSearchCV for each day of validation games to find best parameters.\n",
    "4. Test the model with best parameters on the test set.\n",
    "\n",
    "We need to retrain the model for each different day we test because we input into the model the number of days since a game occurred as a way to convert the timestamp into a numerical variable that is understandable to the model. \n",
    "\n",
    "For validating and choosing proper parameters, we will test on three days from each season: beginning, after the trade-deadline (middle), and near playoffs. This way, we can see how the model handles different times of the season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a044cf0-6065-4397-99a9-0aeb1a798565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_set (first_season, last_season, n = 1) :\n",
    "    dates = []\n",
    "    for season in range(first_season, last_season) :\n",
    "        season_data = all_stats_cleaned[all_stats_cleaned['SEASON_YEAR'] == season]\n",
    "        start_date = season_data['GAME_DATE'].min()\n",
    "        end_date = season_data['GAME_DATE'].max()\n",
    "\n",
    "        # day around the beginning of the season\n",
    "        beg = season_data[season_data['GAME_DATE'].between(start_date, start_date + timedelta(weeks = 4))]\n",
    "\n",
    "        # day around trade deadline (after about 2/3 of the season)\n",
    "        delta = round((2/3)*(end_date-start_date).days)\n",
    "        approx_deadline = start_date + timedelta(days = delta)\n",
    "        mid = season_data[season_data['GAME_DATE'].between(approx_deadline, approx_deadline + timedelta(weeks = 4))]\n",
    "        \n",
    "        # day around the end of the season\n",
    "        end = season_data[season_data['GAME_DATE'].between(end_date - timedelta(weeks = 4), end_date)]\n",
    "\n",
    "        dates.extend(list(pd.concat([beg.sample(n)['GAME_DATE'], mid.sample(n)['GAME_DATE'], end.sample(n)['GAME_DATE']])))\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3eb2ee46-f9f8-4d26-9e53-5d7996f97182",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_season = all_stats_cleaned['SEASON_YEAR'].min() + 1\n",
    "last_season = all_stats_cleaned['SEASON_YEAR'].max() - 4\n",
    "val_set = get_val_set(first_season, last_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f5829c-b7b8-4af1-aa40-18ce24556674",
   "metadata": {},
   "source": [
    "We attempt two different methods for predicting game statistics. As a baseline, we use a regular rolling window. Then, we implement a model which predicts a team's statistics. We use both of these values to test an outcome predictor model after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a07e48fa-aa5b-46c1-8dd5-0ad3546a43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added shooting percentage\n",
    "all_stats_cleaned = add_shooting_percentages(all_stats_cleaned)\n",
    "# added win streak and win percentage\n",
    "all_stats_cleaned = add_win_streak_and_percentage(all_stats_cleaned)\n",
    "# added ELO score\n",
    "all_stats_cleaned = add_elo_score(all_stats_cleaned)\n",
    "# added point differential\n",
    "# all_stats_cleaned = add_point_differential(all_stats_cleaned)\n",
    "# added win for last game\n",
    "all_stats_cleaned = add_win_last_game(all_stats_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a59bdf1e-4808-4599-a5d0-7f9f2155fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(n, cols) :\n",
    "    pred = None\n",
    "    for team_id in all_stats_cleaned['TEAM_ID'].unique() :\n",
    "        team_data = all_stats_cleaned[all_stats_cleaned['TEAM_ID'] == team_id].sort_values(by='GAME_DATE')\n",
    "        for col in cols :\n",
    "            shift = team_data[col].shift(1)\n",
    "            team_data[col] = shift.rolling(window = n).mean()\n",
    "        if pred is None :\n",
    "            pred = team_data\n",
    "        else :\n",
    "            pred = pd.concat([pred, team_data])\n",
    "    pred = pred.dropna(axis = 0)\n",
    "\n",
    "    home = pred[pred['HOME'] == 1]\n",
    "    away = pred[pred['HOME'] == 0]\n",
    "\n",
    "    combined_pred_stats_home = pd.merge(home, away, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "    combined_pred_stats_away = pd.merge(away, home, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "\n",
    "    combined_pred_stats = pd.concat([combined_pred_stats_home, combined_pred_stats_away], ignore_index = True)\n",
    "    combined_pred_stats.rename(columns={'MIN_ONE': 'MIN', 'SEASON_YEAR_TWO': 'SEASON_YEAR'}, inplace=True)\n",
    "    combined_pred_stats = combined_pred_stats.drop(columns = ['MIN_TWO', 'OPPONENT_ONE', 'OPPONENT_TWO', 'SEASON_YEAR_ONE', \n",
    "                                                              'TEAM_ABBREVIATION_ONE', 'TEAM_NAME_ONE', 'MIN', 'FGM_ONE', \n",
    "                                                              'FGA_ONE', 'FG3M_ONE', 'FG3A_ONE', 'FTM_ONE', 'FTA_ONE', 'PTS_ONE', \n",
    "                                                              'PLUS_MINUS_ONE', 'TEAM_ABBREVIATION_TWO', 'TEAM_NAME_TWO', 'HOME_TWO',\n",
    "                                                              'WIN_TWO', 'FGM_TWO', 'FGA_TWO', 'FG3M_TWO', 'FG3A_TWO', 'FTM_TWO', \n",
    "                                                              'FTA_TWO', 'PTS_TWO', 'PLUS_MINUS_TWO'])\n",
    "\n",
    "    return combined_pred_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57f63bd-ac90-4416-9ce4-116cc772b48e",
   "metadata": {},
   "source": [
    "### Rolling Window Statistics (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0593ec6f-a148-48f7-b768-f13759e6949a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM_ID_ONE</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>HOME_ONE</th>\n",
       "      <th>WIN_ONE</th>\n",
       "      <th>FG_PCT_ONE</th>\n",
       "      <th>FG3_PCT_ONE</th>\n",
       "      <th>FT_PCT_ONE</th>\n",
       "      <th>OREB_ONE</th>\n",
       "      <th>DREB_ONE</th>\n",
       "      <th>REB_ONE</th>\n",
       "      <th>...</th>\n",
       "      <th>BLK_TWO</th>\n",
       "      <th>TOV_TWO</th>\n",
       "      <th>PF_TWO</th>\n",
       "      <th>SEASON_YEAR</th>\n",
       "      <th>EFG%_TWO</th>\n",
       "      <th>TS%_TWO</th>\n",
       "      <th>WIN_STREAK_TWO</th>\n",
       "      <th>WIN_PERCENTAGE_TWO</th>\n",
       "      <th>ELO_TWO</th>\n",
       "      <th>WIN_LAST_TWO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>1985-11-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4770</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7348</td>\n",
       "      <td>14.6</td>\n",
       "      <td>34.2</td>\n",
       "      <td>48.8</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>29.4</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.540427</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1555.712573</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>1985-11-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7618</td>\n",
       "      <td>13.6</td>\n",
       "      <td>26.8</td>\n",
       "      <td>40.4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.496664</td>\n",
       "      <td>0.539412</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1485.199131</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>1985-12-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5022</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7216</td>\n",
       "      <td>12.4</td>\n",
       "      <td>29.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>17.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.509258</td>\n",
       "      <td>0.563030</td>\n",
       "      <td>8</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1616.849213</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>1985-12-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>13.2</td>\n",
       "      <td>29.6</td>\n",
       "      <td>42.8</td>\n",
       "      <td>...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>18.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.492694</td>\n",
       "      <td>0.542552</td>\n",
       "      <td>1</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1522.946580</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1985-12-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4842</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7518</td>\n",
       "      <td>12.8</td>\n",
       "      <td>31.2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>28.2</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.497839</td>\n",
       "      <td>0.545260</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1428.104711</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEAM_ID_ONE  GAME_DATE  HOME_ONE  WIN_ONE  FG_PCT_ONE  FG3_PCT_ONE  \\\n",
       "0           14 1985-11-09         1        1      0.4770          0.4   \n",
       "1           14 1985-11-27         1        0      0.5222          0.4   \n",
       "2           14 1985-12-04         1        0      0.5022          0.3   \n",
       "3           14 1985-12-07         1        1      0.4696          0.3   \n",
       "4           14 1985-12-10         1        1      0.4842          0.2   \n",
       "\n",
       "   FT_PCT_ONE  OREB_ONE  DREB_ONE  REB_ONE  ...  BLK_TWO  TOV_TWO  PF_TWO  \\\n",
       "0      0.7348      14.6      34.2     48.8  ...      5.0     20.6    29.4   \n",
       "1      0.7618      13.6      26.8     40.4  ...      5.0     17.2    20.8   \n",
       "2      0.7216      12.4      29.6     42.0  ...      7.6     17.2    22.0   \n",
       "3      0.7154      13.2      29.6     42.8  ...      5.8     18.2    22.8   \n",
       "4      0.7518      12.8      31.2     44.0  ...      3.2     19.8    28.2   \n",
       "\n",
       "   SEASON_YEAR  EFG%_TWO   TS%_TWO  WIN_STREAK_TWO  WIN_PERCENTAGE_TWO  \\\n",
       "0         1985  0.512000  0.540427               4            0.750000   \n",
       "1         1985  0.496664  0.539412               0            0.428571   \n",
       "2         1985  0.509258  0.563030               8            0.888889   \n",
       "3         1985  0.492694  0.542552               1            0.565217   \n",
       "4         1985  0.497839  0.545260               0            0.333333   \n",
       "\n",
       "       ELO_TWO  WIN_LAST_TWO  \n",
       "0  1555.712573           1.0  \n",
       "1  1485.199131           0.0  \n",
       "2  1616.849213           0.0  \n",
       "3  1522.946580           0.0  \n",
       "4  1428.104711           0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['FG_PCT', 'FG3_PCT', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'EFG%', 'TS%']\n",
    "combined_pred_stats = rolling_window(5, cols)\n",
    "combined_pred_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deef007-5859-40a0-8fb3-a6b6b093dc1f",
   "metadata": {},
   "source": [
    "### Predicting Using ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93f5b240-0232-4634-bde4-e9e16bbe02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get actual stats\n",
    "combined_stats_training = add_shooting_percentages(combined_stats, combined = True)\n",
    "combined_stats_training = combined_stats[['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE', 'FG_PCT_ONE',\n",
    "                                          'FG3_PCT_ONE','FT_PCT_ONE', 'OREB_ONE', 'DREB_ONE', 'REB_ONE',\n",
    "                                          'AST_ONE', 'STL_ONE', 'BLK_ONE', 'TOV_ONE', 'PF_ONE', 'EFG%_ONE', 'TS%_ONE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d4c29ad-1005-4391-abd8-6d8f512f19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rolling window stats\n",
    "cols = ['FG_PCT', 'FG3_PCT', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'EFG%', 'TS%']\n",
    "rolling_stats_training = rolling_window(10, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "856efbbe-221c-4fc8-babf-7607c3039029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine \n",
    "model_training_set = pd.merge(rolling_stats_training, combined_stats_training, \n",
    "                          left_on=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'], \n",
    "                          right_on=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'],\n",
    "                          suffixes=('_PRED', '_ACT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "eb949716-047f-43d1-b30a-ee6484b2e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_cols = ['FG_PCT_ONE_ACT', 'FG3_PCT_ONE_ACT', 'FT_PCT_ONE_ACT', 'OREB_ONE_ACT', 'DREB_ONE_ACT', \n",
    "                'REB_ONE_ACT','AST_ONE_ACT', 'STL_ONE_ACT', 'BLK_ONE_ACT', 'TOV_ONE_ACT', \n",
    "                'PF_ONE_ACT', 'EFG%_ONE_ACT', 'TS%_ONE_ACT'] \n",
    "\n",
    "def train_model(df, team_id, game_date, model_params = None):\n",
    "    \"\"\"\n",
    "    Trains a model to predict team stats for a given game using past rolling averages of both teams.\n",
    "    Features: past performance of TEAM_ONE and TEAM_TWO.\n",
    "    Targets: actual stats of TEAM_ONE in the current game.\n",
    "    \"\"\"\n",
    "    df = df[(df['GAME_DATE'] < game_date) & (df['TEAM_ID_ONE'] == team_id)]\n",
    "    X = df.drop(columns = act_cols+['GAME_DATE'])\n",
    "\n",
    "    # fitting a XGBoost model for each stat\n",
    "    models = {}\n",
    "    for col in act_cols:\n",
    "        y = df[col]\n",
    "        if model_params is None :\n",
    "            model = XGBRegressor(n_estimators = 100, random_state = 33)\n",
    "        else :\n",
    "            model = XGBRegressor(**model_params[col], random_state = 33)\n",
    "        model.fit(X, y)\n",
    "        models[col] = model\n",
    "\n",
    "    return models\n",
    "\n",
    "def predict_game_stats(df, team_id, game_date, model_params = None) :\n",
    "    \"\"\"\n",
    "    Predicts the statistics for given game.\n",
    "    \"\"\"\n",
    "    df = pd.get_dummies(df, columns=['TEAM_ID_TWO'], drop_first=True)\n",
    "    if model_params is None :\n",
    "        models = train_model(df, team_id, game_date)\n",
    "    else :\n",
    "        models = train_model(df, team_id, game_date, model_params)\n",
    "\n",
    "    pred = df[(df['GAME_DATE'] == game_date) & (df['TEAM_ID_ONE'] == team_id)].drop(columns = act_cols+['GAME_DATE'])\n",
    "    \n",
    "    prediction = {}\n",
    "    for stat, model in models.items():\n",
    "        prediction[stat] = model.predict(pred)[0]\n",
    "   \n",
    "    return prediction\n",
    "\n",
    "def evaluate_stats_model(df, test_set, model_params = None):\n",
    "    \"\"\"\n",
    "    Evaluates predicting stats model by testing on last `test_seasons` seasons using RMSE.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    for day in test_set :\n",
    "        print(\"Predicting...\", day)\n",
    "        games_on_day = df[df['GAME_DATE'] == day]\n",
    "        for index, row in games_on_day.iterrows() :\n",
    "            if model_params is None :\n",
    "                pred = predict_game_stats(df, row['TEAM_ID_ONE'], day)\n",
    "            else :\n",
    "                pred = predict_game_stats(df, row['TEAM_ID_ONE'], day, model_params)\n",
    "            pred = [pred[col] for col in act_cols]\n",
    "            act = [row[col] for col in act_cols]\n",
    "            predictions.append(pred)\n",
    "            actuals.append(act)\n",
    "\n",
    "    # evaluating model's predictions\n",
    "    y_true = np.array(actuals)\n",
    "    y_pred = np.array(predictions)\n",
    "    total_rmse = np.sqrt(mean_squared_error(y_true.flatten(), y_pred.flatten()))\n",
    "    return total_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "426780d5-531f-4f00-9311-33a0376d8fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting... 1986-11-01 00:00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[173]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rmse = \u001b[43mevaluate_stats_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_training_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[172]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mevaluate_stats_model\u001b[39m\u001b[34m(df, test_set, model_params)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m games_on_day.iterrows() :\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m :\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m         pred = \u001b[43mpredict_game_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTEAM_ID_ONE\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[32m     59\u001b[39m         pred = predict_game_stats(df, row[\u001b[33m'\u001b[39m\u001b[33mTEAM_ID_ONE\u001b[39m\u001b[33m'\u001b[39m], day, model_params)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[172]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mpredict_game_stats\u001b[39m\u001b[34m(df, team_id, game_date, model_params)\u001b[39m\n\u001b[32m     31\u001b[39m df = pd.get_dummies(df, columns=[\u001b[33m'\u001b[39m\u001b[33mTEAM_ID_TWO\u001b[39m\u001b[33m'\u001b[39m], drop_first=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m :\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     models = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteam_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[32m     35\u001b[39m     models = train_model(df, team_id, game_date, model_params)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[172]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(df, team_id, game_date, model_params)\u001b[39m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[32m     21\u001b[39m         model = XGBRegressor(**model_params[col], random_state = \u001b[32m33\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     models[col] = model\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1247\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:184\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    182\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    183\u001b[39m     bst.update(dtrain, iteration=i, fobj=obj)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    187\u001b[39m bst = cb_container.after_training(bst)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\callback.py:264\u001b[39m, in \u001b[36mCallbackContainer.after_iteration\u001b[39m\u001b[34m(self, model, epoch, dtrain, evals)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m name.find(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m) == -\u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDataset name should not contain `-`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m score: \u001b[38;5;28mstr\u001b[39m = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_output_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m metric_score = _parse_eval_str(score)\n\u001b[32m    266\u001b[39m \u001b[38;5;28mself\u001b[39m._update_history(metric_score, epoch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2353\u001b[39m, in \u001b[36mBooster.eval_set\u001b[39m\u001b[34m(self, evals, iteration, feval, output_margin)\u001b[39m\n\u001b[32m   2350\u001b[39m evnames = c_array(ctypes.c_char_p, [c_str(d[\u001b[32m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m evals])\n\u001b[32m   2351\u001b[39m msg = ctypes.c_char_p()\n\u001b[32m   2352\u001b[39m _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2353\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterEvalOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2354\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2355\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mc_bst_ulong\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2360\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2361\u001b[39m )\n\u001b[32m   2362\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m msg.value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2363\u001b[39m res = msg.value.decode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rmse = evaluate_stats_model(model_training_set, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "edc97e59-3df7-461a-ae5e-dbd999d9a347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.7292723986015033)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse # np.float64(3.7292723986015033)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c890aa-a66f-41aa-92f0-8bddb088e6a5",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "To perform hyperparameter tuning, we are going to look at only a small subset of the validation set since each game to be predicted requires fitting a number of different models. For computational efficiency, we are going to make the validation subset include only dates from 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "590aca16-2129-4559-93fc-4d5a7894d05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2018-02-24 00:00:00'),\n",
       " Timestamp('2018-03-15 00:00:00'),\n",
       " Timestamp('2018-11-08 00:00:00')]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test_set = [d for d in val_set if d.year == 2018]\n",
    "param_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "41069b5f-c3fd-4cc1-be67-962dbae294b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hyperparameter_tuning (df, params, test_set) :\n",
    "    index = 1\n",
    "    param_perf = None\n",
    "    for p in params :\n",
    "        print(f\"Iteration {index} / {len(params)}\")\n",
    "        predictions = None \n",
    "        actual = None\n",
    "        for day in test_set :\n",
    "            games_on_day = df[df['GAME_DATE'] == day]\n",
    "            for _, row in games_on_day.iterrows() :\n",
    "                model_params = {col : p for col in act_cols}\n",
    "                pred = pd.DataFrame([predict_game_stats(df, row['TEAM_ID_ONE'], day, model_params)])\n",
    "                act = pd.DataFrame([{col : row[col] for col in act_cols}])\n",
    "                predictions = pred if predictions is None else pd.concat([predictions, pred], ignore_index = True)\n",
    "                actual = act if predictions is None else pd.concat([actual, act], ignore_index = True)\n",
    "\n",
    "        scores = {'params': p}\n",
    "        for col in act_cols :\n",
    "            scores[col] = np.sqrt(mean_squared_error(predictions[col], actual[col]))\n",
    "        scores = pd.DataFrame([scores])\n",
    "        param_perf = scores if param_perf is None else pd.concat([param_perf, scores], ignore_index = True)\n",
    "        index += 1\n",
    "\n",
    "    best_params = {}\n",
    "    for col in act_cols :\n",
    "        best_params[col] = param_perf.loc[param_perf[col].idxmin(), 'params']\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6a458b16-6bed-4605-aebf-d4c335f1bdb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 / 243\n",
      "Iteration 2 / 243\n",
      "Iteration 3 / 243\n",
      "Iteration 4 / 243\n",
      "Iteration 5 / 243\n",
      "Iteration 6 / 243\n",
      "Iteration 7 / 243\n",
      "Iteration 8 / 243\n",
      "Iteration 9 / 243\n",
      "Iteration 10 / 243\n",
      "Iteration 11 / 243\n",
      "Iteration 12 / 243\n",
      "Iteration 13 / 243\n",
      "Iteration 14 / 243\n",
      "Iteration 15 / 243\n",
      "Iteration 16 / 243\n",
      "Iteration 17 / 243\n",
      "Iteration 18 / 243\n",
      "Iteration 19 / 243\n",
      "Iteration 20 / 243\n",
      "Iteration 21 / 243\n",
      "Iteration 22 / 243\n",
      "Iteration 23 / 243\n",
      "Iteration 24 / 243\n",
      "Iteration 25 / 243\n",
      "Iteration 26 / 243\n",
      "Iteration 27 / 243\n",
      "Iteration 28 / 243\n",
      "Iteration 29 / 243\n",
      "Iteration 30 / 243\n",
      "Iteration 31 / 243\n",
      "Iteration 32 / 243\n",
      "Iteration 33 / 243\n",
      "Iteration 34 / 243\n",
      "Iteration 35 / 243\n",
      "Iteration 36 / 243\n",
      "Iteration 37 / 243\n",
      "Iteration 38 / 243\n",
      "Iteration 39 / 243\n",
      "Iteration 40 / 243\n",
      "Iteration 41 / 243\n",
      "Iteration 42 / 243\n",
      "Iteration 43 / 243\n",
      "Iteration 44 / 243\n",
      "Iteration 45 / 243\n",
      "Iteration 46 / 243\n",
      "Iteration 47 / 243\n",
      "Iteration 48 / 243\n",
      "Iteration 49 / 243\n",
      "Iteration 50 / 243\n",
      "Iteration 51 / 243\n",
      "Iteration 52 / 243\n",
      "Iteration 53 / 243\n",
      "Iteration 54 / 243\n",
      "Iteration 55 / 243\n",
      "Iteration 56 / 243\n",
      "Iteration 57 / 243\n",
      "Iteration 58 / 243\n",
      "Iteration 59 / 243\n",
      "Iteration 60 / 243\n",
      "Iteration 61 / 243\n",
      "Iteration 62 / 243\n",
      "Iteration 63 / 243\n",
      "Iteration 64 / 243\n",
      "Iteration 65 / 243\n",
      "Iteration 66 / 243\n",
      "Iteration 67 / 243\n",
      "Iteration 68 / 243\n",
      "Iteration 69 / 243\n",
      "Iteration 70 / 243\n",
      "Iteration 71 / 243\n",
      "Iteration 72 / 243\n",
      "Iteration 73 / 243\n",
      "Iteration 74 / 243\n",
      "Iteration 75 / 243\n",
      "Iteration 76 / 243\n",
      "Iteration 77 / 243\n",
      "Iteration 78 / 243\n",
      "Iteration 79 / 243\n",
      "Iteration 80 / 243\n",
      "Iteration 81 / 243\n",
      "Iteration 82 / 243\n",
      "Iteration 83 / 243\n",
      "Iteration 84 / 243\n",
      "Iteration 85 / 243\n",
      "Iteration 86 / 243\n",
      "Iteration 87 / 243\n",
      "Iteration 88 / 243\n",
      "Iteration 89 / 243\n",
      "Iteration 90 / 243\n",
      "Iteration 91 / 243\n",
      "Iteration 92 / 243\n",
      "Iteration 93 / 243\n",
      "Iteration 94 / 243\n",
      "Iteration 95 / 243\n",
      "Iteration 96 / 243\n",
      "Iteration 97 / 243\n",
      "Iteration 98 / 243\n",
      "Iteration 99 / 243\n",
      "Iteration 100 / 243\n",
      "Iteration 101 / 243\n",
      "Iteration 102 / 243\n",
      "Iteration 103 / 243\n",
      "Iteration 104 / 243\n",
      "Iteration 105 / 243\n",
      "Iteration 106 / 243\n",
      "Iteration 107 / 243\n",
      "Iteration 108 / 243\n",
      "Iteration 109 / 243\n",
      "Iteration 110 / 243\n",
      "Iteration 111 / 243\n",
      "Iteration 112 / 243\n",
      "Iteration 113 / 243\n",
      "Iteration 114 / 243\n",
      "Iteration 115 / 243\n",
      "Iteration 116 / 243\n",
      "Iteration 117 / 243\n",
      "Iteration 118 / 243\n",
      "Iteration 119 / 243\n",
      "Iteration 120 / 243\n",
      "Iteration 121 / 243\n",
      "Iteration 122 / 243\n",
      "Iteration 123 / 243\n",
      "Iteration 124 / 243\n",
      "Iteration 125 / 243\n",
      "Iteration 126 / 243\n",
      "Iteration 127 / 243\n",
      "Iteration 128 / 243\n",
      "Iteration 129 / 243\n",
      "Iteration 130 / 243\n",
      "Iteration 131 / 243\n",
      "Iteration 132 / 243\n",
      "Iteration 133 / 243\n",
      "Iteration 134 / 243\n",
      "Iteration 135 / 243\n",
      "Iteration 136 / 243\n",
      "Iteration 137 / 243\n",
      "Iteration 138 / 243\n",
      "Iteration 139 / 243\n",
      "Iteration 140 / 243\n",
      "Iteration 141 / 243\n",
      "Iteration 142 / 243\n",
      "Iteration 143 / 243\n",
      "Iteration 144 / 243\n",
      "Iteration 145 / 243\n",
      "Iteration 146 / 243\n",
      "Iteration 147 / 243\n",
      "Iteration 148 / 243\n",
      "Iteration 149 / 243\n",
      "Iteration 150 / 243\n",
      "Iteration 151 / 243\n",
      "Iteration 152 / 243\n",
      "Iteration 153 / 243\n",
      "Iteration 154 / 243\n",
      "Iteration 155 / 243\n",
      "Iteration 156 / 243\n",
      "Iteration 157 / 243\n",
      "Iteration 158 / 243\n",
      "Iteration 159 / 243\n",
      "Iteration 160 / 243\n",
      "Iteration 161 / 243\n",
      "Iteration 162 / 243\n",
      "Iteration 163 / 243\n",
      "Iteration 164 / 243\n",
      "Iteration 165 / 243\n",
      "Iteration 166 / 243\n",
      "Iteration 167 / 243\n",
      "Iteration 168 / 243\n",
      "Iteration 169 / 243\n",
      "Iteration 170 / 243\n",
      "Iteration 171 / 243\n",
      "Iteration 172 / 243\n",
      "Iteration 173 / 243\n",
      "Iteration 174 / 243\n",
      "Iteration 175 / 243\n",
      "Iteration 176 / 243\n",
      "Iteration 177 / 243\n",
      "Iteration 178 / 243\n",
      "Iteration 179 / 243\n",
      "Iteration 180 / 243\n",
      "Iteration 181 / 243\n",
      "Iteration 182 / 243\n",
      "Iteration 183 / 243\n",
      "Iteration 184 / 243\n",
      "Iteration 185 / 243\n",
      "Iteration 186 / 243\n",
      "Iteration 187 / 243\n",
      "Iteration 188 / 243\n",
      "Iteration 189 / 243\n",
      "Iteration 190 / 243\n",
      "Iteration 191 / 243\n",
      "Iteration 192 / 243\n",
      "Iteration 193 / 243\n",
      "Iteration 194 / 243\n",
      "Iteration 195 / 243\n",
      "Iteration 196 / 243\n",
      "Iteration 197 / 243\n",
      "Iteration 198 / 243\n",
      "Iteration 199 / 243\n",
      "Iteration 200 / 243\n",
      "Iteration 201 / 243\n",
      "Iteration 202 / 243\n",
      "Iteration 203 / 243\n",
      "Iteration 204 / 243\n",
      "Iteration 205 / 243\n",
      "Iteration 206 / 243\n",
      "Iteration 207 / 243\n",
      "Iteration 208 / 243\n",
      "Iteration 209 / 243\n",
      "Iteration 210 / 243\n",
      "Iteration 211 / 243\n",
      "Iteration 212 / 243\n",
      "Iteration 213 / 243\n",
      "Iteration 214 / 243\n",
      "Iteration 215 / 243\n",
      "Iteration 216 / 243\n",
      "Iteration 217 / 243\n",
      "Iteration 218 / 243\n",
      "Iteration 219 / 243\n",
      "Iteration 220 / 243\n",
      "Iteration 221 / 243\n",
      "Iteration 222 / 243\n",
      "Iteration 223 / 243\n",
      "Iteration 224 / 243\n",
      "Iteration 225 / 243\n",
      "Iteration 226 / 243\n",
      "Iteration 227 / 243\n",
      "Iteration 228 / 243\n",
      "Iteration 229 / 243\n",
      "Iteration 230 / 243\n",
      "Iteration 231 / 243\n",
      "Iteration 232 / 243\n",
      "Iteration 233 / 243\n",
      "Iteration 234 / 243\n",
      "Iteration 235 / 243\n",
      "Iteration 236 / 243\n",
      "Iteration 237 / 243\n",
      "Iteration 238 / 243\n",
      "Iteration 239 / 243\n",
      "Iteration 240 / 243\n",
      "Iteration 241 / 243\n",
      "Iteration 242 / 243\n",
      "Iteration 243 / 243\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 150],\n",
    "    \"eta\": [0.01, 0.05, 0.1], # learning_rate\n",
    "    \"max_depth\": [4, 6, 8], # maximum depth of a tree\n",
    "    \"subsample\": [0.5, 0.7, 1], # fraction of observation to be radnomly sampled for each tree\n",
    "    \"colsample_bytree\": [0.5, 0.7, 1], # fraction of columns to be random samples for each tree\n",
    "    }\n",
    "\n",
    "params = []\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for values in itertools.product(*param_grid.values()):\n",
    "    params.append(dict(zip(param_grid.keys(), values)))\n",
    "\n",
    "best_params = hyperparameter_tuning(model_training_set, params, param_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3a4cb0dc-2ca3-4be0-98f0-024ca48c534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FG_PCT_ONE_ACT {'n_estimators': 50, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.7, 'colsample_bytree': 0.5}\n",
      "FG3_PCT_ONE_ACT {'n_estimators': 50, 'eta': 0.1, 'max_depth': 6, 'subsample': 0.7, 'colsample_bytree': 1}\n",
      "FT_PCT_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 4, 'subsample': 0.5, 'colsample_bytree': 0.5}\n",
      "OREB_ONE_ACT {'n_estimators': 50, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.5}\n",
      "DREB_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 4, 'subsample': 0.5, 'colsample_bytree': 1}\n",
      "REB_ONE_ACT {'n_estimators': 150, 'eta': 0.05, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.7}\n",
      "AST_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.5}\n",
      "STL_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.5}\n",
      "BLK_ONE_ACT {'n_estimators': 150, 'eta': 0.1, 'max_depth': 6, 'subsample': 0.7, 'colsample_bytree': 1}\n",
      "TOV_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 6, 'subsample': 0.7, 'colsample_bytree': 1}\n",
      "PF_ONE_ACT {'n_estimators': 150, 'eta': 0.05, 'max_depth': 4, 'subsample': 0.7, 'colsample_bytree': 1}\n",
      "EFG%_ONE_ACT {'n_estimators': 50, 'eta': 0.05, 'max_depth': 8, 'subsample': 0.7, 'colsample_bytree': 1}\n",
      "TS%_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 6, 'subsample': 1, 'colsample_bytree': 0.5}\n"
     ]
    }
   ],
   "source": [
    "for k, v in best_params.items():\n",
    "    print(k,v)\n",
    "\n",
    "#FG_PCT_ONE_ACT {'n_estimators': 50, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.7, 'colsample_bytree': 0.5}\n",
    "#FG3_PCT_ONE_ACT {'n_estimators': 50, 'eta': 0.1, 'max_depth': 6, 'subsample': 0.7, 'colsample_bytree': 1}\n",
    "#FT_PCT_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 4, 'subsample': 0.5, 'colsample_bytree': 0.5}\n",
    "#OREB_ONE_ACT {'n_estimators': 50, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.5}\n",
    "#DREB_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 4, 'subsample': 0.5, 'colsample_bytree': 1}\n",
    "#REB_ONE_ACT {'n_estimators': 150, 'eta': 0.05, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.7}\n",
    "#AST_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.5}\n",
    "#STL_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.5}\n",
    "#BLK_ONE_ACT {'n_estimators': 150, 'eta': 0.1, 'max_depth': 6, 'subsample': 0.7, 'colsample_bytree': 1}\n",
    "#TOV_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 6, 'subsample': 0.7, 'colsample_bytree': 1}\n",
    "#PF_ONE_ACT {'n_estimators': 150, 'eta': 0.05, 'max_depth': 4, 'subsample': 0.7, 'colsample_bytree': 1}\n",
    "#EFG%_ONE_ACT {'n_estimators': 50, 'eta': 0.05, 'max_depth': 8, 'subsample': 0.7, 'colsample_bytree': 1}\n",
    "#TS%_ONE_ACT {'n_estimators': 100, 'eta': 0.1, 'max_depth': 6, 'subsample': 1, 'colsample_bytree': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "cd0f31df-7462-4509-9527-f2e397ccd0a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting... 1986-11-01 00:00:00\n",
      "Predicting... 1987-03-07 00:00:00\n",
      "Predicting... 1987-04-17 00:00:00\n",
      "Predicting... 1987-11-25 00:00:00\n",
      "Predicting... 1988-03-11 00:00:00\n",
      "Predicting... 1988-04-02 00:00:00\n",
      "Predicting... 1988-11-04 00:00:00\n",
      "Predicting... 1989-03-23 00:00:00\n",
      "Predicting... 1989-04-15 00:00:00\n",
      "Predicting... 1989-11-24 00:00:00\n",
      "Predicting... 1990-03-16 00:00:00\n",
      "Predicting... 1990-03-30 00:00:00\n",
      "Predicting... 1990-11-24 00:00:00\n",
      "Predicting... 1991-03-09 00:00:00\n",
      "Predicting... 1991-04-14 00:00:00\n",
      "Predicting... 1991-11-06 00:00:00\n",
      "Predicting... 1992-03-11 00:00:00\n",
      "Predicting... 1992-03-31 00:00:00\n",
      "Predicting... 1992-11-11 00:00:00\n",
      "Predicting... 1993-03-02 00:00:00\n",
      "Predicting... 1993-04-10 00:00:00\n",
      "Predicting... 1993-11-17 00:00:00\n",
      "Predicting... 1994-03-24 00:00:00\n",
      "Predicting... 1994-04-21 00:00:00\n",
      "Predicting... 1994-11-30 00:00:00\n",
      "Predicting... 1995-03-24 00:00:00\n",
      "Predicting... 1995-04-15 00:00:00\n",
      "Predicting... 1995-11-08 00:00:00\n",
      "Predicting... 1996-02-25 00:00:00\n",
      "Predicting... 1996-04-18 00:00:00\n",
      "Predicting... 1996-11-12 00:00:00\n",
      "Predicting... 1997-03-12 00:00:00\n",
      "Predicting... 1997-03-23 00:00:00\n",
      "Predicting... 1997-11-25 00:00:00\n",
      "Predicting... 1998-03-21 00:00:00\n",
      "Predicting... 1998-04-16 00:00:00\n",
      "Predicting... 1999-02-14 00:00:00\n",
      "Predicting... 1999-04-23 00:00:00\n",
      "Predicting... 1999-05-03 00:00:00\n",
      "Predicting... 1999-11-23 00:00:00\n",
      "Predicting... 2000-03-03 00:00:00\n",
      "Predicting... 2000-04-06 00:00:00\n",
      "Predicting... 2000-11-22 00:00:00\n",
      "Predicting... 2001-03-09 00:00:00\n",
      "Predicting... 2001-03-25 00:00:00\n",
      "Predicting... 2001-11-16 00:00:00\n",
      "Predicting... 2002-03-09 00:00:00\n",
      "Predicting... 2002-04-14 00:00:00\n",
      "Predicting... 2002-11-26 00:00:00\n",
      "Predicting... 2003-03-08 00:00:00\n",
      "Predicting... 2003-04-15 00:00:00\n",
      "Predicting... 2003-11-14 00:00:00\n",
      "Predicting... 2004-02-21 00:00:00\n",
      "Predicting... 2004-04-04 00:00:00\n",
      "Predicting... 2004-11-21 00:00:00\n",
      "Predicting... 2005-03-04 00:00:00\n",
      "Predicting... 2005-03-23 00:00:00\n",
      "Predicting... 2005-11-08 00:00:00\n",
      "Predicting... 2006-03-18 00:00:00\n",
      "Predicting... 2006-04-10 00:00:00\n",
      "Predicting... 2006-11-15 00:00:00\n",
      "Predicting... 2007-02-21 00:00:00\n",
      "Predicting... 2007-03-25 00:00:00\n",
      "Predicting... 2007-11-24 00:00:00\n",
      "Predicting... 2008-03-08 00:00:00\n",
      "Predicting... 2008-03-28 00:00:00\n",
      "Predicting... 2008-11-11 00:00:00\n",
      "Predicting... 2009-03-02 00:00:00\n",
      "Predicting... 2009-04-10 00:00:00\n",
      "Predicting... 2009-11-01 00:00:00\n",
      "Predicting... 2010-02-28 00:00:00\n",
      "Predicting... 2010-04-14 00:00:00\n",
      "Predicting... 2010-11-06 00:00:00\n",
      "Predicting... 2011-03-05 00:00:00\n",
      "Predicting... 2011-04-08 00:00:00\n",
      "Predicting... 2012-01-07 00:00:00\n",
      "Predicting... 2012-04-09 00:00:00\n",
      "Predicting... 2012-04-03 00:00:00\n",
      "Predicting... 2012-11-16 00:00:00\n",
      "Predicting... 2013-02-21 00:00:00\n",
      "Predicting... 2013-04-14 00:00:00\n",
      "Predicting... 2013-11-02 00:00:00\n",
      "Predicting... 2014-02-26 00:00:00\n",
      "Predicting... 2014-04-12 00:00:00\n",
      "Predicting... 2014-11-21 00:00:00\n",
      "Predicting... 2015-03-07 00:00:00\n",
      "Predicting... 2015-04-14 00:00:00\n",
      "Predicting... 2015-11-18 00:00:00\n",
      "Predicting... 2016-02-24 00:00:00\n",
      "Predicting... 2016-03-18 00:00:00\n",
      "Predicting... 2016-11-14 00:00:00\n",
      "Predicting... 2017-03-02 00:00:00\n",
      "Predicting... 2017-03-20 00:00:00\n",
      "Predicting... 2017-10-18 00:00:00\n",
      "Predicting... 2018-02-24 00:00:00\n",
      "Predicting... 2018-03-15 00:00:00\n",
      "Predicting... 2018-11-08 00:00:00\n",
      "Predicting... 2019-02-13 00:00:00\n",
      "Predicting... 2019-04-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "rmse_tuned = evaluate_stats_model(model_training_set, val_set, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1701a792-28cb-498a-96b2-f3d210c6adcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.509182892225601)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d48c5-dd66-4f51-873b-61df603d01e3",
   "metadata": {},
   "source": [
    "### Predict Training Set for Outcome Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "819871b5-df51-4f5f-8c85-25a6675836cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_cols = ['TEAM_ID_ONE', 'SEASON_YEAR', 'HOME_ONE', 'WIN_ONE', 'ELO_ONE', 'WIN_STREAK_ONE', 'WIN_PERCENTAGE_ONE', 'WIN_LAST_ONE']\n",
    "def pred_training_set (df, first_season, last_season) :\n",
    "    all_predictions = None\n",
    "    days = all_stats_cleaned[all_stats_cleaned['SEASON_YEAR'].between(first_season, last_season)]['GAME_DATE'].unique()\n",
    "    rows = []\n",
    "    current_day = 1\n",
    "    total_days = len(days)\n",
    "    for d in days:\n",
    "        print(f\"Predicting Day {current_day} / {total_days} \")\n",
    "        games_on_day = df[df['GAME_DATE'] == d]\n",
    "        for _, row in games_on_day.iterrows() :\n",
    "            pred = predict_game_stats(df, row['TEAM_ID_ONE'], d)\n",
    "            pred['GAME_DATE'] = d\n",
    "            pred['OPP'] = row['TEAM_ID_TWO']\n",
    "            for s in static_cols :\n",
    "                pred[s] = row[s]\n",
    "            rows.append(pred)\n",
    "        current_day += 1\n",
    "            \n",
    "    all_predictions = pd.DataFrame(rows)\n",
    "    all_predictions.rename(columns=lambda col: col.replace('_ONE', ''), inplace=True)\n",
    "    all_predictions.rename(columns=lambda col: col.replace('_ACT', ''), inplace=True)\n",
    "\n",
    "    home = all_predictions[all_predictions.HOME == 1]\n",
    "    away = all_predictions[all_predictions.HOME == 0]\n",
    "\n",
    "    combined_pred_home = pd.merge(home, away, \n",
    "                          left_on=['GAME_DATE', 'OPP'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ID'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "    combined_pred_away = pd.merge(away, home, \n",
    "                          left_on=['GAME_DATE', 'OPP'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ID'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "\n",
    "    combined_pred = pd.concat([combined_pred_home, combined_pred_away], ignore_index = True)\n",
    "    combined_pred = combined_pred.drop(columns = ['OPP_ONE', 'OPP_TWO', 'HOME_TWO', 'WIN_TWO', 'SEASON_YEAR_TWO'])\n",
    "    combined_pred.rename(columns = {'SEASON_YEAR_ONE': 'SEASON_YEAR'}, inplace=True)\n",
    "\n",
    "    return combined_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165661b8-1f7a-460b-be29-614cf888c706",
   "metadata": {},
   "source": [
    "## Outcome Model\n",
    "Since it is computationally expensive to run the second model to predict all the values in the dataset, we will perform feature selection and hyperparameter tuning on the model trained on the basic rolling statistics. Then, we will predict on the test set with both types of models to see which performs better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0f171fa-25f9-4805-9c4d-c8c93d2a576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_horizon = 5\n",
    "df_rolling = combined_pred_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ff14a18-705e-4ac2-a905-2236e8193257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set (df, date, num_seasons) :\n",
    "    \"\"\"\n",
    "    Input: Date of games and number of seasons to include in dataset\n",
    "    Output: All rows from the last num_seasons and all games in the current season up till the given date\n",
    "    \"\"\"\n",
    "    # determine season of the game\n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "    \n",
    "    # get games for training\n",
    "    data = df[df['SEASON_YEAR'].between(season - num_seasons, season)].copy()\n",
    "    data['DAYS_SINCE_GAME'] = [(date-game_day).days for game_day in data['GAME_DATE']]\n",
    "    data = data[data['DAYS_SINCE_GAME'] > 0]\n",
    "\n",
    "    data = data.sort_values(by = 'DAYS_SINCE_GAME')\n",
    "\n",
    "    # split into X and y and only look at relevant columns\n",
    "    X = data.drop(columns = ['WIN_ONE', 'GAME_DATE'])\n",
    "    y = data['WIN_ONE']\n",
    "\n",
    "    return (X,y)\n",
    "\n",
    "def pred_by_date (df, model, date) :\n",
    "    \"\"\"\n",
    "    Predict the outcome of all games on the given date. \n",
    "    \"\"\"\n",
    "    n = time_horizon # how many years in the past for training\n",
    "    \n",
    "    # determine season of the game\n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "\n",
    "    # get data in relevant time frame\n",
    "    X, y = get_training_set(df, date, n)\n",
    "\n",
    "    #df = pd.DataFrame(columns=X.columns)\n",
    "\n",
    "    games_on_day = df[df['GAME_DATE'] == date].copy()\n",
    "    games_on_day['DAYS_SINCE_GAME'] = np.zeros(len(games_on_day))\n",
    "\n",
    "    test = games_on_day.drop(columns = ['WIN_ONE', 'GAME_DATE'])\n",
    "\n",
    "    model.fit(X,y)\n",
    "    pred = model.predict(test)\n",
    "    correct = np.sum(pred == games_on_day['WIN_ONE'])\n",
    "    games = len(pred)\n",
    "    return correct, games\n",
    "\n",
    "def test_model(df, model, dates) :\n",
    "    total_correct = total_games = 0\n",
    "\n",
    "    for d in dates:\n",
    "        correct, games = pred_by_date(df, model, d)\n",
    "\n",
    "        total_correct += correct\n",
    "        total_games += games\n",
    "    return total_correct, total_games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c3431-cb1a-47b1-99fb-17512003a020",
   "metadata": {},
   "source": [
    "### Initial Model With Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a09fe6eb-edc7-4a39-be13-7273f0d10de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6698113207547169)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(objective='binary:logistic', base_score = 0.5, random_state = 33)\n",
    "correct,games = test_model(df_rolling, model, val_set)\n",
    "correct / games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8aebd-1a13-4d39-a7e1-503eec967d90",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609c627-f25c-4a53-bcc4-8e51b475b336",
   "metadata": {},
   "source": [
    "The average feature importance scores is calculated for the three games for each season using XG Boost built-in feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce81c4-0431-49bb-af42-1e3acfc80164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_by_date_with_importance(model, date):\n",
    "    n = 5 \n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "    X, y = get_training_set(date, n)\n",
    "    # one hot encoding on the Home feature \n",
    "    games_on_day = df[df['GAME_DATE'] == date].copy()\n",
    "    games_on_day['DAYS_SINCE_GAME'] = np.zeros(len(games_on_day))\n",
    "\n",
    "    test = games_on_day.drop(columns = ['WIN_ONE', 'GAME_DATE'])\n",
    "\n",
    "    model.fit(X,y)\n",
    "    pred = model.predict(test)\n",
    "    correct = np.sum(pred == games_on_day['WIN_ONE'])\n",
    "    games = len(pred)\n",
    "    importance_scores = model.get_booster().get_score(importance_type='gain')\n",
    "    return correct, games, importance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a114ef-e7ea-48f4-9eb9-8df973cb1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_with_importance(model) :\n",
    "    \"\"\"\n",
    "    Outputs the average feature importance scores of game predictions\n",
    "    \"\"\"\n",
    "    total_correct = total_games = 0\n",
    "    feature_scores = {}\n",
    "    for t in test:\n",
    "        correct, games, importance_scores = pred_by_date_with_importance(model, t)\n",
    "        \n",
    "        for feature, score in importance_scores.items():\n",
    "            if feature not in feature_scores:\n",
    "                feature_scores[feature] = []\n",
    "            feature_scores[feature].append(score)\n",
    "            \n",
    "\n",
    "        total_correct += correct\n",
    "        total_games += games\n",
    "\n",
    "    average_importance = {features: sum(scores)/len(scores) for features, scores in feature_scores.items()}  \n",
    "    sorted_features = sorted(average_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10a8ee-6096-4371-8dd7-b27b2edb2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective='binary:logistic')\n",
    "importance_scores = test_model_with_importance(model)\n",
    "print(importance_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a819828-a7f5-49e1-a494-3a41dff88335",
   "metadata": {},
   "source": [
    "Testing the model with the feature importance scores by iteratively removing the least important features and comparing the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef51f5e-aa1b-4105-a3f9-610da7bfe9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set_with_features (date, num_seasons, features) :\n",
    "    \"\"\"\n",
    "    Input: Date of games, number of seasons and feature subset to include in dataset\n",
    "    Output: All rows from the last num_seasons and all games in the current season up till the given date\n",
    "    \"\"\"\n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "    data = df[df['SEASON_YEAR'].between(season - num_seasons, season)].copy()\n",
    "    data['DAYS_SINCE_GAME'] = [(date-game_day).days for game_day in data['GAME_DATE']]\n",
    "    data = data[data['DAYS_SINCE_GAME'] > 0]\n",
    "\n",
    "    data = data.sort_values(by = 'DAYS_SINCE_GAME')\n",
    "\n",
    "    X = data[features]\n",
    "    y = data['WIN_ONE']\n",
    "\n",
    "    return (X,y)\n",
    "\n",
    "def pred_by_date_with_features (model, date, features) :\n",
    "    n = 5 \n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "\n",
    "    X, y = get_training_set_with_features(date, n, features)\n",
    "\n",
    "    games_on_day = df[df['GAME_DATE'] == date].copy()\n",
    "    games_on_day['DAYS_SINCE_GAME'] = np.zeros(len(games_on_day))\n",
    "\n",
    "    test = games_on_day[features]\n",
    "    model.fit(X,y)\n",
    "    pred = model.predict(test)\n",
    "    correct = np.sum(pred == games_on_day['WIN_ONE'])\n",
    "    games = len(pred)\n",
    "    return correct, games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b97d1c-1e87-428a-9bf3-06f9f99a1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_with_importance(model, current_features, min_subset_size, top_n) :\n",
    "    \"\"\"\n",
    "    Iterates through the feature importance scores and iteratively remove the least importance features\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # current_features = [f[0] for f in feature_importance]\n",
    "    \n",
    "    while len(current_features) >= min_subset_size:\n",
    "        total_correct = total_games = 0\n",
    "        print(f\"Evaluating with {len(current_features)} features...\")\n",
    "        for t in test:    \n",
    "            correct, games = pred_by_date_with_features(model, t, features = current_features)\n",
    "        \n",
    "            total_correct += correct\n",
    "            total_games += games\n",
    "        print(current_features, ':', total_correct/total_games)\n",
    "        results.append((current_features.copy(), total_correct/total_games))\n",
    "        current_features.pop(-1)\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c115eae-4217-49c6-a0a1-67cd4d393b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective='binary:logistic')\n",
    "sorted_features = [f[0] for f in importance_scores]\n",
    "print(sorted_features)\n",
    "top_subsets = feature_selection_with_importance(model, sorted_features, min_subset_size=20, top_n=10)\n",
    "\n",
    "for i, (subset, acc) in enumerate(top_subsets, 1):\n",
    "    print(f\"#{i}: Features = {subset}, Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15196ee5-051c-460c-8e03-2a90839ee184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best performing feature subset\n",
    "best_feature_subset = top_subsets[0][0]\n",
    "print('Best feature subset: ', best_feature_subset)\n",
    "total_correct = total_games = 0\n",
    "for t in test:\n",
    "    correct, games = pred_by_date_with_features(model, t, best_feature_subset)\n",
    "\n",
    "    total_correct += correct\n",
    "    total_games += games\n",
    "print('Accuracy:', total_correct / total_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021aa82-c054-4cf9-a75d-822827baf620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "# def feature_selection(model, feature_names, min_subset_size, max_subset_size, top_n) :\n",
    "#     \"\"\"\n",
    "#     Iterates through the feature subsets and returns the top n subsets that gives the best scores\n",
    "#     \"\"\"\n",
    "#     print('start')\n",
    "#     results = []\n",
    "#     for n in range(min_subset_size, max_subset_size + 1):\n",
    "#         print(n)\n",
    "#         for subset in combinations(feature_names, n):\n",
    "#             print(subset)\n",
    "#             total_correct = total_games = 0\n",
    "#             for t in test:\n",
    "#                 print('test')\n",
    "#                 correct, games = pred_by_date_with_features(model, t, features = list(subset))\n",
    "        \n",
    "#                 total_correct += correct\n",
    "#                 total_games += games\n",
    "#             print(subset, ':', total_correct/total_games)\n",
    "#             results.append((subset, correct/games))\n",
    "#     results.sort(key=lambda x: x[1], reverse=True)\n",
    "#     return results[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae0524-0f30-49a1-aa25-581150e0e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through every combinations of size 40; takes too long (5+ hours)\n",
    "# model = XGBClassifier(objective='binary:logistic')\n",
    "# all_features = [col for col in df.columns if col not in ['WIN_ONE', 'GAME_DATE', 'SEASON_YEAR']]\n",
    "# top_subsets = feature_selection(model, all_features, min_subset_size=40, max_subset_size=40, top_n=10)\n",
    "\n",
    "# for i, (subset, acc, total) in enumerate(top_subsets, 1):\n",
    "#     print(f\"#{i}: Features = {subset}, Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c35db0f-dfd9-4878-8913-ff46cb83fb49",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162a6dd-8bfe-4f6f-bdeb-909b7bcb9f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_by_date_multiple_models (models_dict, date) :\n",
    "    \"\"\"\n",
    "    Predict the outcome of all games on the given date for all models given. Used specifically to make\n",
    "    cross validation more efficient\n",
    "    \"\"\"\n",
    "    n = 5 # how many years in the past for training\n",
    "    \n",
    "    # determine season of the game\n",
    "    season = date.year if date.month >= 10 else date.year - 1\n",
    "\n",
    "    # get data in relevant time frame\n",
    "    X, y = get_training_set(date, n)\n",
    "\n",
    "    games_on_day = df[df['GAME_DATE'] == date].copy()\n",
    "    games_on_day['DAYS_SINCE_GAME'] = np.zeros(len(games_on_day))\n",
    "\n",
    "    test = games_on_day.drop(columns = ['WIN_ONE', 'GAME_DATE'])\n",
    "\n",
    "    scores = np.zeros(len(models_dict))\n",
    "    for k, v in models_dict.items() :\n",
    "        v.fit(X,y)\n",
    "        pred = v.predict(val_set)\n",
    "        scores[k] = np.sum(pred == games_on_day['WIN_ONE'])\n",
    "    return scores, len(games_on_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024d2de-3105-4756-82cb-a22e0e083d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XGBoost parameters\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200, 400],\n",
    "    \"eta\": [0.01, 0.05, 0.1, 0.2], # learning_rate\n",
    "    \"max_depth\": [4, 6, 8, 10], # maximum depth of a tree\n",
    "    \"subsample\": [0.5, 0.7, 1], # fraction of observation to be radnomly sampled for each tree\n",
    "    \"colsample_bytree\": [0.5, 0.7, 1], # fraction of columns to be random samples for each tree\n",
    "    \"alpha\": [0.5, 1, 2, 5] # lasso regression\n",
    "}\n",
    "\n",
    "param_dict = {} # store params with key corresponding to index of score in np.array\n",
    "index = 0\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for values in itertools.product(*param_grid.values()):\n",
    "    param_dict[index] = XGBClassifier(objective='binary:logistic', random_state = 33, **dict(zip(param_grid.keys(), values)))\n",
    "    index += 1\n",
    "\n",
    "scores = np.zeros(len(param_dict))\n",
    "total_games = 0\n",
    "\n",
    "first_season = df['SEASON_YEAR'].min()\n",
    "last_season = df['SEASON_YEAR'].max()-4\n",
    "\n",
    "for t in test:\n",
    "    s, g = pred_by_date_multiple_models(param_dict, t)\n",
    "\n",
    "    scores += s\n",
    "    total_games += g\n",
    "    print(scores / total_games)\n",
    "\n",
    "print('final scores: ', scores / total_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a27693-7bba-4722-81f5-d49cd64b6a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_scores = scores / total_games\n",
    "best_model = param_dict[all_scores.argmax()]\n",
    "best_model.get_params() #'n_estimators': 400, eta: 0.01, max_depth: 4, subsample: 0.7, colsample_bytree: 0.7, alpha: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a830931-febe-453a-bd08-44b895bb871a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_five_models = np.argpartition(all_scores, -5)[-5:]\n",
    "top_five_models = top_five_models[np.argsort(-all_scores[top_five_models])]\n",
    "top_five_scores = all_scores[top_five_models]\n",
    "print(top_five_scores)\n",
    "for i in top_five_models : \n",
    "    p = param_dict[i].get_params()\n",
    "    print(f\"n_estimators = {p['n_estimators']}, eta = {p['eta']}, max_depth = {p['max_depth']}, subsample = {p['subsample']}, colsample_bytree = {p['colsample_bytree']}, alpha = {p['alpha']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e40c97f-7d78-4d1e-aa63-8f3e93ad668f",
   "metadata": {},
   "source": [
    "### Test Models\n",
    "We want to test the model trained on rolling averages and the predicted statistics from the second model. We will predict every game in the last 4 seasons. This means we need to predict all the statistics for the games in the last 9 seasons using the second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c30da327-732d-4884-87f7-6a8b0fc21bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test_season = all_stats_cleaned['SEASON_YEAR'].max() - 4\n",
    "last_test_season =  all_stats_cleaned['SEASON_YEAR'].max()\n",
    "test_set = all_stats_cleaned[all_stats_cleaned['SEASON_YEAR'] >= first_test_season]['GAME_DATE'].unique()\n",
    "train_set = all_stats_cleaned[all_stats_cleaned['SEASON_YEAR'] >= first_test_season - 5]['GAME_DATE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "582ce56d-7d83-40b4-851f-c6051a9ef775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if import in from csv\n",
    "#df_model = pd.read_csv('df_model_basic_parameters.csv')\n",
    "#df_model['GAME_DATE'] = pd.to_datetime(df_model['GAME_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b076c223-6d4d-4bf1-86af-e7d0efc378cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Day 1 / 971 \n",
      "Predicting Day 2 / 971 \n",
      "Predicting Day 3 / 971 \n",
      "Predicting Day 4 / 971 \n",
      "Predicting Day 5 / 971 \n",
      "Predicting Day 6 / 971 \n",
      "Predicting Day 7 / 971 \n",
      "Predicting Day 8 / 971 \n",
      "Predicting Day 9 / 971 \n",
      "Predicting Day 10 / 971 \n",
      "Predicting Day 11 / 971 \n",
      "Predicting Day 12 / 971 \n",
      "Predicting Day 13 / 971 \n",
      "Predicting Day 14 / 971 \n",
      "Predicting Day 15 / 971 \n",
      "Predicting Day 16 / 971 \n",
      "Predicting Day 17 / 971 \n",
      "Predicting Day 18 / 971 \n",
      "Predicting Day 19 / 971 \n",
      "Predicting Day 20 / 971 \n",
      "Predicting Day 21 / 971 \n",
      "Predicting Day 22 / 971 \n",
      "Predicting Day 23 / 971 \n",
      "Predicting Day 24 / 971 \n",
      "Predicting Day 25 / 971 \n",
      "Predicting Day 26 / 971 \n",
      "Predicting Day 27 / 971 \n",
      "Predicting Day 28 / 971 \n",
      "Predicting Day 29 / 971 \n",
      "Predicting Day 30 / 971 \n",
      "Predicting Day 31 / 971 \n",
      "Predicting Day 32 / 971 \n",
      "Predicting Day 33 / 971 \n",
      "Predicting Day 34 / 971 \n",
      "Predicting Day 35 / 971 \n",
      "Predicting Day 36 / 971 \n",
      "Predicting Day 37 / 971 \n",
      "Predicting Day 38 / 971 \n",
      "Predicting Day 39 / 971 \n",
      "Predicting Day 40 / 971 \n",
      "Predicting Day 41 / 971 \n",
      "Predicting Day 42 / 971 \n",
      "Predicting Day 43 / 971 \n",
      "Predicting Day 44 / 971 \n",
      "Predicting Day 45 / 971 \n",
      "Predicting Day 46 / 971 \n",
      "Predicting Day 47 / 971 \n",
      "Predicting Day 48 / 971 \n",
      "Predicting Day 49 / 971 \n",
      "Predicting Day 50 / 971 \n",
      "Predicting Day 51 / 971 \n",
      "Predicting Day 52 / 971 \n",
      "Predicting Day 53 / 971 \n",
      "Predicting Day 54 / 971 \n",
      "Predicting Day 55 / 971 \n",
      "Predicting Day 56 / 971 \n",
      "Predicting Day 57 / 971 \n",
      "Predicting Day 58 / 971 \n",
      "Predicting Day 59 / 971 \n",
      "Predicting Day 60 / 971 \n",
      "Predicting Day 61 / 971 \n",
      "Predicting Day 62 / 971 \n",
      "Predicting Day 63 / 971 \n",
      "Predicting Day 64 / 971 \n",
      "Predicting Day 65 / 971 \n",
      "Predicting Day 66 / 971 \n",
      "Predicting Day 67 / 971 \n",
      "Predicting Day 68 / 971 \n",
      "Predicting Day 69 / 971 \n",
      "Predicting Day 70 / 971 \n",
      "Predicting Day 71 / 971 \n",
      "Predicting Day 72 / 971 \n",
      "Predicting Day 73 / 971 \n",
      "Predicting Day 74 / 971 \n",
      "Predicting Day 75 / 971 \n",
      "Predicting Day 76 / 971 \n",
      "Predicting Day 77 / 971 \n",
      "Predicting Day 78 / 971 \n",
      "Predicting Day 79 / 971 \n",
      "Predicting Day 80 / 971 \n",
      "Predicting Day 81 / 971 \n",
      "Predicting Day 82 / 971 \n",
      "Predicting Day 83 / 971 \n",
      "Predicting Day 84 / 971 \n",
      "Predicting Day 85 / 971 \n",
      "Predicting Day 86 / 971 \n",
      "Predicting Day 87 / 971 \n",
      "Predicting Day 88 / 971 \n",
      "Predicting Day 89 / 971 \n",
      "Predicting Day 90 / 971 \n",
      "Predicting Day 91 / 971 \n",
      "Predicting Day 92 / 971 \n",
      "Predicting Day 93 / 971 \n",
      "Predicting Day 94 / 971 \n",
      "Predicting Day 95 / 971 \n",
      "Predicting Day 96 / 971 \n",
      "Predicting Day 97 / 971 \n",
      "Predicting Day 98 / 971 \n",
      "Predicting Day 99 / 971 \n",
      "Predicting Day 100 / 971 \n",
      "Predicting Day 101 / 971 \n",
      "Predicting Day 102 / 971 \n",
      "Predicting Day 103 / 971 \n",
      "Predicting Day 104 / 971 \n",
      "Predicting Day 105 / 971 \n",
      "Predicting Day 106 / 971 \n",
      "Predicting Day 107 / 971 \n",
      "Predicting Day 108 / 971 \n",
      "Predicting Day 109 / 971 \n",
      "Predicting Day 110 / 971 \n",
      "Predicting Day 111 / 971 \n",
      "Predicting Day 112 / 971 \n",
      "Predicting Day 113 / 971 \n",
      "Predicting Day 114 / 971 \n",
      "Predicting Day 115 / 971 \n",
      "Predicting Day 116 / 971 \n",
      "Predicting Day 117 / 971 \n",
      "Predicting Day 118 / 971 \n",
      "Predicting Day 119 / 971 \n",
      "Predicting Day 120 / 971 \n",
      "Predicting Day 121 / 971 \n",
      "Predicting Day 122 / 971 \n",
      "Predicting Day 123 / 971 \n",
      "Predicting Day 124 / 971 \n",
      "Predicting Day 125 / 971 \n",
      "Predicting Day 126 / 971 \n",
      "Predicting Day 127 / 971 \n",
      "Predicting Day 128 / 971 \n",
      "Predicting Day 129 / 971 \n",
      "Predicting Day 130 / 971 \n",
      "Predicting Day 131 / 971 \n",
      "Predicting Day 132 / 971 \n",
      "Predicting Day 133 / 971 \n",
      "Predicting Day 134 / 971 \n",
      "Predicting Day 135 / 971 \n",
      "Predicting Day 136 / 971 \n",
      "Predicting Day 137 / 971 \n",
      "Predicting Day 138 / 971 \n",
      "Predicting Day 139 / 971 \n",
      "Predicting Day 140 / 971 \n",
      "Predicting Day 141 / 971 \n",
      "Predicting Day 142 / 971 \n",
      "Predicting Day 143 / 971 \n",
      "Predicting Day 144 / 971 \n",
      "Predicting Day 145 / 971 \n",
      "Predicting Day 146 / 971 \n",
      "Predicting Day 147 / 971 \n",
      "Predicting Day 148 / 971 \n",
      "Predicting Day 149 / 971 \n",
      "Predicting Day 150 / 971 \n",
      "Predicting Day 151 / 971 \n",
      "Predicting Day 152 / 971 \n",
      "Predicting Day 153 / 971 \n",
      "Predicting Day 154 / 971 \n",
      "Predicting Day 155 / 971 \n",
      "Predicting Day 156 / 971 \n",
      "Predicting Day 157 / 971 \n",
      "Predicting Day 158 / 971 \n",
      "Predicting Day 159 / 971 \n",
      "Predicting Day 160 / 971 \n",
      "Predicting Day 161 / 971 \n",
      "Predicting Day 162 / 971 \n",
      "Predicting Day 163 / 971 \n",
      "Predicting Day 164 / 971 \n",
      "Predicting Day 165 / 971 \n",
      "Predicting Day 166 / 971 \n",
      "Predicting Day 167 / 971 \n",
      "Predicting Day 168 / 971 \n",
      "Predicting Day 169 / 971 \n",
      "Predicting Day 170 / 971 \n",
      "Predicting Day 171 / 971 \n",
      "Predicting Day 172 / 971 \n",
      "Predicting Day 173 / 971 \n",
      "Predicting Day 174 / 971 \n",
      "Predicting Day 175 / 971 \n",
      "Predicting Day 176 / 971 \n",
      "Predicting Day 177 / 971 \n",
      "Predicting Day 178 / 971 \n",
      "Predicting Day 179 / 971 \n",
      "Predicting Day 180 / 971 \n",
      "Predicting Day 181 / 971 \n",
      "Predicting Day 182 / 971 \n",
      "Predicting Day 183 / 971 \n",
      "Predicting Day 184 / 971 \n",
      "Predicting Day 185 / 971 \n",
      "Predicting Day 186 / 971 \n",
      "Predicting Day 187 / 971 \n",
      "Predicting Day 188 / 971 \n",
      "Predicting Day 189 / 971 \n",
      "Predicting Day 190 / 971 \n",
      "Predicting Day 191 / 971 \n",
      "Predicting Day 192 / 971 \n",
      "Predicting Day 193 / 971 \n",
      "Predicting Day 194 / 971 \n",
      "Predicting Day 195 / 971 \n",
      "Predicting Day 196 / 971 \n",
      "Predicting Day 197 / 971 \n",
      "Predicting Day 198 / 971 \n",
      "Predicting Day 199 / 971 \n",
      "Predicting Day 200 / 971 \n",
      "Predicting Day 201 / 971 \n",
      "Predicting Day 202 / 971 \n",
      "Predicting Day 203 / 971 \n",
      "Predicting Day 204 / 971 \n",
      "Predicting Day 205 / 971 \n",
      "Predicting Day 206 / 971 \n",
      "Predicting Day 207 / 971 \n",
      "Predicting Day 208 / 971 \n",
      "Predicting Day 209 / 971 \n",
      "Predicting Day 210 / 971 \n",
      "Predicting Day 211 / 971 \n",
      "Predicting Day 212 / 971 \n",
      "Predicting Day 213 / 971 \n",
      "Predicting Day 214 / 971 \n",
      "Predicting Day 215 / 971 \n",
      "Predicting Day 216 / 971 \n",
      "Predicting Day 217 / 971 \n",
      "Predicting Day 218 / 971 \n",
      "Predicting Day 219 / 971 \n",
      "Predicting Day 220 / 971 \n",
      "Predicting Day 221 / 971 \n",
      "Predicting Day 222 / 971 \n",
      "Predicting Day 223 / 971 \n",
      "Predicting Day 224 / 971 \n",
      "Predicting Day 225 / 971 \n",
      "Predicting Day 226 / 971 \n",
      "Predicting Day 227 / 971 \n",
      "Predicting Day 228 / 971 \n",
      "Predicting Day 229 / 971 \n",
      "Predicting Day 230 / 971 \n",
      "Predicting Day 231 / 971 \n",
      "Predicting Day 232 / 971 \n",
      "Predicting Day 233 / 971 \n",
      "Predicting Day 234 / 971 \n",
      "Predicting Day 235 / 971 \n",
      "Predicting Day 236 / 971 \n",
      "Predicting Day 237 / 971 \n",
      "Predicting Day 238 / 971 \n",
      "Predicting Day 239 / 971 \n",
      "Predicting Day 240 / 971 \n",
      "Predicting Day 241 / 971 \n",
      "Predicting Day 242 / 971 \n",
      "Predicting Day 243 / 971 \n",
      "Predicting Day 244 / 971 \n",
      "Predicting Day 245 / 971 \n",
      "Predicting Day 246 / 971 \n",
      "Predicting Day 247 / 971 \n",
      "Predicting Day 248 / 971 \n",
      "Predicting Day 249 / 971 \n",
      "Predicting Day 250 / 971 \n",
      "Predicting Day 251 / 971 \n",
      "Predicting Day 252 / 971 \n",
      "Predicting Day 253 / 971 \n",
      "Predicting Day 254 / 971 \n",
      "Predicting Day 255 / 971 \n",
      "Predicting Day 256 / 971 \n",
      "Predicting Day 257 / 971 \n",
      "Predicting Day 258 / 971 \n",
      "Predicting Day 259 / 971 \n",
      "Predicting Day 260 / 971 \n",
      "Predicting Day 261 / 971 \n",
      "Predicting Day 262 / 971 \n",
      "Predicting Day 263 / 971 \n",
      "Predicting Day 264 / 971 \n",
      "Predicting Day 265 / 971 \n",
      "Predicting Day 266 / 971 \n",
      "Predicting Day 267 / 971 \n",
      "Predicting Day 268 / 971 \n",
      "Predicting Day 269 / 971 \n",
      "Predicting Day 270 / 971 \n",
      "Predicting Day 271 / 971 \n",
      "Predicting Day 272 / 971 \n",
      "Predicting Day 273 / 971 \n",
      "Predicting Day 274 / 971 \n",
      "Predicting Day 275 / 971 \n",
      "Predicting Day 276 / 971 \n",
      "Predicting Day 277 / 971 \n",
      "Predicting Day 278 / 971 \n",
      "Predicting Day 279 / 971 \n",
      "Predicting Day 280 / 971 \n",
      "Predicting Day 281 / 971 \n",
      "Predicting Day 282 / 971 \n",
      "Predicting Day 283 / 971 \n",
      "Predicting Day 284 / 971 \n",
      "Predicting Day 285 / 971 \n",
      "Predicting Day 286 / 971 \n",
      "Predicting Day 287 / 971 \n",
      "Predicting Day 288 / 971 \n",
      "Predicting Day 289 / 971 \n",
      "Predicting Day 290 / 971 \n",
      "Predicting Day 291 / 971 \n",
      "Predicting Day 292 / 971 \n",
      "Predicting Day 293 / 971 \n",
      "Predicting Day 294 / 971 \n",
      "Predicting Day 295 / 971 \n",
      "Predicting Day 296 / 971 \n",
      "Predicting Day 297 / 971 \n",
      "Predicting Day 298 / 971 \n",
      "Predicting Day 299 / 971 \n",
      "Predicting Day 300 / 971 \n",
      "Predicting Day 301 / 971 \n",
      "Predicting Day 302 / 971 \n",
      "Predicting Day 303 / 971 \n",
      "Predicting Day 304 / 971 \n",
      "Predicting Day 305 / 971 \n",
      "Predicting Day 306 / 971 \n",
      "Predicting Day 307 / 971 \n",
      "Predicting Day 308 / 971 \n",
      "Predicting Day 309 / 971 \n",
      "Predicting Day 310 / 971 \n",
      "Predicting Day 311 / 971 \n",
      "Predicting Day 312 / 971 \n",
      "Predicting Day 313 / 971 \n",
      "Predicting Day 314 / 971 \n",
      "Predicting Day 315 / 971 \n",
      "Predicting Day 316 / 971 \n",
      "Predicting Day 317 / 971 \n",
      "Predicting Day 318 / 971 \n",
      "Predicting Day 319 / 971 \n",
      "Predicting Day 320 / 971 \n",
      "Predicting Day 321 / 971 \n",
      "Predicting Day 322 / 971 \n",
      "Predicting Day 323 / 971 \n",
      "Predicting Day 324 / 971 \n",
      "Predicting Day 325 / 971 \n",
      "Predicting Day 326 / 971 \n",
      "Predicting Day 327 / 971 \n",
      "Predicting Day 328 / 971 \n",
      "Predicting Day 329 / 971 \n",
      "Predicting Day 330 / 971 \n",
      "Predicting Day 331 / 971 \n",
      "Predicting Day 332 / 971 \n",
      "Predicting Day 333 / 971 \n",
      "Predicting Day 334 / 971 \n",
      "Predicting Day 335 / 971 \n",
      "Predicting Day 336 / 971 \n",
      "Predicting Day 337 / 971 \n",
      "Predicting Day 338 / 971 \n",
      "Predicting Day 339 / 971 \n",
      "Predicting Day 340 / 971 \n",
      "Predicting Day 341 / 971 \n",
      "Predicting Day 342 / 971 \n",
      "Predicting Day 343 / 971 \n",
      "Predicting Day 344 / 971 \n",
      "Predicting Day 345 / 971 \n",
      "Predicting Day 346 / 971 \n",
      "Predicting Day 347 / 971 \n",
      "Predicting Day 348 / 971 \n",
      "Predicting Day 349 / 971 \n",
      "Predicting Day 350 / 971 \n",
      "Predicting Day 351 / 971 \n",
      "Predicting Day 352 / 971 \n",
      "Predicting Day 353 / 971 \n",
      "Predicting Day 354 / 971 \n",
      "Predicting Day 355 / 971 \n",
      "Predicting Day 356 / 971 \n",
      "Predicting Day 357 / 971 \n",
      "Predicting Day 358 / 971 \n",
      "Predicting Day 359 / 971 \n",
      "Predicting Day 360 / 971 \n",
      "Predicting Day 361 / 971 \n",
      "Predicting Day 362 / 971 \n",
      "Predicting Day 363 / 971 \n",
      "Predicting Day 364 / 971 \n",
      "Predicting Day 365 / 971 \n",
      "Predicting Day 366 / 971 \n",
      "Predicting Day 367 / 971 \n",
      "Predicting Day 368 / 971 \n",
      "Predicting Day 369 / 971 \n",
      "Predicting Day 370 / 971 \n",
      "Predicting Day 371 / 971 \n",
      "Predicting Day 372 / 971 \n",
      "Predicting Day 373 / 971 \n",
      "Predicting Day 374 / 971 \n",
      "Predicting Day 375 / 971 \n",
      "Predicting Day 376 / 971 \n",
      "Predicting Day 377 / 971 \n",
      "Predicting Day 378 / 971 \n",
      "Predicting Day 379 / 971 \n",
      "Predicting Day 380 / 971 \n",
      "Predicting Day 381 / 971 \n",
      "Predicting Day 382 / 971 \n",
      "Predicting Day 383 / 971 \n",
      "Predicting Day 384 / 971 \n",
      "Predicting Day 385 / 971 \n",
      "Predicting Day 386 / 971 \n",
      "Predicting Day 387 / 971 \n",
      "Predicting Day 388 / 971 \n",
      "Predicting Day 389 / 971 \n",
      "Predicting Day 390 / 971 \n",
      "Predicting Day 391 / 971 \n",
      "Predicting Day 392 / 971 \n",
      "Predicting Day 393 / 971 \n",
      "Predicting Day 394 / 971 \n",
      "Predicting Day 395 / 971 \n",
      "Predicting Day 396 / 971 \n",
      "Predicting Day 397 / 971 \n",
      "Predicting Day 398 / 971 \n",
      "Predicting Day 399 / 971 \n",
      "Predicting Day 400 / 971 \n",
      "Predicting Day 401 / 971 \n",
      "Predicting Day 402 / 971 \n",
      "Predicting Day 403 / 971 \n",
      "Predicting Day 404 / 971 \n",
      "Predicting Day 405 / 971 \n",
      "Predicting Day 406 / 971 \n",
      "Predicting Day 407 / 971 \n",
      "Predicting Day 408 / 971 \n",
      "Predicting Day 409 / 971 \n",
      "Predicting Day 410 / 971 \n",
      "Predicting Day 411 / 971 \n",
      "Predicting Day 412 / 971 \n",
      "Predicting Day 413 / 971 \n",
      "Predicting Day 414 / 971 \n",
      "Predicting Day 415 / 971 \n",
      "Predicting Day 416 / 971 \n",
      "Predicting Day 417 / 971 \n",
      "Predicting Day 418 / 971 \n",
      "Predicting Day 419 / 971 \n",
      "Predicting Day 420 / 971 \n",
      "Predicting Day 421 / 971 \n",
      "Predicting Day 422 / 971 \n",
      "Predicting Day 423 / 971 \n",
      "Predicting Day 424 / 971 \n",
      "Predicting Day 425 / 971 \n",
      "Predicting Day 426 / 971 \n",
      "Predicting Day 427 / 971 \n",
      "Predicting Day 428 / 971 \n",
      "Predicting Day 429 / 971 \n",
      "Predicting Day 430 / 971 \n",
      "Predicting Day 431 / 971 \n",
      "Predicting Day 432 / 971 \n",
      "Predicting Day 433 / 971 \n",
      "Predicting Day 434 / 971 \n",
      "Predicting Day 435 / 971 \n",
      "Predicting Day 436 / 971 \n",
      "Predicting Day 437 / 971 \n",
      "Predicting Day 438 / 971 \n",
      "Predicting Day 439 / 971 \n",
      "Predicting Day 440 / 971 \n",
      "Predicting Day 441 / 971 \n",
      "Predicting Day 442 / 971 \n",
      "Predicting Day 443 / 971 \n",
      "Predicting Day 444 / 971 \n",
      "Predicting Day 445 / 971 \n",
      "Predicting Day 446 / 971 \n",
      "Predicting Day 447 / 971 \n",
      "Predicting Day 448 / 971 \n",
      "Predicting Day 449 / 971 \n",
      "Predicting Day 450 / 971 \n",
      "Predicting Day 451 / 971 \n",
      "Predicting Day 452 / 971 \n",
      "Predicting Day 453 / 971 \n",
      "Predicting Day 454 / 971 \n",
      "Predicting Day 455 / 971 \n",
      "Predicting Day 456 / 971 \n",
      "Predicting Day 457 / 971 \n",
      "Predicting Day 458 / 971 \n",
      "Predicting Day 459 / 971 \n",
      "Predicting Day 460 / 971 \n",
      "Predicting Day 461 / 971 \n",
      "Predicting Day 462 / 971 \n",
      "Predicting Day 463 / 971 \n",
      "Predicting Day 464 / 971 \n",
      "Predicting Day 465 / 971 \n",
      "Predicting Day 466 / 971 \n",
      "Predicting Day 467 / 971 \n",
      "Predicting Day 468 / 971 \n",
      "Predicting Day 469 / 971 \n",
      "Predicting Day 470 / 971 \n",
      "Predicting Day 471 / 971 \n",
      "Predicting Day 472 / 971 \n",
      "Predicting Day 473 / 971 \n",
      "Predicting Day 474 / 971 \n",
      "Predicting Day 475 / 971 \n",
      "Predicting Day 476 / 971 \n",
      "Predicting Day 477 / 971 \n",
      "Predicting Day 478 / 971 \n",
      "Predicting Day 479 / 971 \n",
      "Predicting Day 480 / 971 \n",
      "Predicting Day 481 / 971 \n",
      "Predicting Day 482 / 971 \n",
      "Predicting Day 483 / 971 \n",
      "Predicting Day 484 / 971 \n",
      "Predicting Day 485 / 971 \n",
      "Predicting Day 486 / 971 \n",
      "Predicting Day 487 / 971 \n",
      "Predicting Day 488 / 971 \n",
      "Predicting Day 489 / 971 \n",
      "Predicting Day 490 / 971 \n",
      "Predicting Day 491 / 971 \n",
      "Predicting Day 492 / 971 \n",
      "Predicting Day 493 / 971 \n",
      "Predicting Day 494 / 971 \n",
      "Predicting Day 495 / 971 \n",
      "Predicting Day 496 / 971 \n",
      "Predicting Day 497 / 971 \n",
      "Predicting Day 498 / 971 \n",
      "Predicting Day 499 / 971 \n",
      "Predicting Day 500 / 971 \n",
      "Predicting Day 501 / 971 \n",
      "Predicting Day 502 / 971 \n",
      "Predicting Day 503 / 971 \n",
      "Predicting Day 504 / 971 \n",
      "Predicting Day 505 / 971 \n",
      "Predicting Day 506 / 971 \n",
      "Predicting Day 507 / 971 \n",
      "Predicting Day 508 / 971 \n",
      "Predicting Day 509 / 971 \n",
      "Predicting Day 510 / 971 \n",
      "Predicting Day 511 / 971 \n",
      "Predicting Day 512 / 971 \n",
      "Predicting Day 513 / 971 \n",
      "Predicting Day 514 / 971 \n",
      "Predicting Day 515 / 971 \n",
      "Predicting Day 516 / 971 \n",
      "Predicting Day 517 / 971 \n",
      "Predicting Day 518 / 971 \n",
      "Predicting Day 519 / 971 \n",
      "Predicting Day 520 / 971 \n",
      "Predicting Day 521 / 971 \n",
      "Predicting Day 522 / 971 \n",
      "Predicting Day 523 / 971 \n",
      "Predicting Day 524 / 971 \n",
      "Predicting Day 525 / 971 \n",
      "Predicting Day 526 / 971 \n",
      "Predicting Day 527 / 971 \n",
      "Predicting Day 528 / 971 \n",
      "Predicting Day 529 / 971 \n",
      "Predicting Day 530 / 971 \n",
      "Predicting Day 531 / 971 \n",
      "Predicting Day 532 / 971 \n",
      "Predicting Day 533 / 971 \n",
      "Predicting Day 534 / 971 \n",
      "Predicting Day 535 / 971 \n",
      "Predicting Day 536 / 971 \n",
      "Predicting Day 537 / 971 \n",
      "Predicting Day 538 / 971 \n",
      "Predicting Day 539 / 971 \n",
      "Predicting Day 540 / 971 \n",
      "Predicting Day 541 / 971 \n",
      "Predicting Day 542 / 971 \n",
      "Predicting Day 543 / 971 \n",
      "Predicting Day 544 / 971 \n",
      "Predicting Day 545 / 971 \n",
      "Predicting Day 546 / 971 \n",
      "Predicting Day 547 / 971 \n",
      "Predicting Day 548 / 971 \n",
      "Predicting Day 549 / 971 \n",
      "Predicting Day 550 / 971 \n",
      "Predicting Day 551 / 971 \n",
      "Predicting Day 552 / 971 \n",
      "Predicting Day 553 / 971 \n",
      "Predicting Day 554 / 971 \n",
      "Predicting Day 555 / 971 \n",
      "Predicting Day 556 / 971 \n",
      "Predicting Day 557 / 971 \n",
      "Predicting Day 558 / 971 \n",
      "Predicting Day 559 / 971 \n",
      "Predicting Day 560 / 971 \n",
      "Predicting Day 561 / 971 \n",
      "Predicting Day 562 / 971 \n",
      "Predicting Day 563 / 971 \n",
      "Predicting Day 564 / 971 \n",
      "Predicting Day 565 / 971 \n",
      "Predicting Day 566 / 971 \n",
      "Predicting Day 567 / 971 \n",
      "Predicting Day 568 / 971 \n",
      "Predicting Day 569 / 971 \n",
      "Predicting Day 570 / 971 \n",
      "Predicting Day 571 / 971 \n",
      "Predicting Day 572 / 971 \n",
      "Predicting Day 573 / 971 \n",
      "Predicting Day 574 / 971 \n",
      "Predicting Day 575 / 971 \n",
      "Predicting Day 576 / 971 \n",
      "Predicting Day 577 / 971 \n",
      "Predicting Day 578 / 971 \n",
      "Predicting Day 579 / 971 \n",
      "Predicting Day 580 / 971 \n",
      "Predicting Day 581 / 971 \n",
      "Predicting Day 582 / 971 \n",
      "Predicting Day 583 / 971 \n",
      "Predicting Day 584 / 971 \n",
      "Predicting Day 585 / 971 \n",
      "Predicting Day 586 / 971 \n",
      "Predicting Day 587 / 971 \n",
      "Predicting Day 588 / 971 \n",
      "Predicting Day 589 / 971 \n",
      "Predicting Day 590 / 971 \n",
      "Predicting Day 591 / 971 \n",
      "Predicting Day 592 / 971 \n",
      "Predicting Day 593 / 971 \n",
      "Predicting Day 594 / 971 \n",
      "Predicting Day 595 / 971 \n",
      "Predicting Day 596 / 971 \n",
      "Predicting Day 597 / 971 \n",
      "Predicting Day 598 / 971 \n",
      "Predicting Day 599 / 971 \n",
      "Predicting Day 600 / 971 \n",
      "Predicting Day 601 / 971 \n",
      "Predicting Day 602 / 971 \n",
      "Predicting Day 603 / 971 \n",
      "Predicting Day 604 / 971 \n",
      "Predicting Day 605 / 971 \n",
      "Predicting Day 606 / 971 \n",
      "Predicting Day 607 / 971 \n",
      "Predicting Day 608 / 971 \n",
      "Predicting Day 609 / 971 \n",
      "Predicting Day 610 / 971 \n",
      "Predicting Day 611 / 971 \n",
      "Predicting Day 612 / 971 \n",
      "Predicting Day 613 / 971 \n",
      "Predicting Day 614 / 971 \n",
      "Predicting Day 615 / 971 \n",
      "Predicting Day 616 / 971 \n",
      "Predicting Day 617 / 971 \n",
      "Predicting Day 618 / 971 \n",
      "Predicting Day 619 / 971 \n",
      "Predicting Day 620 / 971 \n",
      "Predicting Day 621 / 971 \n",
      "Predicting Day 622 / 971 \n",
      "Predicting Day 623 / 971 \n",
      "Predicting Day 624 / 971 \n",
      "Predicting Day 625 / 971 \n",
      "Predicting Day 626 / 971 \n",
      "Predicting Day 627 / 971 \n",
      "Predicting Day 628 / 971 \n",
      "Predicting Day 629 / 971 \n",
      "Predicting Day 630 / 971 \n",
      "Predicting Day 631 / 971 \n",
      "Predicting Day 632 / 971 \n",
      "Predicting Day 633 / 971 \n",
      "Predicting Day 634 / 971 \n",
      "Predicting Day 635 / 971 \n",
      "Predicting Day 636 / 971 \n",
      "Predicting Day 637 / 971 \n",
      "Predicting Day 638 / 971 \n",
      "Predicting Day 639 / 971 \n",
      "Predicting Day 640 / 971 \n",
      "Predicting Day 641 / 971 \n",
      "Predicting Day 642 / 971 \n",
      "Predicting Day 643 / 971 \n",
      "Predicting Day 644 / 971 \n",
      "Predicting Day 645 / 971 \n",
      "Predicting Day 646 / 971 \n",
      "Predicting Day 647 / 971 \n",
      "Predicting Day 648 / 971 \n",
      "Predicting Day 649 / 971 \n",
      "Predicting Day 650 / 971 \n",
      "Predicting Day 651 / 971 \n",
      "Predicting Day 652 / 971 \n",
      "Predicting Day 653 / 971 \n",
      "Predicting Day 654 / 971 \n",
      "Predicting Day 655 / 971 \n",
      "Predicting Day 656 / 971 \n",
      "Predicting Day 657 / 971 \n",
      "Predicting Day 658 / 971 \n",
      "Predicting Day 659 / 971 \n",
      "Predicting Day 660 / 971 \n",
      "Predicting Day 661 / 971 \n",
      "Predicting Day 662 / 971 \n",
      "Predicting Day 663 / 971 \n",
      "Predicting Day 664 / 971 \n",
      "Predicting Day 665 / 971 \n",
      "Predicting Day 666 / 971 \n",
      "Predicting Day 667 / 971 \n",
      "Predicting Day 668 / 971 \n",
      "Predicting Day 669 / 971 \n",
      "Predicting Day 670 / 971 \n",
      "Predicting Day 671 / 971 \n",
      "Predicting Day 672 / 971 \n",
      "Predicting Day 673 / 971 \n",
      "Predicting Day 674 / 971 \n",
      "Predicting Day 675 / 971 \n",
      "Predicting Day 676 / 971 \n",
      "Predicting Day 677 / 971 \n",
      "Predicting Day 678 / 971 \n",
      "Predicting Day 679 / 971 \n",
      "Predicting Day 680 / 971 \n",
      "Predicting Day 681 / 971 \n",
      "Predicting Day 682 / 971 \n",
      "Predicting Day 683 / 971 \n",
      "Predicting Day 684 / 971 \n",
      "Predicting Day 685 / 971 \n",
      "Predicting Day 686 / 971 \n",
      "Predicting Day 687 / 971 \n",
      "Predicting Day 688 / 971 \n",
      "Predicting Day 689 / 971 \n",
      "Predicting Day 690 / 971 \n",
      "Predicting Day 691 / 971 \n",
      "Predicting Day 692 / 971 \n",
      "Predicting Day 693 / 971 \n",
      "Predicting Day 694 / 971 \n",
      "Predicting Day 695 / 971 \n",
      "Predicting Day 696 / 971 \n",
      "Predicting Day 697 / 971 \n",
      "Predicting Day 698 / 971 \n",
      "Predicting Day 699 / 971 \n",
      "Predicting Day 700 / 971 \n",
      "Predicting Day 701 / 971 \n",
      "Predicting Day 702 / 971 \n",
      "Predicting Day 703 / 971 \n",
      "Predicting Day 704 / 971 \n",
      "Predicting Day 705 / 971 \n",
      "Predicting Day 706 / 971 \n",
      "Predicting Day 707 / 971 \n",
      "Predicting Day 708 / 971 \n",
      "Predicting Day 709 / 971 \n",
      "Predicting Day 710 / 971 \n",
      "Predicting Day 711 / 971 \n",
      "Predicting Day 712 / 971 \n",
      "Predicting Day 713 / 971 \n",
      "Predicting Day 714 / 971 \n",
      "Predicting Day 715 / 971 \n",
      "Predicting Day 716 / 971 \n",
      "Predicting Day 717 / 971 \n",
      "Predicting Day 718 / 971 \n",
      "Predicting Day 719 / 971 \n",
      "Predicting Day 720 / 971 \n",
      "Predicting Day 721 / 971 \n",
      "Predicting Day 722 / 971 \n",
      "Predicting Day 723 / 971 \n",
      "Predicting Day 724 / 971 \n",
      "Predicting Day 725 / 971 \n",
      "Predicting Day 726 / 971 \n",
      "Predicting Day 727 / 971 \n",
      "Predicting Day 728 / 971 \n",
      "Predicting Day 729 / 971 \n",
      "Predicting Day 730 / 971 \n",
      "Predicting Day 731 / 971 \n",
      "Predicting Day 732 / 971 \n",
      "Predicting Day 733 / 971 \n",
      "Predicting Day 734 / 971 \n",
      "Predicting Day 735 / 971 \n",
      "Predicting Day 736 / 971 \n",
      "Predicting Day 737 / 971 \n",
      "Predicting Day 738 / 971 \n",
      "Predicting Day 739 / 971 \n",
      "Predicting Day 740 / 971 \n",
      "Predicting Day 741 / 971 \n",
      "Predicting Day 742 / 971 \n",
      "Predicting Day 743 / 971 \n",
      "Predicting Day 744 / 971 \n",
      "Predicting Day 745 / 971 \n",
      "Predicting Day 746 / 971 \n",
      "Predicting Day 747 / 971 \n",
      "Predicting Day 748 / 971 \n",
      "Predicting Day 749 / 971 \n",
      "Predicting Day 750 / 971 \n",
      "Predicting Day 751 / 971 \n",
      "Predicting Day 752 / 971 \n",
      "Predicting Day 753 / 971 \n",
      "Predicting Day 754 / 971 \n",
      "Predicting Day 755 / 971 \n",
      "Predicting Day 756 / 971 \n",
      "Predicting Day 757 / 971 \n",
      "Predicting Day 758 / 971 \n",
      "Predicting Day 759 / 971 \n",
      "Predicting Day 760 / 971 \n",
      "Predicting Day 761 / 971 \n",
      "Predicting Day 762 / 971 \n",
      "Predicting Day 763 / 971 \n",
      "Predicting Day 764 / 971 \n",
      "Predicting Day 765 / 971 \n",
      "Predicting Day 766 / 971 \n",
      "Predicting Day 767 / 971 \n",
      "Predicting Day 768 / 971 \n",
      "Predicting Day 769 / 971 \n",
      "Predicting Day 770 / 971 \n",
      "Predicting Day 771 / 971 \n",
      "Predicting Day 772 / 971 \n",
      "Predicting Day 773 / 971 \n",
      "Predicting Day 774 / 971 \n",
      "Predicting Day 775 / 971 \n",
      "Predicting Day 776 / 971 \n",
      "Predicting Day 777 / 971 \n",
      "Predicting Day 778 / 971 \n",
      "Predicting Day 779 / 971 \n",
      "Predicting Day 780 / 971 \n",
      "Predicting Day 781 / 971 \n",
      "Predicting Day 782 / 971 \n",
      "Predicting Day 783 / 971 \n",
      "Predicting Day 784 / 971 \n",
      "Predicting Day 785 / 971 \n",
      "Predicting Day 786 / 971 \n",
      "Predicting Day 787 / 971 \n",
      "Predicting Day 788 / 971 \n",
      "Predicting Day 789 / 971 \n",
      "Predicting Day 790 / 971 \n",
      "Predicting Day 791 / 971 \n",
      "Predicting Day 792 / 971 \n",
      "Predicting Day 793 / 971 \n",
      "Predicting Day 794 / 971 \n",
      "Predicting Day 795 / 971 \n",
      "Predicting Day 796 / 971 \n",
      "Predicting Day 797 / 971 \n",
      "Predicting Day 798 / 971 \n",
      "Predicting Day 799 / 971 \n",
      "Predicting Day 800 / 971 \n",
      "Predicting Day 801 / 971 \n",
      "Predicting Day 802 / 971 \n",
      "Predicting Day 803 / 971 \n",
      "Predicting Day 804 / 971 \n",
      "Predicting Day 805 / 971 \n",
      "Predicting Day 806 / 971 \n",
      "Predicting Day 807 / 971 \n",
      "Predicting Day 808 / 971 \n",
      "Predicting Day 809 / 971 \n",
      "Predicting Day 810 / 971 \n",
      "Predicting Day 811 / 971 \n",
      "Predicting Day 812 / 971 \n",
      "Predicting Day 813 / 971 \n",
      "Predicting Day 814 / 971 \n",
      "Predicting Day 815 / 971 \n",
      "Predicting Day 816 / 971 \n",
      "Predicting Day 817 / 971 \n",
      "Predicting Day 818 / 971 \n",
      "Predicting Day 819 / 971 \n",
      "Predicting Day 820 / 971 \n",
      "Predicting Day 821 / 971 \n",
      "Predicting Day 822 / 971 \n",
      "Predicting Day 823 / 971 \n",
      "Predicting Day 824 / 971 \n",
      "Predicting Day 825 / 971 \n",
      "Predicting Day 826 / 971 \n",
      "Predicting Day 827 / 971 \n",
      "Predicting Day 828 / 971 \n",
      "Predicting Day 829 / 971 \n",
      "Predicting Day 830 / 971 \n",
      "Predicting Day 831 / 971 \n",
      "Predicting Day 832 / 971 \n",
      "Predicting Day 833 / 971 \n",
      "Predicting Day 834 / 971 \n",
      "Predicting Day 835 / 971 \n",
      "Predicting Day 836 / 971 \n",
      "Predicting Day 837 / 971 \n",
      "Predicting Day 838 / 971 \n",
      "Predicting Day 839 / 971 \n",
      "Predicting Day 840 / 971 \n",
      "Predicting Day 841 / 971 \n",
      "Predicting Day 842 / 971 \n",
      "Predicting Day 843 / 971 \n",
      "Predicting Day 844 / 971 \n",
      "Predicting Day 845 / 971 \n",
      "Predicting Day 846 / 971 \n",
      "Predicting Day 847 / 971 \n",
      "Predicting Day 848 / 971 \n",
      "Predicting Day 849 / 971 \n",
      "Predicting Day 850 / 971 \n",
      "Predicting Day 851 / 971 \n",
      "Predicting Day 852 / 971 \n",
      "Predicting Day 853 / 971 \n",
      "Predicting Day 854 / 971 \n",
      "Predicting Day 855 / 971 \n",
      "Predicting Day 856 / 971 \n",
      "Predicting Day 857 / 971 \n",
      "Predicting Day 858 / 971 \n",
      "Predicting Day 859 / 971 \n",
      "Predicting Day 860 / 971 \n",
      "Predicting Day 861 / 971 \n",
      "Predicting Day 862 / 971 \n",
      "Predicting Day 863 / 971 \n",
      "Predicting Day 864 / 971 \n",
      "Predicting Day 865 / 971 \n",
      "Predicting Day 866 / 971 \n",
      "Predicting Day 867 / 971 \n",
      "Predicting Day 868 / 971 \n",
      "Predicting Day 869 / 971 \n",
      "Predicting Day 870 / 971 \n",
      "Predicting Day 871 / 971 \n",
      "Predicting Day 872 / 971 \n",
      "Predicting Day 873 / 971 \n",
      "Predicting Day 874 / 971 \n",
      "Predicting Day 875 / 971 \n",
      "Predicting Day 876 / 971 \n",
      "Predicting Day 877 / 971 \n",
      "Predicting Day 878 / 971 \n",
      "Predicting Day 879 / 971 \n",
      "Predicting Day 880 / 971 \n",
      "Predicting Day 881 / 971 \n",
      "Predicting Day 882 / 971 \n",
      "Predicting Day 883 / 971 \n",
      "Predicting Day 884 / 971 \n",
      "Predicting Day 885 / 971 \n",
      "Predicting Day 886 / 971 \n",
      "Predicting Day 887 / 971 \n",
      "Predicting Day 888 / 971 \n",
      "Predicting Day 889 / 971 \n",
      "Predicting Day 890 / 971 \n",
      "Predicting Day 891 / 971 \n",
      "Predicting Day 892 / 971 \n",
      "Predicting Day 893 / 971 \n",
      "Predicting Day 894 / 971 \n",
      "Predicting Day 895 / 971 \n",
      "Predicting Day 896 / 971 \n",
      "Predicting Day 897 / 971 \n",
      "Predicting Day 898 / 971 \n",
      "Predicting Day 899 / 971 \n",
      "Predicting Day 900 / 971 \n",
      "Predicting Day 901 / 971 \n",
      "Predicting Day 902 / 971 \n",
      "Predicting Day 903 / 971 \n",
      "Predicting Day 904 / 971 \n",
      "Predicting Day 905 / 971 \n",
      "Predicting Day 906 / 971 \n",
      "Predicting Day 907 / 971 \n",
      "Predicting Day 908 / 971 \n",
      "Predicting Day 909 / 971 \n",
      "Predicting Day 910 / 971 \n",
      "Predicting Day 911 / 971 \n",
      "Predicting Day 912 / 971 \n",
      "Predicting Day 913 / 971 \n",
      "Predicting Day 914 / 971 \n",
      "Predicting Day 915 / 971 \n",
      "Predicting Day 916 / 971 \n",
      "Predicting Day 917 / 971 \n",
      "Predicting Day 918 / 971 \n",
      "Predicting Day 919 / 971 \n",
      "Predicting Day 920 / 971 \n",
      "Predicting Day 921 / 971 \n",
      "Predicting Day 922 / 971 \n",
      "Predicting Day 923 / 971 \n",
      "Predicting Day 924 / 971 \n",
      "Predicting Day 925 / 971 \n",
      "Predicting Day 926 / 971 \n",
      "Predicting Day 927 / 971 \n",
      "Predicting Day 928 / 971 \n",
      "Predicting Day 929 / 971 \n",
      "Predicting Day 930 / 971 \n",
      "Predicting Day 931 / 971 \n",
      "Predicting Day 932 / 971 \n",
      "Predicting Day 933 / 971 \n",
      "Predicting Day 934 / 971 \n",
      "Predicting Day 935 / 971 \n",
      "Predicting Day 936 / 971 \n",
      "Predicting Day 937 / 971 \n",
      "Predicting Day 938 / 971 \n",
      "Predicting Day 939 / 971 \n",
      "Predicting Day 940 / 971 \n",
      "Predicting Day 941 / 971 \n",
      "Predicting Day 942 / 971 \n",
      "Predicting Day 943 / 971 \n",
      "Predicting Day 944 / 971 \n",
      "Predicting Day 945 / 971 \n",
      "Predicting Day 946 / 971 \n",
      "Predicting Day 947 / 971 \n",
      "Predicting Day 948 / 971 \n",
      "Predicting Day 949 / 971 \n",
      "Predicting Day 950 / 971 \n",
      "Predicting Day 951 / 971 \n",
      "Predicting Day 952 / 971 \n",
      "Predicting Day 953 / 971 \n",
      "Predicting Day 954 / 971 \n",
      "Predicting Day 955 / 971 \n",
      "Predicting Day 956 / 971 \n",
      "Predicting Day 957 / 971 \n",
      "Predicting Day 958 / 971 \n",
      "Predicting Day 959 / 971 \n",
      "Predicting Day 960 / 971 \n",
      "Predicting Day 961 / 971 \n",
      "Predicting Day 962 / 971 \n",
      "Predicting Day 963 / 971 \n",
      "Predicting Day 964 / 971 \n",
      "Predicting Day 965 / 971 \n",
      "Predicting Day 966 / 971 \n",
      "Predicting Day 967 / 971 \n",
      "Predicting Day 968 / 971 \n",
      "Predicting Day 969 / 971 \n",
      "Predicting Day 970 / 971 \n",
      "Predicting Day 971 / 971 \n"
     ]
    }
   ],
   "source": [
    "df_model = pred_training_set(model_training_set, first_test_season - time_horizon, last_test_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4556b094-3627-4ed1-bc43-f5ad9a1625f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = XGBClassifier(n_estimators = 100, eta = 0.05, max_depth = 4, subsample = 0.5, colsample_bytree = 0.5, alpha = 1, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd0f0aa-0345-455c-b469-3a4989c02c30",
   "metadata": {},
   "source": [
    "#### Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e54a4476-ea51-44f9-bb59-70823f83ce8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6349288042545891\n"
     ]
    }
   ],
   "source": [
    "correct, games = test_model(df_rolling, final_model, test_set)\n",
    "print(\"Score:\", correct / games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c373a6-8414-46e2-baa5-61c801b9802e",
   "metadata": {},
   "source": [
    "#### ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1cbbb170-3761-48c7-94ec-345883c6bf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.979241722422371\n"
     ]
    }
   ],
   "source": [
    "correct, games = test_model(df_model, final_model, test_set)\n",
    "print(\"Score:\", correct / games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a175568f-207e-48af-870c-97b182623772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-04-14 00:00:00')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model['GAME_DATE'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "27a8a06d-5e7b-40d6-a9fa-6e596c279d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model[df_rolling.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "40d4e02d-84bc-40bc-9f31-8a4343ce0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.sort_values(by = ['TEAM_ID_ONE', 'GAME_DATE'])\n",
    "df_rolling_part = df_rolling[df_rolling['SEASON_YEAR'].between(2014, 2023)].sort_values(by = ['TEAM_ID_ONE', 'GAME_DATE'])\n",
    "combined_stats_part = combined_stats[combined_stats['SEASON_YEAR'].between(2014, 2023)].sort_values(by = ['TEAM_ID_ONE', 'GAME_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7fcb7c26-4201-48ac-b1a0-da2fda9c7124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WIN_LAST_ONE</th>\n",
       "      <th>TEAM_ID_TWO</th>\n",
       "      <th>FG_PCT_TWO</th>\n",
       "      <th>FG3_PCT_TWO</th>\n",
       "      <th>FT_PCT_TWO</th>\n",
       "      <th>OREB_TWO</th>\n",
       "      <th>DREB_TWO</th>\n",
       "      <th>REB_TWO</th>\n",
       "      <th>AST_TWO</th>\n",
       "      <th>STL_TWO</th>\n",
       "      <th>BLK_TWO</th>\n",
       "      <th>TOV_TWO</th>\n",
       "      <th>PF_TWO</th>\n",
       "      <th>SEASON_YEAR</th>\n",
       "      <th>EFG%_TWO</th>\n",
       "      <th>TS%_TWO</th>\n",
       "      <th>WIN_STREAK_TWO</th>\n",
       "      <th>WIN_PERCENTAGE_TWO</th>\n",
       "      <th>ELO_TWO</th>\n",
       "      <th>WIN_LAST_TWO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.489568</td>\n",
       "      <td>0.335449</td>\n",
       "      <td>0.665901</td>\n",
       "      <td>12.724613</td>\n",
       "      <td>34.938010</td>\n",
       "      <td>44.368960</td>\n",
       "      <td>19.677550</td>\n",
       "      <td>6.821535</td>\n",
       "      <td>3.224573</td>\n",
       "      <td>14.741632</td>\n",
       "      <td>18.017159</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.673542</td>\n",
       "      <td>0.559697</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416556</td>\n",
       "      <td>1574.766174</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.420344</td>\n",
       "      <td>0.290530</td>\n",
       "      <td>0.829226</td>\n",
       "      <td>10.063592</td>\n",
       "      <td>36.179520</td>\n",
       "      <td>44.801605</td>\n",
       "      <td>20.174774</td>\n",
       "      <td>5.874753</td>\n",
       "      <td>4.138094</td>\n",
       "      <td>16.903025</td>\n",
       "      <td>21.174635</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.578456</td>\n",
       "      <td>0.521106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529816</td>\n",
       "      <td>1533.826551</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.528347</td>\n",
       "      <td>0.455580</td>\n",
       "      <td>0.777013</td>\n",
       "      <td>8.303092</td>\n",
       "      <td>38.414825</td>\n",
       "      <td>49.088240</td>\n",
       "      <td>27.503584</td>\n",
       "      <td>5.487940</td>\n",
       "      <td>7.622308</td>\n",
       "      <td>15.457068</td>\n",
       "      <td>18.050951</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.710087</td>\n",
       "      <td>0.574460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629931</td>\n",
       "      <td>1674.141487</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7280</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.460664</td>\n",
       "      <td>0.377649</td>\n",
       "      <td>0.773966</td>\n",
       "      <td>11.642198</td>\n",
       "      <td>36.507870</td>\n",
       "      <td>44.827686</td>\n",
       "      <td>24.433992</td>\n",
       "      <td>7.021293</td>\n",
       "      <td>6.240212</td>\n",
       "      <td>12.641404</td>\n",
       "      <td>19.289635</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.603931</td>\n",
       "      <td>0.565200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434805</td>\n",
       "      <td>1510.100970</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.413949</td>\n",
       "      <td>0.362901</td>\n",
       "      <td>0.759866</td>\n",
       "      <td>10.345777</td>\n",
       "      <td>30.776129</td>\n",
       "      <td>41.955290</td>\n",
       "      <td>21.843782</td>\n",
       "      <td>5.277457</td>\n",
       "      <td>1.829193</td>\n",
       "      <td>13.854770</td>\n",
       "      <td>20.912514</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.530434</td>\n",
       "      <td>0.499021</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499144</td>\n",
       "      <td>1488.887976</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WIN_LAST_ONE  TEAM_ID_TWO  FG_PCT_TWO  FG3_PCT_TWO  FT_PCT_TWO  \\\n",
       "7213           0.0           24    0.489568     0.335449    0.665901   \n",
       "26             1.0           17    0.420344     0.290530    0.829226   \n",
       "7265           0.0           22    0.528347     0.455580    0.777013   \n",
       "7280           0.0           29    0.460664     0.377649    0.773966   \n",
       "81             1.0           15    0.413949     0.362901    0.759866   \n",
       "\n",
       "       OREB_TWO   DREB_TWO    REB_TWO    AST_TWO   STL_TWO   BLK_TWO  \\\n",
       "7213  12.724613  34.938010  44.368960  19.677550  6.821535  3.224573   \n",
       "26    10.063592  36.179520  44.801605  20.174774  5.874753  4.138094   \n",
       "7265   8.303092  38.414825  49.088240  27.503584  5.487940  7.622308   \n",
       "7280  11.642198  36.507870  44.827686  24.433992  7.021293  6.240212   \n",
       "81    10.345777  30.776129  41.955290  21.843782  5.277457  1.829193   \n",
       "\n",
       "        TOV_TWO     PF_TWO  SEASON_YEAR  EFG%_TWO   TS%_TWO  WIN_STREAK_TWO  \\\n",
       "7213  14.741632  18.017159         2014  0.673542  0.559697               0   \n",
       "26    16.903025  21.174635         2014  0.578456  0.521106               0   \n",
       "7265  15.457068  18.050951         2014  0.710087  0.574460               0   \n",
       "7280  12.641404  19.289635         2014  0.603931  0.565200               1   \n",
       "81    13.854770  20.912514         2014  0.530434  0.499021               0   \n",
       "\n",
       "      WIN_PERCENTAGE_TWO      ELO_TWO  WIN_LAST_TWO  \n",
       "7213            0.416556  1574.766174           1.0  \n",
       "26              0.529816  1533.826551           0.0  \n",
       "7265            0.629931  1674.141487           1.0  \n",
       "7280            0.434805  1510.100970           1.0  \n",
       "81              0.499144  1488.887976           0.0  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.iloc[:5, 20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d7f0b3c3-edc2-459e-92d8-9d8e33e0123f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WIN_LAST_ONE</th>\n",
       "      <th>TEAM_ID_TWO</th>\n",
       "      <th>FG_PCT_TWO</th>\n",
       "      <th>FG3_PCT_TWO</th>\n",
       "      <th>FT_PCT_TWO</th>\n",
       "      <th>OREB_TWO</th>\n",
       "      <th>DREB_TWO</th>\n",
       "      <th>REB_TWO</th>\n",
       "      <th>AST_TWO</th>\n",
       "      <th>STL_TWO</th>\n",
       "      <th>BLK_TWO</th>\n",
       "      <th>TOV_TWO</th>\n",
       "      <th>PF_TWO</th>\n",
       "      <th>SEASON_YEAR</th>\n",
       "      <th>EFG%_TWO</th>\n",
       "      <th>TS%_TWO</th>\n",
       "      <th>WIN_STREAK_TWO</th>\n",
       "      <th>WIN_PERCENTAGE_TWO</th>\n",
       "      <th>ELO_TWO</th>\n",
       "      <th>WIN_LAST_TWO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48278</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.4590</td>\n",
       "      <td>0.4148</td>\n",
       "      <td>0.7706</td>\n",
       "      <td>11.8</td>\n",
       "      <td>30.4</td>\n",
       "      <td>42.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>14.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.681119</td>\n",
       "      <td>0.582714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416556</td>\n",
       "      <td>1574.766174</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.4798</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.653826</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529816</td>\n",
       "      <td>1533.826551</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48279</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.4478</td>\n",
       "      <td>0.3642</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>8.6</td>\n",
       "      <td>34.8</td>\n",
       "      <td>43.4</td>\n",
       "      <td>23.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>11.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.622998</td>\n",
       "      <td>0.538621</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629931</td>\n",
       "      <td>1674.141487</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48280</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.3072</td>\n",
       "      <td>0.7412</td>\n",
       "      <td>9.4</td>\n",
       "      <td>33.6</td>\n",
       "      <td>43.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.526557</td>\n",
       "      <td>0.501114</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434805</td>\n",
       "      <td>1510.100970</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.4808</td>\n",
       "      <td>0.7640</td>\n",
       "      <td>11.6</td>\n",
       "      <td>28.2</td>\n",
       "      <td>39.8</td>\n",
       "      <td>23.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>24.4</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.593362</td>\n",
       "      <td>0.529088</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499144</td>\n",
       "      <td>1488.887976</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       WIN_LAST_ONE  TEAM_ID_TWO  FG_PCT_TWO  FG3_PCT_TWO  FT_PCT_TWO  \\\n",
       "48278           0.0           24      0.4590       0.4148      0.7706   \n",
       "4219            1.0           17      0.4798       0.4400      0.7600   \n",
       "48279           0.0           22      0.4478       0.3642      0.8108   \n",
       "48280           0.0           29      0.4256       0.3072      0.7412   \n",
       "4220            1.0           15      0.4500       0.4808      0.7640   \n",
       "\n",
       "       OREB_TWO  DREB_TWO  REB_TWO  AST_TWO  STL_TWO  BLK_TWO  TOV_TWO  \\\n",
       "48278      11.8      30.4     42.2     21.6      6.4      3.8     14.4   \n",
       "4219       11.0      34.0     45.0     22.0      4.6      5.0     17.4   \n",
       "48279       8.6      34.8     43.4     23.2      4.8      3.8     11.4   \n",
       "48280       9.4      33.6     43.0     22.0      7.0      5.0     14.2   \n",
       "4220       11.6      28.2     39.8     23.2      5.8      3.2     14.8   \n",
       "\n",
       "       PF_TWO  SEASON_YEAR  EFG%_TWO   TS%_TWO  WIN_STREAK_TWO  \\\n",
       "48278    23.4         2014  0.681119  0.582714               0   \n",
       "4219     20.0         2014  0.653826  0.570423               0   \n",
       "48279    20.4         2014  0.622998  0.538621               0   \n",
       "48280    18.2         2014  0.526557  0.501114               1   \n",
       "4220     24.4         2014  0.593362  0.529088               0   \n",
       "\n",
       "       WIN_PERCENTAGE_TWO      ELO_TWO  WIN_LAST_TWO  \n",
       "48278            0.416556  1574.766174           1.0  \n",
       "4219             0.529816  1533.826551           0.0  \n",
       "48279            0.629931  1674.141487           1.0  \n",
       "48280            0.434805  1510.100970           1.0  \n",
       "4220             0.499144  1488.887976           0.0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rolling_part.iloc[:5, 20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "713d551e-3dec-44f9-a05e-d732d998567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats_part = combined_stats_part[df_rolling.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e9b4c380-e782-403f-80ca-f160efe95c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WIN_LAST_ONE</th>\n",
       "      <th>TEAM_ID_TWO</th>\n",
       "      <th>FG_PCT_TWO</th>\n",
       "      <th>FG3_PCT_TWO</th>\n",
       "      <th>FT_PCT_TWO</th>\n",
       "      <th>OREB_TWO</th>\n",
       "      <th>DREB_TWO</th>\n",
       "      <th>REB_TWO</th>\n",
       "      <th>AST_TWO</th>\n",
       "      <th>STL_TWO</th>\n",
       "      <th>BLK_TWO</th>\n",
       "      <th>TOV_TWO</th>\n",
       "      <th>PF_TWO</th>\n",
       "      <th>SEASON_YEAR</th>\n",
       "      <th>EFG%_TWO</th>\n",
       "      <th>TS%_TWO</th>\n",
       "      <th>WIN_STREAK_TWO</th>\n",
       "      <th>WIN_PERCENTAGE_TWO</th>\n",
       "      <th>ELO_TWO</th>\n",
       "      <th>WIN_LAST_TWO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65595</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.818</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.521431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416556</td>\n",
       "      <td>1575.940065</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65649</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.857</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>44</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>0.509752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529816</td>\n",
       "      <td>1541.582470</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65710</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.711</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.557971</td>\n",
       "      <td>0.548297</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629931</td>\n",
       "      <td>1664.654161</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65731</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.741</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.560250</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434805</td>\n",
       "      <td>1518.897711</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65749</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.727</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.540297</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499144</td>\n",
       "      <td>1487.585170</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       WIN_LAST_ONE  TEAM_ID_TWO  FG_PCT_TWO  FG3_PCT_TWO  FT_PCT_TWO  \\\n",
       "65595           0.0           24       0.411        0.308       0.818   \n",
       "65649           1.0           17       0.383        0.375       0.857   \n",
       "65710           0.0           22       0.449        0.294       0.711   \n",
       "65731           0.0           29       0.495        0.286       0.741   \n",
       "65749           1.0           15       0.476        0.381       0.727   \n",
       "\n",
       "       OREB_TWO  DREB_TWO  REB_TWO  AST_TWO  STL_TWO  BLK_TWO  TOV_TWO  \\\n",
       "65595        16        32       48       26       13        9     10.0   \n",
       "65649        11        33       44       25        5        5     18.0   \n",
       "65710        11        39       50       25        7        9     21.0   \n",
       "65731        11        40       51       31        6        7     21.0   \n",
       "65749        13        31       44       26        2        6     15.0   \n",
       "\n",
       "       PF_TWO  SEASON_YEAR  EFG%_TWO   TS%_TWO  WIN_STREAK_TWO  \\\n",
       "65595      22         2014  0.544444  0.521431               0   \n",
       "65649      26         2014  0.604938  0.509752               0   \n",
       "65710      15         2014  0.557971  0.548297               0   \n",
       "65731      30         2014  0.587629  0.560250               1   \n",
       "65749      29         2014  0.619048  0.540297               0   \n",
       "\n",
       "       WIN_PERCENTAGE_TWO      ELO_TWO  WIN_LAST_TWO  \n",
       "65595            0.416556  1575.940065           1.0  \n",
       "65649            0.529816  1541.582470           0.0  \n",
       "65710            0.629931  1664.654161           1.0  \n",
       "65731            0.434805  1518.897711           1.0  \n",
       "65749            0.499144  1487.585170           0.0  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_stats_part.iloc[:5, 20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "88011b4d-8c06-486e-bda0-76874aa1a074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23958, 40)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "88e29cd1-f190-49f3-a969-9c789ce37a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23958, 40)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "26069ec1-8db4-4b5d-9e45-04aa171cb7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23958, 40)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_stats_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a0995-a690-4ff3-a22f-6a423fc2c7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
