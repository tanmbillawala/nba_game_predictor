{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42d26fd-3ce7-4b46-852f-eaba07eb0c33",
   "metadata": {},
   "source": [
    "# NBA Game Statistics Predictor\n",
    "### CMPE 257 Project\n",
    "Authors: Kaushika Uppu, Miranda Billawala, Yun Ei Hlaing, Iris Cheung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25214fa-c1ec-41ce-8261-a4e19e2d4f3d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2883a1e4-3ea5-476a-8414-5aa55d1f2a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6350c5-b1fd-4af3-9b86-158631f3a8c4",
   "metadata": {},
   "source": [
    "## NBA Game Data\n",
    "First, we load in all of the NBA game data from the CSV file. Exact code for gathering data is in a separate file and use the nba_api file. Only games from the 1985-1986 season and afterward are loaded in as the seasons before that are missing a very significant portion of the game statistics' data. We also want to be able to map from team id to abbreviation and back easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ea3ddd-9e97-4547-a78d-52853fd15d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>HOME</th>\n",
       "      <th>OPPONENT</th>\n",
       "      <th>WIN</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>...</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>SEASON_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>IND</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>38</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>59</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21</td>\n",
       "      <td>108</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-10</td>\n",
       "      <td>1</td>\n",
       "      <td>NJN</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>44</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26</td>\n",
       "      <td>126</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>52</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22</td>\n",
       "      <td>131</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-05</td>\n",
       "      <td>0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>40</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28</td>\n",
       "      <td>97</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>54</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37</td>\n",
       "      <td>129</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEAM_ID TEAM_ABBREVIATION      TEAM_NAME  GAME_DATE  HOME OPPONENT  WIN  \\\n",
       "0        0               ATL  Atlanta Hawks 1986-04-12     1      IND    1   \n",
       "1        0               ATL  Atlanta Hawks 1986-04-10     1      NJN    1   \n",
       "2        0               ATL  Atlanta Hawks 1986-04-08     1      CHI    1   \n",
       "3        0               ATL  Atlanta Hawks 1986-04-05     0      CHI    0   \n",
       "4        0               ATL  Atlanta Hawks 1986-04-04     0      WAS    0   \n",
       "\n",
       "     MIN  FGM  FGA  ...  DREB  REB  AST  STL  BLK   TOV  PF  PTS  PLUS_MINUS  \\\n",
       "0  240.0   38   88  ...    39   59   22    6    3  12.0  21  108        17.0   \n",
       "1  240.0   44   87  ...    27   42   30   15    5  22.0  26  126         9.0   \n",
       "2  240.0   52   98  ...    25   42   33   13    6  10.0  22  131        13.0   \n",
       "3  240.0   40   76  ...    25   38   17    7    7  21.0  28   97        -5.0   \n",
       "4  265.0   54  100  ...    28   45   24    6    7  14.0  37  129        -6.0   \n",
       "\n",
       "   SEASON_YEAR  \n",
       "0         1985  \n",
       "1         1985  \n",
       "2         1985  \n",
       "3         1985  \n",
       "4         1985  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stats_cleaned = pd.read_csv('all_stats_cleaned.csv')\n",
    "all_stats_cleaned['GAME_DATE'] = pd.to_datetime(all_stats_cleaned['GAME_DATE'], format='ISO8601') # convert date to datetime object\n",
    "\n",
    "all_stats_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eafaf1dc-8746-40e3-bb94-f463c25e023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_id_to_abb = {} # dictionary to convert from team_id to team_abbreviation\n",
    "team_abb_to_id = {} # dictionary to convert from team_abbreviation to team_id\n",
    "\n",
    "teams = (all_stats_cleaned[['TEAM_ID', 'TEAM_ABBREVIATION']]).drop_duplicates()\n",
    "\n",
    "for index, row in teams.iterrows() :\n",
    "    if row['TEAM_ID'] not in team_id_to_abb.keys():\n",
    "        team_id_to_abb[row['TEAM_ID']] = []\n",
    "    team_id_to_abb[row['TEAM_ID']].append(row['TEAM_ABBREVIATION'])\n",
    "    team_abb_to_id[row['TEAM_ABBREVIATION']] = row['TEAM_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11030cf2-2332-4a7b-8fb1-956d5c9dd414",
   "metadata": {},
   "source": [
    "### Merging Home and Away Team Stats Into One Row\n",
    "Currently, each game is represented by two separate rows in the dataset - one for the home team and one for the away team. To make the data more clear, we decided to combine the two rows into a single row with statistics for both teams. Since predicting with our model will pass one set order of team one and team two (i.e. Lakers as Team One, Warriors as Team Two), we want to make sure that the model realizes games with the Lakers as Team Two and Warriors as Team One are more similar than may appear by the data. To do this, we will duplicate the rows and flip the teams. Then, we will have each game listed twice with the teams flipped. \n",
    "\n",
    "Firstly, we split the dataset into two : home games and away games. Then, we performed a join on these two datasets, matching each home team with its corresponding opponent based on the same dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f46a086-28f9-42e3-a748-479413bdd2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = all_stats_cleaned[all_stats_cleaned.HOME == 1]\n",
    "away = all_stats_cleaned[all_stats_cleaned.HOME == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54962ac3-291e-4a12-b5ee-510b236162a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM_ID_ONE</th>\n",
       "      <th>TEAM_ABBREVIATION_ONE</th>\n",
       "      <th>TEAM_NAME_ONE</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>HOME_ONE</th>\n",
       "      <th>OPPONENT_ONE</th>\n",
       "      <th>WIN_ONE</th>\n",
       "      <th>MIN_ONE</th>\n",
       "      <th>FGM_ONE</th>\n",
       "      <th>FGA_ONE</th>\n",
       "      <th>...</th>\n",
       "      <th>DREB_TWO</th>\n",
       "      <th>REB_TWO</th>\n",
       "      <th>AST_TWO</th>\n",
       "      <th>STL_TWO</th>\n",
       "      <th>BLK_TWO</th>\n",
       "      <th>TOV_TWO</th>\n",
       "      <th>PF_TWO</th>\n",
       "      <th>PTS_TWO</th>\n",
       "      <th>PLUS_MINUS_TWO</th>\n",
       "      <th>SEASON_YEAR_TWO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>IND</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>38</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33</td>\n",
       "      <td>91</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-10</td>\n",
       "      <td>1</td>\n",
       "      <td>NJN</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>44</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30</td>\n",
       "      <td>117</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>52</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26</td>\n",
       "      <td>118</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>41</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22</td>\n",
       "      <td>91</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>1986-03-29</td>\n",
       "      <td>1</td>\n",
       "      <td>CLE</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>36</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32</td>\n",
       "      <td>123</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEAM_ID_ONE TEAM_ABBREVIATION_ONE  TEAM_NAME_ONE  GAME_DATE  HOME_ONE  \\\n",
       "0            0                   ATL  Atlanta Hawks 1986-04-12         1   \n",
       "1            0                   ATL  Atlanta Hawks 1986-04-10         1   \n",
       "2            0                   ATL  Atlanta Hawks 1986-04-08         1   \n",
       "3            0                   ATL  Atlanta Hawks 1986-04-01         1   \n",
       "4            0                   ATL  Atlanta Hawks 1986-03-29         1   \n",
       "\n",
       "  OPPONENT_ONE  WIN_ONE  MIN_ONE  FGM_ONE  FGA_ONE  ...  DREB_TWO  REB_TWO  \\\n",
       "0          IND        1    240.0       38       88  ...        36       43   \n",
       "1          NJN        1    240.0       44       87  ...        30       44   \n",
       "2          CHI        1    240.0       52       98  ...        35       44   \n",
       "3          WAS        1    240.0       41       90  ...        30       46   \n",
       "4          CLE        0    240.0       36       84  ...        25       33   \n",
       "\n",
       "   AST_TWO  STL_TWO  BLK_TWO  TOV_TWO  PF_TWO  PTS_TWO  PLUS_MINUS_TWO  \\\n",
       "0       22        7        3     13.0      33       91           -17.0   \n",
       "1       25       10        1     24.0      30      117            -9.0   \n",
       "2       29        5        1     17.0      26      118           -13.0   \n",
       "3       19       10        6     17.0      22       91           -16.0   \n",
       "4       31        8        5     16.0      32      123            18.0   \n",
       "\n",
       "   SEASON_YEAR_TWO  \n",
       "0             1985  \n",
       "1             1985  \n",
       "2             1985  \n",
       "3             1985  \n",
       "4             1985  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_stats_home = pd.merge(home, away, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "combined_stats_away = pd.merge(away, home, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "\n",
    "combined_stats = pd.concat([combined_stats_home, combined_stats_away], ignore_index = True)\n",
    "combined_stats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7f909-70bb-4176-b60b-3105225981cd",
   "metadata": {},
   "source": [
    "After merging the rows, there are some columns that appear twice or are now unneccessary to the dataset. These columns include `MIN_ONE`/`MIN_TWO` (length of game in minutes), `SEASON_YEAR_ONE`/`SEASON_YEAR_TWO`, `OPPONENT_ONE` and `OPPONENT_TWO`. We first checked if the `MIN_ONE` and `MIN_TWO` for each row has the same values. As seen below, there are 24 games where the minutes differed slightly. However, since the difference did not seem to be significant, we decided to retain one column and rename it `MIN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12bc732c-6265-46ef-86bc-3c82ea97d414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(48)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(combined_stats['MIN_ONE'] != combined_stats['MIN_TWO']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f1b9bb9-eabe-4aaf-8a5d-7b1a89962272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIN_ONE</th>\n",
       "      <th>MIN_TWO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.637333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.906667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.517333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.357667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19857</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.599333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.813333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25946</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.456000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30645</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>52.906667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32173</th>\n",
       "      <td>47.881000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32176</th>\n",
       "      <td>47.700333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32177</th>\n",
       "      <td>47.706667</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32180</th>\n",
       "      <td>52.743333</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32206</th>\n",
       "      <td>47.443333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32208</th>\n",
       "      <td>57.716333</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32209</th>\n",
       "      <td>47.643333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32210</th>\n",
       "      <td>47.703333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32211</th>\n",
       "      <td>47.697000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32213</th>\n",
       "      <td>47.524000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35307</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35337</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.601333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36488</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.399667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38059</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42338</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.808333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58306</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62873</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>57.716333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64441</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.643333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70366</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.443333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75033</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.700333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76630</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.697000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78163</th>\n",
       "      <td>47.448000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78165</th>\n",
       "      <td>47.813333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78166</th>\n",
       "      <td>47.570000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78172</th>\n",
       "      <td>47.906667</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78176</th>\n",
       "      <td>47.517333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78189</th>\n",
       "      <td>47.599333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78190</th>\n",
       "      <td>47.808333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78192</th>\n",
       "      <td>47.456000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78193</th>\n",
       "      <td>47.399667</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78194</th>\n",
       "      <td>47.637333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78195</th>\n",
       "      <td>52.906667</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78197</th>\n",
       "      <td>47.601333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78198</th>\n",
       "      <td>47.707000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78200</th>\n",
       "      <td>47.357667</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79732</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>52.743333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81329</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.703333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84011</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.881000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85170</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.706667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MIN_ONE    MIN_TWO\n",
       "455    48.000000  47.448000\n",
       "3612   48.000000  47.637333\n",
       "6039   48.000000  47.906667\n",
       "7608   48.000000  47.517333\n",
       "12325  48.000000  47.357667\n",
       "19857  48.000000  47.599333\n",
       "24354  48.000000  47.813333\n",
       "25946  48.000000  47.456000\n",
       "30645  53.000000  52.906667\n",
       "32173  47.881000  48.000000\n",
       "32176  47.700333  48.000000\n",
       "32177  47.706667  48.000000\n",
       "32180  52.743333  53.000000\n",
       "32206  47.443333  48.000000\n",
       "32208  57.716333  58.000000\n",
       "32209  47.643333  48.000000\n",
       "32210  47.703333  48.000000\n",
       "32211  47.697000  48.000000\n",
       "32213  47.524000  48.000000\n",
       "35307  48.000000  47.570000\n",
       "35337  48.000000  47.601333\n",
       "36488  48.000000  47.399667\n",
       "38059  48.000000  47.707000\n",
       "42338  48.000000  47.808333\n",
       "58306  48.000000  47.524000\n",
       "62873  58.000000  57.716333\n",
       "64441  48.000000  47.643333\n",
       "70366  48.000000  47.443333\n",
       "75033  48.000000  47.700333\n",
       "76630  48.000000  47.697000\n",
       "78163  47.448000  48.000000\n",
       "78165  47.813333  48.000000\n",
       "78166  47.570000  48.000000\n",
       "78172  47.906667  48.000000\n",
       "78176  47.517333  48.000000\n",
       "78189  47.599333  48.000000\n",
       "78190  47.808333  48.000000\n",
       "78192  47.456000  48.000000\n",
       "78193  47.399667  48.000000\n",
       "78194  47.637333  48.000000\n",
       "78195  52.906667  53.000000\n",
       "78197  47.601333  48.000000\n",
       "78198  47.707000  48.000000\n",
       "78200  47.357667  48.000000\n",
       "79732  53.000000  52.743333\n",
       "81329  48.000000  47.703333\n",
       "84011  48.000000  47.881000\n",
       "85170  48.000000  47.706667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_stats[combined_stats['MIN_ONE'] != combined_stats['MIN_TWO']][['MIN_ONE','MIN_TWO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7190f75-23a5-42d9-9d86-9f8bf0de731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats = combined_stats.drop(columns = ['MIN_TWO', 'OPPONENT_ONE', 'OPPONENT_TWO', 'SEASON_YEAR_ONE'])\n",
    "combined_stats.rename(columns={'MIN_ONE': 'MIN', 'SEASON_YEAR_TWO': 'SEASON_YEAR'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0086820b-220a-4dfb-8407-e444f67d51e8",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Features to add : \n",
    "1) Win streak\n",
    "2) Win percentage\n",
    "3) ELO Scores\n",
    "4) EFG%\n",
    "5) TS%\n",
    "6) Win last (who won the last game between the two teams playing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff93b8-58b9-434e-9c20-a0eb23fe3a01",
   "metadata": {},
   "source": [
    "### Win Streak and Win Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e0563b4-3b14-4453-bb50-0c4356b17caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_win_streak_and_percentage(df, combined=False):\n",
    "    \"\"\"\n",
    "    Input: Dataframe with team one and team two data for each game and boolean to check if dataframe is combined with both team data\n",
    "    Output: New dataframe with added win streak and win percentage for both teams\n",
    "    \"\"\"\n",
    "    if combined :\n",
    "        team_date_stats = df[['TEAM_ID_ONE', 'GAME_DATE', 'WIN_ONE']].sort_values(by=['TEAM_ID_ONE', 'GAME_DATE']).reset_index(drop=True)\n",
    "        team_date_stats['WIN_STREAK'] = 0\n",
    "        team_date_stats['WIN_PERCENTAGE'] = 0.0\n",
    "        \n",
    "        for team_id, group in team_date_stats.groupby('TEAM_ID_ONE'):\n",
    "            streak = 0\n",
    "            wins = 0\n",
    "            total_games = 0\n",
    "            indices = group.index\n",
    "        \n",
    "            for i in range(len(indices)):\n",
    "                idx = indices[i]\n",
    "        \n",
    "                # WIN STREAK\n",
    "                team_date_stats.at[idx, 'WIN_STREAK'] = streak\n",
    "        \n",
    "                if team_date_stats.at[idx, 'WIN_ONE'] == 1:\n",
    "                    streak += 1\n",
    "                else: \n",
    "                    streak = 0\n",
    "        \n",
    "                # WIN PERCENTAGE\n",
    "                if total_games == 0:\n",
    "                    team_date_stats.at[idx, 'WIN_PERCENTAGE'] = 0.0\n",
    "                else: \n",
    "                    team_date_stats.at[idx, 'WIN_PERCENTAGE'] = wins / total_games\n",
    "        \n",
    "                total_games += 1\n",
    "                if team_date_stats.at[idx, 'WIN_ONE'] == 1:\n",
    "                    wins += 1\n",
    "        # First, prepare a lookup table\n",
    "        stats_lookup = team_date_stats.set_index(['TEAM_ID_ONE', 'GAME_DATE'])\n",
    "        df['WIN_STREAK_ONE'] = df.set_index(['TEAM_ID_ONE', 'GAME_DATE']).index.map(stats_lookup['WIN_STREAK'])\n",
    "        df['WIN_PERCENTAGE_ONE'] = df.set_index(['TEAM_ID_ONE', 'GAME_DATE']).index.map(stats_lookup['WIN_PERCENTAGE'])\n",
    "    \n",
    "        df['WIN_STREAK_TWO'] = df.set_index(['TEAM_ID_TWO', 'GAME_DATE']).index.map(stats_lookup['WIN_STREAK'])\n",
    "        df['WIN_PERCENTAGE_TWO'] = df.set_index(['TEAM_ID_TWO', 'GAME_DATE']).index.map(stats_lookup['WIN_PERCENTAGE'])\n",
    "    \n",
    "    else :\n",
    "        team_date_stats = df[['TEAM_ID', 'GAME_DATE', 'WIN']].sort_values(by=['TEAM_ID', 'GAME_DATE']).reset_index(drop=True)\n",
    "        team_date_stats['WIN_STREAK'] = 0\n",
    "        team_date_stats['WIN_PERCENTAGE'] = 0.0\n",
    "        \n",
    "        for team_id, group in team_date_stats.groupby('TEAM_ID'):\n",
    "            streak = 0\n",
    "            wins = 0\n",
    "            total_games = 0\n",
    "            indices = group.index\n",
    "        \n",
    "            for i in range(len(indices)):\n",
    "                idx = indices[i]\n",
    "        \n",
    "                # WIN STREAK\n",
    "                team_date_stats.at[idx, 'WIN_STREAK'] = streak\n",
    "        \n",
    "                if team_date_stats.at[idx, 'WIN'] == 1:\n",
    "                    streak += 1\n",
    "                else: \n",
    "                    streak = 0\n",
    "        \n",
    "                # WIN PERCENTAGE\n",
    "                if total_games == 0:\n",
    "                    team_date_stats.at[idx, 'WIN_PERCENTAGE'] = 0.0\n",
    "                else: \n",
    "                    team_date_stats.at[idx, 'WIN_PERCENTAGE'] = wins / total_games\n",
    "        \n",
    "                total_games += 1\n",
    "                if team_date_stats.at[idx, 'WIN'] == 1:\n",
    "                    wins += 1\n",
    "        # First, prepare a lookup table\n",
    "        stats_lookup = team_date_stats.set_index(['TEAM_ID', 'GAME_DATE'])\n",
    "        df['WIN_STREAK'] = df.set_index(['TEAM_ID', 'GAME_DATE']).index.map(stats_lookup['WIN_STREAK'])\n",
    "        df['WIN_PERCENTAGE'] = df.set_index(['TEAM_ID', 'GAME_DATE']).index.map(stats_lookup['WIN_PERCENTAGE'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b0396-7068-40d7-a713-3e8ea1d4304a",
   "metadata": {},
   "source": [
    "### ELO Score Before Current Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e4b21d7-a9f8-49cf-832d-3702cce6f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_opponent_points(df):\n",
    "    df_opp = df[['TEAM_ABBREVIATION', 'GAME_DATE', 'PTS', 'TEAM_ID']].copy()\n",
    "    merged_df = pd.merge(df, df_opp, \n",
    "                         how='left',\n",
    "                          left_on=['GAME_DATE', 'OPPONENT'],\n",
    "                            right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('', '_OPPONENT'))\n",
    "    merged_df.drop(columns=['TEAM_ABBREVIATION_OPPONENT'], inplace=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c9c4030-c1db-4c4c-98a4-2699c0830060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elo_score(df, combined=False):\n",
    "    \"\"\"\n",
    "    Input: Dataframe with team one and team two data for each game and boolean to check if dataframe is combined with both team data\n",
    "    Output: New dataframe with elo scores for both teams added \n",
    "    \"\"\"\n",
    "    if combined:\n",
    "        df['GAME_ID'] = df.apply(\n",
    "        lambda row: '_'.join(sorted([str(row['TEAM_ID_ONE']), str(row['TEAM_ID_TWO'])]) + [str(row['GAME_DATE'])]),\n",
    "        axis=1\n",
    "    )\n",
    "        df['ELO_ONE'] = np.nan\n",
    "        df['ELO_TWO'] = np.nan\n",
    "    else:\n",
    "        df = merge_opponent_points(df)\n",
    "        df['ELO'] = np.nan\n",
    "        df['GAME_ID'] = df.apply(\n",
    "        lambda row: '_'.join(sorted([str(row['TEAM_ID']), str(row['TEAM_ID_OPPONENT'])]) + [str(row['GAME_DATE'])]),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    team_elos = {} # to use for checking if a team has appeared and track team last elo scores\n",
    "    team_last_season = {} # to track last seasons of teams\n",
    "    processed_games = set() # to track game id - handle duplicate game columns\n",
    "    elo_map = {} # for faster computation\n",
    "    df = df.sort_values(by='GAME_DATE').reset_index(drop=True)\n",
    "    \n",
    "    for i,row in df.iterrows():\n",
    "        season = row['SEASON_YEAR']\n",
    "        game_id = row['GAME_ID']\n",
    "\n",
    "        if game_id in processed_games:\n",
    "            continue\n",
    "        processed_games.add(game_id)\n",
    "\n",
    "        if combined:\n",
    "            team_one, team_two = row['TEAM_ID_ONE'], row['TEAM_ID_TWO']\n",
    "            points_one, points_two = row['PTS_ONE'], row['PTS_TWO']\n",
    "            home_one = row['HOME_ONE']\n",
    "        \n",
    "            # Season adjustment formula for ELO : New Season ELO = 0.75 * Last Season ELO + 0.25 * Mean ELO, Mean ELO = 1505\n",
    "            for team in [team_one, team_two]:\n",
    "                # check if team has not appeared yet in the dataset\n",
    "                if team not in team_elos:\n",
    "                    team_elos[team] = 1505 \n",
    "                    team_last_season[team] = season\n",
    "                # check for new season, if yes, apply season adjustment\n",
    "                elif team_last_season[team] != season:\n",
    "                    team_elos[team] = 0.75 * team_elos[team] + 0.25 * 1505\n",
    "                    team_last_season[team] = season\n",
    "        \n",
    "            # elo scores before game\n",
    "            elo_one = team_elos[team_one]\n",
    "            elo_two = team_elos[team_two]\n",
    "        \n",
    "            # Add 100 score to home team\n",
    "            if home_one == 1:\n",
    "                elo_one_after_home_adv = elo_one + 100 \n",
    "                elo_two_after_home_adv = elo_two\n",
    "            else:\n",
    "                elo_one_after_home_adv = elo_one \n",
    "                elo_two_after_home_adv = elo_two + 100\n",
    "        \n",
    "            # Expected score of game formula : exp = 1/ (1+10^((ELO two after home advantage - ELO one after home advantage) / 400))\n",
    "            exp = 1/ (1+10**((elo_two_after_home_adv - elo_one_after_home_adv) / 400))\n",
    "        \n",
    "            actual = 1 if points_one > points_two else 0\n",
    "            margin_of_victory = abs(points_one - points_two)\n",
    "        \n",
    "            # Margin of Victory Multiplier formula : ((MOV + 3) ** 0.8) / (7.5 + 0.006 * (Elo team one - Elo team two))\n",
    "            MOVM = ((margin_of_victory + 3) ** 0.8) / (7.5 + 0.006 * (elo_one - elo_two))\n",
    "        \n",
    "            # change in ELO: K * MOVM * (actual - exp), k -> attenuation factor -> higher means elo score adjusts quickly to changes in strength of team\n",
    "            K = 20 # 20 is optimal for nba \n",
    "            change = K * MOVM * (actual - exp)\n",
    "    \n",
    "            # Update data for ELO ratings\n",
    "            team_elos[team_one] += change\n",
    "            team_elos[team_two] -= change\n",
    "        \n",
    "            # store elo score for game id at the table\n",
    "            # df.at[i, 'ELO_ONE'] = elo_one\n",
    "            # df.at[i, 'ELO_TWO'] = elo_two\n",
    "            # df.loc[(df['GAME_ID'] == game_id) & df['TEAM_ID_ONE'] == team_two, 'ELO_ONE'] = elo_two\n",
    "            # df.loc[(df['GAME_ID'] == game_id) & df['TEAM_ID_TWO'] == team_one, 'ELO_TWO'] = elo_one\n",
    "\n",
    "            # store elo scores in dictionary\n",
    "            elo_map[(game_id, team_one, team_two)] = elo_one\n",
    "            elo_map[(game_id, team_two, team_one)] = elo_two\n",
    "     \n",
    "        else:\n",
    "            team, team_opp = row['TEAM_ID'], row['TEAM_ID_OPPONENT']\n",
    "            points_team, points_opp = row['PTS'], row['PTS_OPPONENT']\n",
    "            home = row['HOME']\n",
    "        \n",
    "            # Season adjustment formula for ELO : New Season ELO = 0.75 * Last Season ELO + 0.25 * Mean ELO, Mean ELO = 1505\n",
    "            for t in [team, team_opp]:\n",
    "                # check if team has not appeared yet in the dataset\n",
    "                if t not in team_elos:\n",
    "                    team_elos[t] = 1505 \n",
    "                    team_last_season[t] = season\n",
    "                # check for new season, if yes, apply season adjustment\n",
    "                elif team_last_season[t] != season:\n",
    "                    team_elos[t] = 0.75 * team_elos[t] + 0.25 * 1505\n",
    "                    team_last_season[t] = season\n",
    "        \n",
    "            # elo scores before game\n",
    "            elo_team = team_elos[team]\n",
    "            elo_opponent = team_elos[team_opp]\n",
    "        \n",
    "            # Add 100 score to home team\n",
    "            if home == 1:\n",
    "                elo_team_home = elo_team + 100 \n",
    "                elo_opp_home = elo_opponent\n",
    "            else:\n",
    "                elo_team_home = elo_team \n",
    "                elo_opp_home = elo_opponent + 100\n",
    "        \n",
    "            # Expected score of game formula : exp = 1/ (1+10^((ELO two after home advantage - ELO one after home advantage) / 400))\n",
    "            exp = 1/ (1+10**((elo_opp_home - elo_team_home) / 400))\n",
    "        \n",
    "            actual = 1 if points_team > points_opp else 0\n",
    "            margin_of_victory = abs(points_team - points_opp)\n",
    "        \n",
    "            # Margin of Victory Multiplier formula : ((MOV + 3) ** 0.8) / (7.5 + 0.006 * (Elo team one - Elo team two))\n",
    "            MOVM = ((margin_of_victory + 3) ** 0.8) / (7.5 + 0.006 * (elo_team - elo_opponent))\n",
    "        \n",
    "            # change in ELO: K * MOVM * (actual - exp), k -> attenuation factor -> higher means elo score adjusts quickly to changes in strength of team\n",
    "            K = 20 # 20 is optimal for nba \n",
    "            change = K * MOVM * (actual - exp)\n",
    "\n",
    "            # Update data for ELO ratings\n",
    "            team_elos[team] += change\n",
    "            team_elos[team_opp] -= change\n",
    "        \n",
    "            # store elo score for both row of game at the table\n",
    "            # df.at[i, 'ELO'] = elo_team\n",
    "            # df.loc[(df['GAME_ID'] == game_id) & df['TEAM_ID'] == team_opp, 'ELO'] = elo_opponent\n",
    "            elo_map[(game_id, team)] = elo_team\n",
    "            elo_map[(game_id, team_opp)] = elo_opponent\n",
    "\n",
    "    # add data from elo dictionary into dataframe\n",
    "    if not combined:\n",
    "        df['ELO'] = df.apply(lambda x: elo_map.get((x['GAME_ID'], x['TEAM_ID']), np.nan), axis=1)\n",
    "        df.drop(columns=['PTS_OPPONENT', 'TEAM_ID_OPPONENT'], axis=1, inplace=True)\n",
    "    else: \n",
    "        df['ELO_ONE'] = df.apply(lambda x: elo_map.get((x['GAME_ID'], x['TEAM_ID_ONE'], x['TEAM_ID_TWO']), np.nan), axis=1)\n",
    "        df['ELO_TWO'] = df.apply(lambda x: elo_map.get((x['GAME_ID'], x['TEAM_ID_TWO'], x['TEAM_ID_ONE']), np.nan), axis=1)\n",
    "    df.drop(columns=['GAME_ID'], axis=1, inplace=True)\n",
    "    \n",
    "            \n",
    "    return df                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fb3d3a-5e21-45d6-944d-9541ede2dc50",
   "metadata": {},
   "source": [
    "### Effective Field Goal Percentage and True Shooting Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f454283-ac34-4bd0-a798-1d962bdd4c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shooting_percentages(df, combined=False):\n",
    "    if combined: \n",
    "        df['EFG%_ONE'] = (df['FGM_ONE'] + 1.5 * df['FG3M_ONE']) / df['FGA_ONE']\n",
    "        df['EFG%_TWO'] = (df['FGM_TWO'] + 1.5 * df['FG3M_TWO']) / df['FGA_TWO']\n",
    "        df['TS%_ONE'] = df['PTS_ONE'] / (2 * (df['FGA_ONE'] + 0.44 * df['FTA_ONE']))\n",
    "        df['TS%_TWO'] = df['PTS_TWO'] / (2 * (df['FGA_TWO'] + 0.44 * df['FTA_TWO']))\n",
    "    else:\n",
    "        df['EFG%'] = (df['FGM'] + 1.5 * df['FG3M']) / df['FGA']\n",
    "        df['TS%'] = df['PTS'] / (2 * (df['FGA'] + 0.44 * df['FTA']))\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad3bc4-2711-42c5-b37c-4774ff7e55a4",
   "metadata": {},
   "source": [
    "### Win for Last Matchup Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59d519cd-3e8b-497f-9308-8ea3620877ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_win_last_game(df, combined=False):\n",
    "    if combined:\n",
    "        # Save original order\n",
    "        df['__original_order'] = range(len(df))\n",
    "\n",
    "        # Sort for correct shifting\n",
    "        sorted_df = df.sort_values(by=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'])\n",
    "        # Compute WIN_LAST\n",
    "        sorted_df['WIN_LAST_ONE'] = sorted_df.groupby(['TEAM_ID_ONE', 'TEAM_ID_TWO'])['WIN_ONE'].shift(1)\n",
    "        sorted_df['WIN_LAST_TWO'] = 1 - sorted_df['WIN_LAST_ONE'] \n",
    "        \n",
    "        # Restore original order and keep WIN_LAST\n",
    "        df = sorted_df.sort_values('__original_order').drop(columns='__original_order')\n",
    "        \n",
    "    else:\n",
    "        # Save original order\n",
    "        df['__original_order'] = range(len(df))\n",
    "\n",
    "        # Sort for correct shifting\n",
    "        sorted_df = df.sort_values(by=['TEAM_ID', 'OPPONENT', 'GAME_DATE'])\n",
    "\n",
    "        # Compute WIN_LAST\n",
    "        sorted_df['WIN_LAST'] = sorted_df.groupby(['TEAM_ID', 'OPPONENT'])['WIN'].shift(1)\n",
    "\n",
    "        # Restore original order and keep WIN_LAST\n",
    "        df = sorted_df.sort_values('__original_order').drop(columns='__original_order')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4316bb7d-80cb-45d6-a738-5fd9907a1c5e",
   "metadata": {},
   "source": [
    "## Predict Game Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f910ff7c-7433-48ca-90d6-3fd755ed304e",
   "metadata": {},
   "source": [
    "### Get Validation Set\n",
    "We will take some subset of the games to check how well our predicted statistics represent the actual statistics.Since the last five seasons are our test set, we will not look at games in that window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4d0d863-5970-46f0-a639-b4092043b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_set (first_season, last_season, n = 1) :\n",
    "    dates = []\n",
    "    for season in range(first_season, last_season) :\n",
    "        season_data = all_stats_cleaned[all_stats_cleaned['SEASON_YEAR'] == season]\n",
    "        start_date = season_data['GAME_DATE'].min()\n",
    "        end_date = season_data['GAME_DATE'].max()\n",
    "\n",
    "        # day around the beginning of the season\n",
    "        beg = season_data[season_data['GAME_DATE'].between(start_date, start_date + timedelta(weeks = 4))]\n",
    "\n",
    "        # day around trade deadline (after about 2/3 of the season)\n",
    "        delta = round((2/3)*(end_date-start_date).days)\n",
    "        approx_deadline = start_date + timedelta(days = delta)\n",
    "        mid = season_data[season_data['GAME_DATE'].between(approx_deadline, approx_deadline + timedelta(weeks = 4))]\n",
    "        \n",
    "        # day around the end of the season\n",
    "        end = season_data[season_data['GAME_DATE'].between(end_date - timedelta(weeks = 4), end_date)]\n",
    "\n",
    "        dates.extend(list(pd.concat([beg.sample(n)['GAME_DATE'], mid.sample(n)['GAME_DATE'], end.sample(n)['GAME_DATE']])))\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b33c4c6d-0b27-4526-bd8b-a578bbefdb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_season = all_stats_cleaned['SEASON_YEAR'].min() + 1\n",
    "last_season = all_stats_cleaned['SEASON_YEAR'].max() - 5\n",
    "val_set = get_val_set(first_season, last_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8074433b-c6bb-48e8-b879-51917d30c000",
   "metadata": {},
   "source": [
    "We attempt two different methods for predicting game statistics. As a baseline, we use a regular rolling window. Then, we implement a model which predicts a team's statistics. We use both of these values to test an outcome predictor model after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82184664-d5f3-4181-9c14-e5ea485847a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added shooting percentage\n",
    "all_stats_cleaned = add_shooting_percentages(all_stats_cleaned)\n",
    "# added win streak and win percentage\n",
    "all_stats_cleaned = add_win_streak_and_percentage(all_stats_cleaned)\n",
    "# added ELO score\n",
    "all_stats_cleaned = add_elo_score(all_stats_cleaned)\n",
    "# added win for last game\n",
    "all_stats_cleaned = add_win_last_game(all_stats_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acc3bc3c-6b06-4677-8ef6-8989b046c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(df, n, cols) :\n",
    "    pred = None\n",
    "    for team_id in df['TEAM_ID'].unique() :\n",
    "        team_data = df[df['TEAM_ID'] == team_id].sort_values(by='GAME_DATE')\n",
    "        for col in cols :\n",
    "            shift = team_data[col].shift(1)\n",
    "            team_data[col] = shift.rolling(window = n).mean()\n",
    "        if pred is None :\n",
    "            pred = team_data\n",
    "        else :\n",
    "            pred = pd.concat([pred, team_data], ignore_index = True)\n",
    "    pred = pred.dropna(axis = 0)\n",
    "\n",
    "    home = pred[pred['HOME'] == 1]\n",
    "    away = pred[pred['HOME'] == 0]\n",
    "\n",
    "    combined_pred_stats_home = pd.merge(home, away, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "    combined_pred_stats_away = pd.merge(away, home, \n",
    "                          left_on=['GAME_DATE', 'OPPONENT'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ABBREVIATION'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "\n",
    "    combined_pred_stats = pd.concat([combined_pred_stats_home, combined_pred_stats_away], ignore_index = True)\n",
    "    combined_pred_stats.rename(columns={'MIN_ONE': 'MIN', 'SEASON_YEAR_TWO': 'SEASON_YEAR'}, inplace=True)\n",
    "    combined_pred_stats = combined_pred_stats.drop(columns = ['MIN_TWO', 'OPPONENT_ONE', 'OPPONENT_TWO', 'SEASON_YEAR_ONE', \n",
    "                                                              'TEAM_ABBREVIATION_ONE', 'TEAM_NAME_ONE', 'MIN', 'FGM_ONE', \n",
    "                                                              'FGA_ONE', 'FG3M_ONE', 'FG3A_ONE', 'FTM_ONE', 'FTA_ONE', 'PTS_ONE', \n",
    "                                                              'PLUS_MINUS_ONE', 'TEAM_ABBREVIATION_TWO', 'TEAM_NAME_TWO', 'HOME_TWO',\n",
    "                                                              'WIN_TWO', 'FGM_TWO', 'FGA_TWO', 'FG3M_TWO', 'FG3A_TWO', 'FTM_TWO', \n",
    "                                                              'FTA_TWO', 'PTS_TWO', 'PLUS_MINUS_TWO'])\n",
    "\n",
    "    return combined_pred_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93202b91-284d-4a12-97c2-5ac0471a1b0e",
   "metadata": {},
   "source": [
    "### Rolling Window Statistics (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24c4b049-ef2b-4e20-b329-18e9dc3571ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM_ID_ONE</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>HOME_ONE</th>\n",
       "      <th>WIN_ONE</th>\n",
       "      <th>FG_PCT_ONE</th>\n",
       "      <th>FG3_PCT_ONE</th>\n",
       "      <th>FT_PCT_ONE</th>\n",
       "      <th>OREB_ONE</th>\n",
       "      <th>DREB_ONE</th>\n",
       "      <th>REB_ONE</th>\n",
       "      <th>...</th>\n",
       "      <th>BLK_TWO</th>\n",
       "      <th>TOV_TWO</th>\n",
       "      <th>PF_TWO</th>\n",
       "      <th>SEASON_YEAR</th>\n",
       "      <th>EFG%_TWO</th>\n",
       "      <th>TS%_TWO</th>\n",
       "      <th>WIN_STREAK_TWO</th>\n",
       "      <th>WIN_PERCENTAGE_TWO</th>\n",
       "      <th>ELO_TWO</th>\n",
       "      <th>WIN_LAST_TWO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>1985-11-06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4818</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.7716</td>\n",
       "      <td>18.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>51.6</td>\n",
       "      <td>...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.467987</td>\n",
       "      <td>0.526725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1502.871568</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>1985-11-12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4934</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.7922</td>\n",
       "      <td>14.6</td>\n",
       "      <td>29.4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.472332</td>\n",
       "      <td>0.496543</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1479.166935</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1985-11-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.8744</td>\n",
       "      <td>13.6</td>\n",
       "      <td>30.8</td>\n",
       "      <td>44.4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.2</td>\n",
       "      <td>18.4</td>\n",
       "      <td>31.6</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.562264</td>\n",
       "      <td>0.586669</td>\n",
       "      <td>2</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>1633.196494</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1985-12-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4938</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>13.4</td>\n",
       "      <td>29.4</td>\n",
       "      <td>42.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>16.6</td>\n",
       "      <td>20.4</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.505386</td>\n",
       "      <td>0.548772</td>\n",
       "      <td>3</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>1524.715303</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>1985-12-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4752</td>\n",
       "      <td>0.2334</td>\n",
       "      <td>0.8146</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>43.8</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>25.4</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.514892</td>\n",
       "      <td>0.548520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1470.994115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEAM_ID_ONE  GAME_DATE  HOME_ONE  WIN_ONE  FG_PCT_ONE  FG3_PCT_ONE  \\\n",
       "0           28 1985-11-06         1        1      0.4818       0.1334   \n",
       "1           28 1985-11-12         1        1      0.4934       0.2000   \n",
       "2           28 1985-11-29         1        1      0.5110       0.1000   \n",
       "3           28 1985-12-03         1        0      0.4938       0.1334   \n",
       "4           28 1985-12-05         1        1      0.4752       0.2334   \n",
       "\n",
       "   FT_PCT_ONE  OREB_ONE  DREB_ONE  REB_ONE  ...  BLK_TWO  TOV_TWO  PF_TWO  \\\n",
       "0      0.7716      18.6      33.0     51.6  ...      7.2     18.0    30.2   \n",
       "1      0.7922      14.6      29.4     44.0  ...      5.0     19.4    20.8   \n",
       "2      0.8744      13.6      30.8     44.4  ...      6.2     18.4    31.6   \n",
       "3      0.8700      13.4      29.4     42.8  ...      4.6     16.6    20.4   \n",
       "4      0.8146      13.0      30.8     43.8  ...      5.0     21.4    25.4   \n",
       "\n",
       "   SEASON_YEAR  EFG%_TWO   TS%_TWO  WIN_STREAK_TWO  WIN_PERCENTAGE_TWO  \\\n",
       "0         1985  0.467987  0.526725               0            0.600000   \n",
       "1         1985  0.472332  0.496543               0            0.285714   \n",
       "2         1985  0.562264  0.586669               2            0.736842   \n",
       "3         1985  0.505386  0.548772               3            0.529412   \n",
       "4         1985  0.514892  0.548520               0            0.500000   \n",
       "\n",
       "       ELO_TWO  WIN_LAST_TWO  \n",
       "0  1502.871568           1.0  \n",
       "1  1479.166935           0.0  \n",
       "2  1633.196494           1.0  \n",
       "3  1524.715303           0.0  \n",
       "4  1470.994115           0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['FG_PCT', 'FG3_PCT', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'EFG%', 'TS%']\n",
    "df_rolling = rolling_window(all_stats_cleaned, 5, cols)\n",
    "df_rolling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a602a6-3a1a-4be0-8694-2ab73032ff98",
   "metadata": {},
   "source": [
    "### Predicting Using ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3c44a63-da4e-453c-aac5-1777d8716254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get actual stats\n",
    "combined_stats_training = add_shooting_percentages(combined_stats, combined = True)\n",
    "combined_stats_training = combined_stats[['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE', 'FG_PCT_ONE',\n",
    "                                          'FG3_PCT_ONE','FT_PCT_ONE', 'OREB_ONE', 'DREB_ONE', 'REB_ONE',\n",
    "                                          'AST_ONE', 'STL_ONE', 'BLK_ONE', 'TOV_ONE', 'PF_ONE', 'EFG%_ONE', 'TS%_ONE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25fdac0f-da9f-4927-8577-7ce09b07a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rolling window stats\n",
    "cols = ['FG_PCT', 'FG3_PCT', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'EFG%', 'TS%']\n",
    "rolling_stats_training = rolling_window(all_stats_cleaned, 5, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9749a1a9-2625-449c-a014-4c9fcbfd7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine \n",
    "model_training_set = pd.merge(rolling_stats_training, combined_stats_training, \n",
    "                          left_on=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'], \n",
    "                          right_on=['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'],\n",
    "                          suffixes=('_PRED', '_ACT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30a08d71-712f-4857-8ba5-ba00b94a1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_cols = ['FG_PCT_ONE_ACT', 'FG3_PCT_ONE_ACT', 'FT_PCT_ONE_ACT', 'OREB_ONE_ACT', 'DREB_ONE_ACT', \n",
    "                'REB_ONE_ACT','AST_ONE_ACT', 'STL_ONE_ACT', 'BLK_ONE_ACT', 'TOV_ONE_ACT', \n",
    "                'PF_ONE_ACT', 'EFG%_ONE_ACT', 'TS%_ONE_ACT'] \n",
    "\n",
    "\n",
    "def train_model(df, team_id, game_date, model_params = None):\n",
    "    \"\"\"\n",
    "    Trains a model to predict team stats for a given game using past rolling averages of both teams.\n",
    "    Features: past performance of TEAM_ONE and TEAM_TWO.\n",
    "    Targets: actual stats of TEAM_ONE in the current game.\n",
    "    \"\"\"\n",
    "    # determine season of the game\n",
    "    season = game_date.year if game_date.month >= 10 else game_date.year - 1\n",
    "    \n",
    "    # get games for training\n",
    "    df_past = df[df['SEASON_YEAR'].between(season - 5, season)].copy() # only look at the last 5 seasons\n",
    "    df_past = df[(df['GAME_DATE'] < game_date) & (df['TEAM_ID_ONE'] == team_id)]\n",
    "    X = df_past.drop(columns = act_cols+['GAME_DATE'])\n",
    "    # fitting a XGBoost model for each stat\n",
    "    models = {}\n",
    "    for col in act_cols:\n",
    "        y = df_past[col]\n",
    "        if model_params is None :\n",
    "            model = XGBRegressor(n_estimators = 100, random_state = 33)\n",
    "        else :\n",
    "            model = XGBRegressor(**model_params[col], random_state = 33)\n",
    "        model.fit(X, y)\n",
    "        models[col] = model\n",
    "\n",
    "    return models\n",
    "\n",
    "def predict_game_stats(df, team_id, game_date, model_params = None) :\n",
    "    \"\"\"\n",
    "    Predicts the statistics for given game.\n",
    "    \"\"\"\n",
    "    df = df.drop(columns = 'WIN_ONE')\n",
    "    df = pd.get_dummies(df, columns=['TEAM_ID_TWO'], drop_first=True)\n",
    "    if model_params is None :\n",
    "        models = train_model(df, team_id, game_date)\n",
    "    else :\n",
    "        models = train_model(df, team_id, game_date, model_params)\n",
    "\n",
    "    pred = df[(df['GAME_DATE'] == game_date) & (df['TEAM_ID_ONE'] == team_id)].drop(columns = act_cols+['GAME_DATE'])\n",
    "\n",
    "    \n",
    "    prediction = {}\n",
    "    for stat, model in models.items():\n",
    "        prediction[stat] = model.predict(pred)[0]\n",
    "    return prediction\n",
    "\n",
    "def evaluate_stats_model(df, test_set, model_params = None):\n",
    "    \"\"\"\n",
    "    Evaluates predicting stats model by testing on last `test_seasons` seasons using RMSE.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    for day in test_set :\n",
    "        print(\"Predicting...\", day)\n",
    "        games_on_day = df[df['GAME_DATE'] == day]\n",
    "        for index, row in games_on_day.iterrows() :\n",
    "            if model_params is None :\n",
    "                pred = predict_game_stats(df, row['TEAM_ID_ONE'], day)\n",
    "            else :\n",
    "                pred = predict_game_stats(df, row['TEAM_ID_ONE'], day, model_params)\n",
    "            pred = [pred[col] for col in act_cols]\n",
    "            act = [row[col] for col in act_cols]\n",
    "            predictions.append(pred)\n",
    "            actuals.append(act)\n",
    "\n",
    "    # evaluating model's predictions\n",
    "    y_true = np.array(actuals)\n",
    "    y_pred = np.array(predictions)\n",
    "\n",
    "    # rmse\n",
    "    total_rmse = np.sqrt(mean_squared_error(y_true.flatten(), y_pred.flatten()))\n",
    "    # r-squared\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return total_rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2db519cf-f9f6-4426-87c1-bbcc231b33cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting... 1986-10-31 00:00:00\n",
      "Predicting... 1987-02-23 00:00:00\n",
      "Predicting... 1987-04-18 00:00:00\n",
      "Predicting... 1987-11-12 00:00:00\n",
      "Predicting... 1988-03-26 00:00:00\n",
      "Predicting... 1988-04-01 00:00:00\n",
      "Predicting... 1988-12-02 00:00:00\n",
      "Predicting... 1989-02-25 00:00:00\n",
      "Predicting... 1989-04-06 00:00:00\n",
      "Predicting... 1989-11-08 00:00:00\n",
      "Predicting... 1990-03-05 00:00:00\n",
      "Predicting... 1990-04-01 00:00:00\n",
      "Predicting... 1990-11-10 00:00:00\n",
      "Predicting... 1991-03-02 00:00:00\n",
      "Predicting... 1991-04-08 00:00:00\n",
      "Predicting... 1991-11-29 00:00:00\n",
      "Predicting... 1992-03-13 00:00:00\n",
      "Predicting... 1992-04-16 00:00:00\n",
      "Predicting... 1992-11-25 00:00:00\n",
      "Predicting... 1993-03-20 00:00:00\n",
      "Predicting... 1993-04-17 00:00:00\n",
      "Predicting... 1993-11-19 00:00:00\n",
      "Predicting... 1994-03-02 00:00:00\n",
      "Predicting... 1994-04-10 00:00:00\n",
      "Predicting... 1994-11-12 00:00:00\n",
      "Predicting... 1995-02-28 00:00:00\n",
      "Predicting... 1995-04-17 00:00:00\n",
      "Predicting... 1995-11-25 00:00:00\n",
      "Predicting... 1996-02-25 00:00:00\n",
      "Predicting... 1996-03-26 00:00:00\n",
      "Predicting... 1996-11-29 00:00:00\n",
      "Predicting... 1997-03-20 00:00:00\n",
      "Predicting... 1997-04-18 00:00:00\n",
      "Predicting... 1997-11-12 00:00:00\n",
      "Predicting... 1998-03-06 00:00:00\n",
      "Predicting... 1998-04-14 00:00:00\n",
      "Predicting... 1999-02-19 00:00:00\n",
      "Predicting... 1999-04-22 00:00:00\n",
      "Predicting... 1999-04-26 00:00:00\n",
      "Predicting... 1999-11-19 00:00:00\n",
      "Predicting... 2000-03-21 00:00:00\n",
      "Predicting... 2000-04-13 00:00:00\n",
      "Predicting... 2000-11-03 00:00:00\n",
      "Predicting... 2001-03-02 00:00:00\n",
      "Predicting... 2001-03-27 00:00:00\n",
      "Predicting... 2001-11-08 00:00:00\n",
      "Predicting... 2002-02-26 00:00:00\n",
      "Predicting... 2002-04-06 00:00:00\n",
      "Predicting... 2002-11-01 00:00:00\n",
      "Predicting... 2003-03-04 00:00:00\n",
      "Predicting... 2003-04-11 00:00:00\n",
      "Predicting... 2003-10-31 00:00:00\n",
      "Predicting... 2004-02-22 00:00:00\n",
      "Predicting... 2004-04-09 00:00:00\n",
      "Predicting... 2004-11-16 00:00:00\n",
      "Predicting... 2005-03-14 00:00:00\n",
      "Predicting... 2005-03-25 00:00:00\n",
      "Predicting... 2005-11-20 00:00:00\n",
      "Predicting... 2006-03-05 00:00:00\n",
      "Predicting... 2006-04-14 00:00:00\n",
      "Predicting... 2006-11-12 00:00:00\n",
      "Predicting... 2007-03-02 00:00:00\n",
      "Predicting... 2007-04-18 00:00:00\n",
      "Predicting... 2007-11-21 00:00:00\n",
      "Predicting... 2008-02-29 00:00:00\n",
      "Predicting... 2008-04-13 00:00:00\n",
      "Predicting... 2008-11-07 00:00:00\n",
      "Predicting... 2009-03-15 00:00:00\n",
      "Predicting... 2009-04-08 00:00:00\n",
      "Predicting... 2009-11-07 00:00:00\n",
      "Predicting... 2010-03-03 00:00:00\n",
      "Predicting... 2010-04-14 00:00:00\n",
      "Predicting... 2010-11-11 00:00:00\n",
      "Predicting... 2011-03-07 00:00:00\n",
      "Predicting... 2011-04-11 00:00:00\n",
      "Predicting... 2012-01-16 00:00:00\n",
      "Predicting... 2012-03-28 00:00:00\n",
      "Predicting... 2012-04-13 00:00:00\n",
      "Predicting... 2012-11-09 00:00:00\n",
      "Predicting... 2013-03-18 00:00:00\n",
      "Predicting... 2013-04-15 00:00:00\n",
      "Predicting... 2013-11-24 00:00:00\n",
      "Predicting... 2014-02-19 00:00:00\n",
      "Predicting... 2014-03-21 00:00:00\n",
      "Predicting... 2014-11-21 00:00:00\n",
      "Predicting... 2015-02-27 00:00:00\n",
      "Predicting... 2015-04-05 00:00:00\n",
      "Predicting... 2015-11-21 00:00:00\n",
      "Predicting... 2016-03-15 00:00:00\n",
      "Predicting... 2016-03-30 00:00:00\n",
      "Predicting... 2016-10-25 00:00:00\n",
      "Predicting... 2017-03-08 00:00:00\n",
      "Predicting... 2017-04-04 00:00:00\n",
      "Predicting... 2017-10-30 00:00:00\n",
      "Predicting... 2018-02-26 00:00:00\n",
      "Predicting... 2018-03-31 00:00:00\n",
      "Predicting... 2018-11-04 00:00:00\n",
      "Predicting... 2019-03-08 00:00:00\n",
      "Predicting... 2019-03-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "rmse, r2 = evaluate_stats_model(model_training_set, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2dd23ac7-5f73-4288-a2e6-a488cd1b619c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.7844883108033978\n",
      "R-Squared: -0.07352584366635623\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-Squared: {r2}\")\n",
    "\n",
    "#RMSE: 3.7844883108033978\n",
    "#R-Squared: -0.07352584366635623"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa5875-6c70-4131-9248-05a75e190956",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "To perform hyperparameter tuning, we are going to look at only a small subset of the validation set since each game to be predicted requires fitting a number of different models. For computational efficiency, we are going to make the validation subset include only dates from 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f21d8b0-3991-4dc1-9330-4cd9a9d5854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test_set = [d for d in val_set if d.year == 2018]\n",
    "param_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f28b7-9596-4c07-9ebb-ae245785469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning (df, params, test_set) :\n",
    "    index = 1\n",
    "    param_perf = None\n",
    "    for p in params :\n",
    "        print(f\"Iteration {index} / {len(params)}\")\n",
    "        predictions = None \n",
    "        actual = None\n",
    "        for day in test_set :\n",
    "            games_on_day = df[df['GAME_DATE'] == day]\n",
    "            for _, row in games_on_day.iterrows() :\n",
    "                model_params = {col : p for col in act_cols}\n",
    "                pred = pd.DataFrame([predict_game_stats(df, row['TEAM_ID_ONE'], day, model_params)])\n",
    "                act = pd.DataFrame([{col : row[col] for col in act_cols}])\n",
    "                predictions = pred if predictions is None else pd.concat([predictions, pred], ignore_index = True)\n",
    "                actual = act if predictions is None else pd.concat([actual, act], ignore_index = True)\n",
    "\n",
    "        scores = {'params': p}\n",
    "        for col in act_cols :\n",
    "            scores[col] = np.sqrt(mean_squared_error(predictions[col], actual[col]))\n",
    "        scores = pd.DataFrame([scores])\n",
    "        param_perf = scores if param_perf is None else pd.concat([param_perf, scores], ignore_index = True)\n",
    "        index += 1\n",
    "\n",
    "    best_params = {}\n",
    "    for col in act_cols :\n",
    "        best_params[col] = param_perf.loc[param_perf[col].idxmin(), 'params']\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e96dcb-1b4b-44dc-9c48-5adc6021461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 150],\n",
    "    \"eta\": [0.01, 0.05, 0.1], # learning_rate\n",
    "    \"max_depth\": [4, 6, 8], # maximum depth of a tree\n",
    "    \"subsample\": [0.5, 0.7, 1], # fraction of observation to be radnomly sampled for each tree\n",
    "    \"colsample_bytree\": [0.5, 0.7, 1], # fraction of columns to be random samples for each tree\n",
    "    }\n",
    "\n",
    "params = []\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for values in itertools.product(*param_grid.values()):\n",
    "    params.append(dict(zip(param_grid.keys(), values)))\n",
    "\n",
    "best_params = hyperparameter_tuning(model_training_set, params, param_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ea6ed-c405-4129-bbc5-8595e6d28bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in best_params.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b855c851-1412-4ad7-a186-3da581301b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to avoid rerunning\n",
    "best_params = {\n",
    "    'FG_PCT_ONE_ACT': {'n_estimators': 50, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.7, 'colsample_bytree': 0.5},\n",
    "    'FG3_PCT_ONE_ACT': {'n_estimators': 50, 'eta': 0.1, 'max_depth': 6, 'subsample': 0.7, 'colsample_bytree': 1},\n",
    "    'FT_PCT_ONE_ACT': {'n_estimators': 100, 'eta': 0.1, 'max_depth': 4, 'subsample': 0.5, 'colsample_bytree': 0.5},\n",
    "    'OREB_ONE_ACT': {'n_estimators': 50, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.5},\n",
    "    'DREB_ONE_ACT': {'n_estimators': 100, 'eta': 0.1, 'max_depth': 4, 'subsample': 0.5, 'colsample_bytree': 1},\n",
    "    'REB_ONE_ACT': {'n_estimators': 150, 'eta': 0.05, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.7},\n",
    "    'AST_ONE_ACT': {'n_estimators': 100, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.5},\n",
    "    'STL_ONE_ACT': {'n_estimators': 100, 'eta': 0.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.5},\n",
    "    'BLK_ONE_ACT': {'n_estimators': 150, 'eta': 0.1, 'max_depth': 6, 'subsample': 0.7, 'colsample_bytree': 1},\n",
    "    'TOV_ONE_ACT': {'n_estimators': 100, 'eta': 0.1, 'max_depth': 6, 'subsample': 0.7, 'colsample_bytree': 1},\n",
    "    'PF_ONE_ACT': {'n_estimators': 150, 'eta': 0.05, 'max_depth': 4, 'subsample': 0.7, 'colsample_bytree': 1},\n",
    "    'EFG%_ONE_ACT': {'n_estimators': 50, 'eta': 0.05, 'max_depth': 8, 'subsample': 0.7, 'colsample_bytree': 1},\n",
    "    'TS%_ONE_ACT': {'n_estimators': 100, 'eta': 0.1, 'max_depth': 6, 'subsample': 1, 'colsample_bytree': 0.5}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe558f71-6af2-4df5-a566-aac1d5d0a87e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_training_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rmse_tuned, r2_tuned = evaluate_stats_model(\u001b[43mmodel_training_set\u001b[49m, val_set, best_params)\n",
      "\u001b[31mNameError\u001b[39m: name 'model_training_set' is not defined"
     ]
    }
   ],
   "source": [
    "rmse_tuned, r2_tuned = evaluate_stats_model(model_training_set, val_set, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c80429-9cf9-4c1a-be2a-3bfc013aa8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE: {rmse_tuned}\")\n",
    "print(f\"R-Squared: {r2_tuned}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d24aaf-bec1-46e4-9d19-69ee01492175",
   "metadata": {},
   "source": [
    "### Predict Training Set for Outcome Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92006d8d-db7e-4fbc-b06d-27776366dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_cols = ['TEAM_ID_ONE', 'SEASON_YEAR', 'HOME_ONE', 'WIN_ONE', 'ELO_ONE', 'WIN_STREAK_ONE', 'WIN_PERCENTAGE_ONE', 'WIN_LAST_ONE']\n",
    "def pred_training_set (df, first_season, last_season, model_params) :\n",
    "    days = all_stats_cleaned[all_stats_cleaned['SEASON_YEAR'].between(first_season, last_season)]['GAME_DATE'].unique()\n",
    "    rows = []\n",
    "    current_day = 1\n",
    "    total_days = len(days)\n",
    "    for d in days:\n",
    "        print(f\"Predicting Day {current_day} / {total_days} \")\n",
    "        games_on_day = df[df['GAME_DATE'] == d]\n",
    "        for _, row in games_on_day.iterrows() :\n",
    "            pred = predict_game_stats(df, row['TEAM_ID_ONE'], d, model_params)\n",
    "            pred['GAME_DATE'] = d\n",
    "            pred['OPP'] = row['TEAM_ID_TWO']\n",
    "            for s in static_cols :\n",
    "                pred[s] = row[s]\n",
    "            rows.append(pred)\n",
    "        current_day += 1\n",
    "            \n",
    "    all_predictions = pd.DataFrame(rows)\n",
    "    all_predictions.rename(columns=lambda col: col.replace('_ONE', ''), inplace=True)\n",
    "    all_predictions.rename(columns=lambda col: col.replace('_ACT', ''), inplace=True)\n",
    "\n",
    "    home = all_predictions[all_predictions.HOME == 1]\n",
    "    away = all_predictions[all_predictions.HOME == 0]\n",
    "\n",
    "    combined_pred_home = pd.merge(home, away, \n",
    "                          left_on=['GAME_DATE', 'OPP'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ID'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "    combined_pred_away = pd.merge(away, home, \n",
    "                          left_on=['GAME_DATE', 'OPP'], \n",
    "                          right_on=['GAME_DATE', 'TEAM_ID'],\n",
    "                          suffixes=('_ONE', '_TWO'))\n",
    "\n",
    "    combined_pred = pd.concat([combined_pred_home, combined_pred_away], ignore_index = True)\n",
    "    combined_pred = combined_pred.drop(columns = ['OPP_ONE', 'OPP_TWO', 'HOME_TWO', 'WIN_TWO', 'SEASON_YEAR_TWO'])\n",
    "    combined_pred.rename(columns = {'SEASON_YEAR_ONE': 'SEASON_YEAR'}, inplace=True)\n",
    "    combined_pred=combined_pred[rolling_stats_training.columns] # orient the columns nicely\n",
    "\n",
    "    return combined_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59615f7b-57bf-4df0-a4b9-e82f629a3764",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_horizon = 5\n",
    "first_test_season = all_stats_cleaned['SEASON_YEAR'].max() - 5\n",
    "last_test_season = all_stats_cleaned['SEASON_YEAR'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db91f76a-5024-4362-8bd8-937ad278f420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_model = pred_training_set(model_training_set, first_test_season - time_horizon, last_test_season, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b6b64-fd92-4dde-b210-fbd9f13a93f9",
   "metadata": {},
   "source": [
    "### Compare Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b905c97a-db56-4d71-859e-c108594e4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats = add_shooting_percentages(combined_stats, combined = True)\n",
    "model_pred = df_model.sort_values(by = ['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'])\n",
    "rolling_pred = df_rolling[df_rolling['SEASON_YEAR'].between(2014, 2024)].sort_values(by = ['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'])\n",
    "act = combined_stats[combined_stats['SEASON_YEAR'].between(2014, 2024)].sort_values(by = ['TEAM_ID_ONE', 'TEAM_ID_TWO', 'GAME_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a33cabf7-a0fe-4501-9d91-88718518d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['FG_PCT_ONE', 'FG3_PCT_ONE', 'FT_PCT_ONE', 'OREB_ONE', 'DREB_ONE', 'REB_ONE', 'AST_ONE', 'STL_ONE', 'BLK_ONE', 'TOV_ONE', 'PF_ONE', 'EFG%_ONE', 'TS%_ONE', \n",
    "        'FG_PCT_TWO', 'FG3_PCT_TWO', 'FT_PCT_TWO', 'OREB_TWO', 'DREB_TWO', 'REB_TWO', 'AST_TWO', 'STL_TWO', 'BLK_TWO', 'TOV_TWO', 'PF_TWO', 'EFG%_TWO', 'TS%_TWO']\n",
    "model_pred = model_pred[cols].to_numpy().flatten()\n",
    "rolling_pred = rolling_pred[cols].to_numpy().flatten()\n",
    "act = act[cols].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8a89463-5342-4999-8bda-4c0b9e0f54b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling Predictions: RMSE = 3.6547, R^2 = 0.9331\n",
      "Model Predictions: RMSE = 3.5135, R^2 = 0.9381\n"
     ]
    }
   ],
   "source": [
    "rmse_rolling = np.sqrt(mean_squared_error(act, rolling_pred))\n",
    "r2_rolling = r2_score(act, rolling_pred)\n",
    "\n",
    "rmse_model = np.sqrt(mean_squared_error(act, model_pred))\n",
    "r2_model = r2_score(act, model_pred)\n",
    "\n",
    "print(f\"Rolling Predictions: RMSE = {rmse_rolling:.4f}, R^2 = {r2_rolling:.4f}\")\n",
    "print(f\"Model Predictions: RMSE = {rmse_model:.4f}, R^2 = {r2_model:.4f}\")\n",
    "\n",
    "#Rolling Predictions: RMSE = 3.6547, R^2 = 0.9331\n",
    "#Model Predictions: RMSE = 3.5135, R^2 = 0.9381"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97757c7e-775e-40fc-8450-44bfb0fde395",
   "metadata": {},
   "source": [
    "## Export Training Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f595b2-cbc1-40ae-ae55-9061bf0e1770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.to_csv('df_model_tuned.csv', index = False)\n",
    "df_rolling.to_csv('df_rolling.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83ac9b6-3018-4ad6-bed2-2f876320de98",
   "metadata": {},
   "source": [
    "## Predict Playoff Statistics\n",
    "For each playoff game, need to calculate the rolling statistics, input them into the outcome model, assume these values to be true and add them to our dataset. Then, we repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "abc72bac-846d-45c9-abbc-912772a5225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_values = all_stats_cleaned[['TEAM_ID', 'GAME_DATE', 'HOME', 'OPPONENT', 'WIN', 'FG_PCT', 'FG3_PCT',\n",
    "                                'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'SEASON_YEAR', \n",
    "                                'EFG%', 'TS%', 'WIN_STREAK', 'WIN_PERCENTAGE', 'ELO', 'WIN_LAST']]\n",
    "act_values.loc[:, 'OPPONENT'] = act_values['OPPONENT'].map(team_abb_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8a0dd07c-3baf-42b5-b910-70a26349b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_values (df, team_id, opponent, game_date, home, n=5) :\n",
    "    cols = ['FG_PCT', 'FG3_PCT','FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'EFG%', 'TS%']\n",
    "    season = game_date.year if game_date.month >= 10 else game_date.year - 1\n",
    "\n",
    "    input_values = {\n",
    "        'TEAM_ID': team_id,\n",
    "        'OPPONENT': opponent,\n",
    "        'GAME_DATE': game_date,\n",
    "        'HOME': home,\n",
    "        'SEASON_YEAR': season\n",
    "    }\n",
    "    \n",
    "    team_data = df[df['TEAM_ID'] == team_id].sort_values(by='GAME_DATE')\n",
    "    rolling_stats = team_data.tail(n)\n",
    "    for col in cols :\n",
    "            input_values[col] = rolling_stats[col].mean()\n",
    "\n",
    "    return pd.DataFrame(input_values, index = [0])\n",
    "\n",
    "def pred_playoff_game(df_act, team_one, team_two, game_date, home_one) :\n",
    "    team_one_stats = get_input_values(df_act, team_one, team_two, game_date, home_one)\n",
    "    team_two_stats = get_input_values(df_act, team_two, team_one, game_date, int(not home_one))\n",
    "\n",
    "    team_one_stats.loc[:,'ELO'] = df_act[df_act['TEAM_ID'] == team_one].sort_values(by = 'GAME_DATE').iloc[-1]['ELO']\n",
    "    team_two_stats.loc[:,'ELO'] = df_act[df_act['TEAM_ID'] == team_two].sort_values(by = 'GAME_DATE').iloc[-1]['ELO']\n",
    "    \n",
    "    df_act_upd = pd.concat([df_act, team_one_stats, team_two_stats], ignore_index = True)\n",
    "    # added win streak and win percentage\n",
    "    df_act_upd = add_win_streak_and_percentage(df_act_upd)\n",
    "    # added win for last game\n",
    "    df_act_upd = add_win_last_game(df_act_upd)\n",
    "\n",
    "    team_one_stats = df_act_upd.iloc[[-2]]\n",
    "    team_two_stats = df_act_upd.iloc[[-1]]\n",
    "\n",
    "    pred_stats = pd.merge(team_one_stats, team_two_stats, \n",
    "                          left_on = ['GAME_DATE'],\n",
    "                          right_on = ['GAME_DATE'],\n",
    "                          suffixes = ('_ONE', '_TWO')).drop(columns = ['OPPONENT_ONE', 'OPPONENT_TWO', 'WIN_TWO', 'HOME_TWO', 'SEASON_YEAR_TWO'])\n",
    "    pred_stats.rename(columns = {'SEASON_YEAR_ONE': 'SEASON_YEAR'}, inplace=True)\n",
    "    return pred_stats, pd.concat([team_one_stats, team_two_stats], ignore_index = True)\n",
    "\n",
    "def playoff_predictions(df_act, games) :\n",
    "    all_predictions = None\n",
    "    act_rows = None\n",
    "    for _, row in games.iterrows() :\n",
    "        pred, act = pred_playoff_game(df_act, row['TEAM_ONE'], row['TEAM_TWO'], row['GAME_DATE'], row['HOME_ONE'])\n",
    "        all_predictions = pred if all_predictions is None else pd.concat([all_predictions, pred], ignore_index = True)\n",
    "        act_rows = act if act_rows is None else pd.concat([act_rows, act], ignore_index = True)\n",
    "    return all_predictions, act_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438b8689-c4cc-4bfe-85a3-526aeeae0210",
   "metadata": {},
   "source": [
    "### Round 1 : Conference Quarterfinals\n",
    "In Round 1, we have the following games\n",
    "\n",
    "Eastern\n",
    "1. Cleveland (C, 2) vs. Miami (H, 11): 4/20 C, 4/23 C, 4/26 H, 4/28 H, 4/30 C, 5/2 H, 5/4 C\n",
    "2. Boston (C, 1) vs. Orlando (M, 16): 4/20 C, 4/23 C, 4/25 M, 4/27 M, 4/29 C, 5/1 M, 5/3 C\n",
    "3. New York (K, 15) vs. Detroit (P, 28): 4/19 K, 4/21 K, 4/24 P, 4/27 P, 4/29 K, 5/1 P, 5/3 K\n",
    "4. Indiana (P, 17) vs. Milwaukee (B, 12): 4/19 P, 4/22 P, 4/25 B, 4/27 B, 4/29 P, 5/2 B, 5/4 P\n",
    "\n",
    "Western\n",
    "1. Oklahoma City (T, 23) vs. Memphis (G, 26): 4/20 T, 4/22 T, 4/24 G, 4/26 G, 4/28 T, 5/1 G, 5/3 T\n",
    "2. Houston (R, 8) vs Golden State (W, 7): 4/20 R, 4/23 R, 4/26 W, 4/28 W, 4/30 R, 5/2 W, 5/4 R\n",
    "3. LA Lakers (L, 10) vs. Minnesota (T, 13): 4/19 L, 4/22 L, 4/25 T, 4/27 T, 4/30 L, 5/2 T, 5/4 L\n",
    "4. Denver (N, 6) vs. LA Clippers (C, 9): 4/19 N, 4/21 N, 4/24 C, 4/26 C, 4/29 N, 5/1 C, 5/3 N\n",
    "\n",
    "To simulate the playoffs properly, we will predict the statistics and outcome for the first game of each series. Then, append this value and predict the statistics and outcome for the next. We keep going until every matchup has a winner. But, first we need to figure out the id numbers for the teams playing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ba2a0-1043-43e5-9b48-9f59c0f7c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats_cleaned[['TEAM_ID', 'TEAM_NAME']].sort_values(by = 'TEAM_ID').drop_duplicates(subset=['TEAM_ID'], keep = 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000355b-4e66-4d23-869d-850b78e230d5",
   "metadata": {},
   "source": [
    "#### Game 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cb9be449-7933-4d47-8dcd-cbfbc2cd5a42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[2, 11, pd.Timestamp('2025-04-20'), 1], \n",
    "         [1, 16, pd.Timestamp('2025-04-20'), 1], \n",
    "         [15, 28, pd.Timestamp('2025-04-19'), 1], \n",
    "         [17, 12, pd.Timestamp('2025-04-19'), 1], \n",
    "         [23, 26, pd.Timestamp('2025-04-20'), 1], \n",
    "         [8, 7, pd.Timestamp('2025-04-20'), 1], \n",
    "         [10, 13, pd.Timestamp('2025-04-19'), 1],\n",
    "         [6, 9, pd.Timestamp('2025-04-19'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_one_one.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce79a2b1-da3b-4e9c-978b-f91b4a8a00c9",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Cleveland vs. Miami : 1-0\n",
    "2. Boston vs Orlando : 1-0\n",
    "3. New York vs Detroit: 1-0\n",
    "4. Indiana vs. Milwaukee 0-1\n",
    "5. Oklahoma City vs. Memphis : 1-0\n",
    "6. Houston vs. Golden State : 1-0\n",
    "7. LA Lakers vs. Minnesota : 0-1\n",
    "8. Denver vs. LA Clippers : 1-0\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "002c3670-d0ae-4107-af56-04569e54d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [2, 1, 23, 8, 15, 12, 13, 6]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e125d94-a761-4a89-ae93-35c9240775f2",
   "metadata": {},
   "source": [
    "#### Game 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "be0d55ae-e2bc-4e09-a68a-98cce4c9d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[2, 11, pd.Timestamp('2025-04-23'), 1], \n",
    "         [1, 16, pd.Timestamp('2025-04-23'), 1], \n",
    "         [15, 28, pd.Timestamp('2025-04-21'), 1], \n",
    "         [17, 12, pd.Timestamp('2025-04-22'), 1], \n",
    "         [23, 26, pd.Timestamp('2025-04-22'), 1], \n",
    "         [8, 7, pd.Timestamp('2025-04-23'), 1], \n",
    "         [10, 13, pd.Timestamp('2025-04-22'), 1],\n",
    "         [6, 9, pd.Timestamp('2025-04-21'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_one_two.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aba62b-591d-4db1-98d4-5c98fd8a778a",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Cleveland vs. Miami : 1-1\n",
    "2. Boston vs Orlando : 2-0\n",
    "3. New York vs Detroit: 1-1\n",
    "4. Indiana vs. Milwaukee 0-2\n",
    "5. Oklahoma City vs. Memphis : 2-0\n",
    "6. Houston vs. Golden State : 2-0\n",
    "7. LA Lakers vs. Minnesota : 0-2\n",
    "8. Denver vs. LA Clippers : 2-0\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1147cac8-828a-4dfa-bbe6-46c33fca3625",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [11, 1, 8, 28, 6, 12, 23, 13]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017de646-49e4-4a39-99d0-b17fa0f38940",
   "metadata": {},
   "source": [
    "#### Game 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b69a5b3a-21ec-41b4-8bd5-0bbe9bbb4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[2, 11, pd.Timestamp('2025-04-26'), 0], \n",
    "         [1, 16, pd.Timestamp('2025-04-25'), 0], \n",
    "         [15, 28, pd.Timestamp('2025-04-24'), 0], \n",
    "         [17, 12, pd.Timestamp('2025-04-25'), 0], \n",
    "         [23, 26, pd.Timestamp('2025-04-24'), 0], \n",
    "         [8, 7, pd.Timestamp('2025-04-26'), 0], \n",
    "         [10, 13, pd.Timestamp('2025-04-25'), 0],\n",
    "         [6, 9, pd.Timestamp('2025-04-24'), 0]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_one_three.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679680df-39ef-4fbd-a3ed-98f214e8b748",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Cleveland vs. Miami : 1-2\n",
    "2. Boston vs Orlando : 2-1\n",
    "3. New York vs Detroit: 1-2\n",
    "4. Indiana vs. Milwaukee 0-3\n",
    "5. Oklahoma City vs. Memphis : 3-0\n",
    "6. Houston vs. Golden State : 2-1\n",
    "7. LA Lakers vs. Minnesota : 0-3\n",
    "8. Denver vs. LA Clippers : 2-1\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "972d329a-eb79-440b-8c03-d2783c6f45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [11, 7, 16, 12, 13, 28, 23, 9]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652047c7-ce54-420f-96ae-8be719ba2736",
   "metadata": {},
   "source": [
    "#### Game 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bae67c81-42cc-4911-8257-89a9d1996e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[2, 11, pd.Timestamp('2025-04-28'), 0], \n",
    "         [1, 16, pd.Timestamp('2025-04-27'), 0], \n",
    "         [15, 28, pd.Timestamp('2025-04-27'), 0], \n",
    "         [17, 12, pd.Timestamp('2025-04-27'), 0], \n",
    "         [23, 26, pd.Timestamp('2025-04-26'), 0], \n",
    "         [8, 7, pd.Timestamp('2025-04-28'), 0], \n",
    "         [10, 13, pd.Timestamp('2025-04-27'), 0],\n",
    "         [6, 9, pd.Timestamp('2025-04-26'), 0]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_one_four.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46abe2-a575-4868-9b2d-410fc223dc34",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Cleveland vs. Miami : 1-3\n",
    "2. Boston vs Orlando : 2-2\n",
    "3. New York vs Detroit: 1-3\n",
    "4. Indiana vs. Milwaukee 0-4 COMPLETE\n",
    "5. Oklahoma City vs. Memphis : 4-0 COMPLETE\n",
    "6. Houston vs. Golden State : 2-2\n",
    "7. LA Lakers vs. Minnesota : 0-4 COMPLETE\n",
    "8. Denver vs. LA Clippers : 2-2\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "de165d16-5eb4-4d6f-acf3-d3bc4e013150",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [16, 28, 12, 13, 11, 7, 23, 9]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca5b40-0928-4771-9bec-a356a2891bc3",
   "metadata": {},
   "source": [
    "#### Game 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "200a0971-f360-4ac7-8d9b-0a70f97f37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[2, 11, pd.Timestamp('2025-04-30'), 1], \n",
    "                      [1, 16, pd.Timestamp('2025-04-29'), 1], \n",
    "                      [15, 28, pd.Timestamp('2025-04-29'), 1],\n",
    "                      [8, 7, pd.Timestamp('2025-04-30'), 1],\n",
    "                      [6, 9, pd.Timestamp('2025-04-29'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_one_five.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21561c-f4d8-449d-b258-b2b876cf6cc8",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Cleveland vs. Miami : 1-4 COMPLETE\n",
    "2. Boston vs Orlando : 2-3\n",
    "3. New York vs Detroit: 1-4 COMPLETE\n",
    "4. Indiana vs. Milwaukee 0-4 COMPLETE\n",
    "5. Oklahoma City vs. Memphis : 4-0 COMPLETE\n",
    "6. Houston vs. Golden State : 2-3\n",
    "7. LA Lakers vs. Minnesota : 0-4 COMPLETE\n",
    "8. Denver vs. LA Clippers : 2-3\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "82eb4e23-63cb-4fe8-a5a0-42e0137cf28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [11, 7, 16, 15, 6]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4587ae91-e130-40e9-b20d-df10b1d7c5ef",
   "metadata": {},
   "source": [
    "#### Game 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3fc2cce0-caee-4e29-be69-5a087b1c1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[1, 16, pd.Timestamp('2025-05-01'), 0], \n",
    "                      [8, 7, pd.Timestamp('2025-05-02'), 0],\n",
    "                      [6, 9, pd.Timestamp('2025-05-01'), 0]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_one_six.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db443ec1-e758-4cb3-abdf-e607d5d3921e",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Cleveland vs. Miami : 1-4 COMPLETE\n",
    "2. Boston vs Orlando : 2-4 COMPLETE\n",
    "3. New York vs Detroit: 1-4 COMPLETE\n",
    "4. Indiana vs. Milwaukee 0-4 COMPLETE\n",
    "5. Oklahoma City vs. Memphis : 4-0 COMPLETE\n",
    "6. Houston vs. Golden State : 2-4 COMPLETE\n",
    "7. LA Lakers vs. Minnesota : 0-4 COMPLETE\n",
    "8. Denver vs. LA Clippers : 2-4 COMPLETE\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0972e579-49c8-4637-b9bf-7f0e567b5e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [16, 9, 7]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12591a7d-c85b-46d7-9a1f-9d4852b05ba9",
   "metadata": {},
   "source": [
    "#### Game 7 (no games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248cff3-824e-47a3-82fa-e6daa74dbb31",
   "metadata": {},
   "source": [
    "### Round 2 : Conference Semifinals\n",
    "From these results, we get the following conference semifinal matchups. \n",
    "1. Oklahoma City (23) vs. LA Clippers (9) : OKC home first\n",
    "2. Minnesota (13) vs. Golden State (7) : Minnesota home first\n",
    "3. Milwaukee (12) vs. Miami (11) : Milwaukee home first\n",
    "4. Detroit (28) vs. Orlando (16) : Detroit home first\n",
    "\n",
    "Games begin May 5-6 so we will just have each game be two days apart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03183a-0082-43c0-b8f7-30569bfc9d2d",
   "metadata": {},
   "source": [
    "#### Game 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "91ef0a3b-8213-40a8-b73a-63f8ee8da01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[23, 9, pd.Timestamp('2025-05-05'), 1], \n",
    "         [13, 7, pd.Timestamp('2025-05-05'), 1], \n",
    "         [12, 11, pd.Timestamp('2025-05-05'), 1],\n",
    "         [28, 16, pd.Timestamp('2025-05-05'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_two_one.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f2a9d-e8a8-466c-8ecd-c35041649890",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. LA Clippers (9) : 1-0\n",
    "2. Minnesota (13) vs. Golden State (7) : 1-0\n",
    "3. Milwaukee (12) vs. Miami (11) : 0-1\n",
    "4. Detroit (28) vs. Orlando (16) : 1-0\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a0dd64a2-a0ab-441a-98cf-8976aeac9cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [23, 13, 11, 28]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563dbf2f-5fdf-4dad-aca4-448087b04e4d",
   "metadata": {},
   "source": [
    "#### Game 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "395cdf28-3f65-45a0-932c-1f239a328ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[23, 9, pd.Timestamp('2025-05-07'), 1], \n",
    "         [13, 7, pd.Timestamp('2025-05-07'), 1], \n",
    "         [12, 11, pd.Timestamp('2025-05-07'), 1],\n",
    "         [28, 16, pd.Timestamp('2025-05-07'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_two_two.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef85d67c-06d1-4427-96c4-9138acc8c3bc",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. LA Clippers (9) : 2-0\n",
    "2. Minnesota (13) vs. Golden State (7) : 2-0\n",
    "3. Milwaukee (12) vs. Miami (11) : 1-1\n",
    "4. Detroit (28) vs. Orlando (16) : 2-0\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f0cc40db-7f62-4982-9762-5e756c9df7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [23, 13, 12, 28]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b22024-5e39-42f8-809f-a83cfaeed9eb",
   "metadata": {},
   "source": [
    "#### Game 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6cc4b346-805f-4eaf-8f2e-a7d82907506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[23, 9, pd.Timestamp('2025-05-09'), 0], \n",
    "         [13, 7, pd.Timestamp('2025-05-09'), 0], \n",
    "         [12, 11, pd.Timestamp('2025-05-09'), 0],\n",
    "         [28, 16, pd.Timestamp('2025-05-09'), 0]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_two_three.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98223f-eaf1-4e9c-b6a3-c15cb46ccc25",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. LA Clippers (9) : 2-1\n",
    "2. Minnesota (13) vs. Golden State (7) : 2-1\n",
    "3. Milwaukee (12) vs. Miami (11) : 1-2\n",
    "4. Detroit (28) vs. Orlando (16) : 2-1\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c534d351-5962-4587-ab35-9fcb638b9f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [9, 7, 11, 16]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9529be-ec4a-44c3-80bd-623186dfc19e",
   "metadata": {},
   "source": [
    "#### Game 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bbf7a32d-5e1d-4d5e-be49-c3e666292537",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[23, 9, pd.Timestamp('2025-05-11'), 0], \n",
    "         [13, 7, pd.Timestamp('2025-05-11'), 0], \n",
    "         [12, 11, pd.Timestamp('2025-05-11'), 0],\n",
    "         [28, 16, pd.Timestamp('2025-05-11'), 0]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_two_four.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2848f0-96ca-4b5a-82ea-2352e1da8c7b",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. LA Clippers (9) : 2-2\n",
    "2. Minnesota (13) vs. Golden State (7) : 3-1\n",
    "3. Milwaukee (12) vs. Miami (11) : 1-3\n",
    "4. Detroit (28) vs. Orlando (16) : 2-2\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "89706dfe-dd20-487d-8357-b4fcff7e420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [9, 13, 11, 16]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14039eec-72ac-4c3a-842b-210988a35712",
   "metadata": {},
   "source": [
    "#### Game 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "642294d3-a0b6-4a34-8ddd-89177685a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[23, 9, pd.Timestamp('2025-05-13'), 1], \n",
    "         [13, 7, pd.Timestamp('2025-05-13'), 1], \n",
    "         [12, 11, pd.Timestamp('2025-05-13'), 1],\n",
    "         [28, 16, pd.Timestamp('2025-05-13'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_two_five.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7f147-d31b-4865-b133-f6e5a0ed736f",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. LA Clippers (9) : 3-2\n",
    "2. Minnesota (13) vs. Golden State (7) : 4-1 COMPLETE\n",
    "3. Milwaukee (12) vs. Miami (11) : 1-4 COMPLETE\n",
    "4. Detroit (28) vs. Orlando (16) : 3-2\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6fe2c79f-8c7b-4354-9806-16d18f5a47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [23, 13, 11, 28]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd2750-5d11-47d2-b241-8a9527396f32",
   "metadata": {},
   "source": [
    "#### Game 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "35bad830-e70e-4515-800f-c9f66f0d6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[23, 9, pd.Timestamp('2025-05-15'), 0], \n",
    "         [28, 16, pd.Timestamp('2025-05-15'), 0]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_two_six.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44af0c91-8871-4092-a0da-d757958d3eb3",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. LA Clippers (9) : 3-3\n",
    "2. Minnesota (13) vs. Golden State (7) : 4-1 COMPLETE\n",
    "3. Milwaukee (12) vs. Miami (11) : 1-4 COMPLETE\n",
    "4. Detroit (28) vs. Orlando (16) : 3-3\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c6a267eb-7553-4315-81aa-0e30f842d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [9, 16]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2ab800-3381-419f-8eed-2443b5a8f8f5",
   "metadata": {},
   "source": [
    "#### Game 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "49f18891-49a7-42c8-bb84-d8a78d56c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[23, 9, pd.Timestamp('2025-05-17'), 1], \n",
    "         [28, 16, pd.Timestamp('2025-05-17'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_two_seven.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a64f6-049d-4b42-b605-c091d242c579",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. LA Clippers (9) : 4-3 COMPLETE\n",
    "2. Minnesota (13) vs. Golden State (7) : 4-1 COMPLETE\n",
    "3. Milwaukee (12) vs. Miami (11) : 1-4 COMPLETE\n",
    "4. Detroit (28) vs. Orlando (16) : 3-4 COMPLETE\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c3307007-04fb-472a-832d-4ef8694ea939",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [23, 16]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd655f-066e-4347-b64d-f4a7bcee7abe",
   "metadata": {},
   "source": [
    "### Round 3 : Conference Finals\n",
    "From these results, we get the following conference final matchups. \n",
    "1. Oklahoma City (23) vs. Minnesota (13) : Oklahoma City home first\n",
    "2. Miami (11) vs. Orlando (16) : Miami home first\n",
    "\n",
    "Games begin May 20-21 with the following schedule: \n",
    "\n",
    "Western: 5/20, 5/22, 5/24, 5/26, 5/28, 5/30, 6/1\n",
    "\n",
    "Eastern: 5/21, 5/23, 5/25, 5/27, 5/29, 5/31, 6/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a30dab-4133-4ca3-ba4f-039351fbcfc0",
   "metadata": {},
   "source": [
    "#### Game 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f86ce559-1213-4360-8bf4-697dc3295a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[23, 13, pd.Timestamp('2025-05-20'), 1], \n",
    "         [11, 16, pd.Timestamp('2025-05-21'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_three_one.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7ae8f-1f5e-46a8-ab99-b50f5dd1f362",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. Minnesota (13) : 0-1\n",
    "2. Miami (11) vs. Orlando (16) : 1-0\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "827d1c51-c725-40f9-974c-d4435876dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [13, 11]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46158a12-5c10-4bc0-8fa9-b3cc5e523acd",
   "metadata": {},
   "source": [
    "#### Game 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "08abb237-6fe2-4419-abe8-8c0b048854c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[23, 13, pd.Timestamp('2025-05-22'), 1], \n",
    "         [11, 16, pd.Timestamp('2025-05-23'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_three_two.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65363558-0cd4-4235-83d4-f8a70f83d713",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. Minnesota (13) : 0-2\n",
    "2. Miami (11) vs. Orlando (16) : 2-0\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "22087c0e-5629-40bf-960b-987a653d416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [13, 11]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d08e4c-27b4-4dda-80f7-5d2d9c9c73f8",
   "metadata": {},
   "source": [
    "#### Game 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0fab3bb8-bb82-4edb-8324-32c9094f78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[23, 13, pd.Timestamp('2025-05-24'), 0], \n",
    "         [11, 16, pd.Timestamp('2025-05-25'), 0]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_three_three.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b3a2c-8327-4c75-8140-a569189252f5",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. Minnesota (13) : 0-3\n",
    "2. Miami (11) vs. Orlando (16) : 2-1\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "960902db-fdc3-46d2-ab03-c29fd5089fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [13, 16]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a9cac-29ca-4f25-a1e2-6e57c89ea952",
   "metadata": {},
   "source": [
    "#### Game 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5896497b-bc21-4156-9508-971b97e9f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[23, 13, pd.Timestamp('2025-05-26'), 0], \n",
    "         [11, 16, pd.Timestamp('2025-05-27'), 0]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_three_four.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d679bca7-8efd-43a4-b0e9-4261812f7880",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. Minnesota (13) : 0-4 COMPLETE\n",
    "2. Miami (11) vs. Orlando (16) : 2-2\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "27c10f0b-7834-4913-aeb9-6b241d81b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [13, 16]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d664f13-e62e-40e1-a908-baf31ce31f58",
   "metadata": {},
   "source": [
    "#### Game 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ac9935a4-1b41-4e0f-875d-fe0f24a7bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[11, 16, pd.Timestamp('2025-05-29'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_three_five.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca85e909-47c3-42fa-a315-277821ebc128",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. Minnesota (13) : 0-4 COMPLETE\n",
    "2. Miami (11) vs. Orlando (16) : 3-2\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6371c688-9387-4330-bc37-8147423b51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [11]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94472911-a97f-4756-a88d-1a5386a6d20b",
   "metadata": {},
   "source": [
    "#### Game 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "df7a29b5-0d5a-44d2-83ef-30169cfc7ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[11, 16, pd.Timestamp('2025-05-31'), 0]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_three_six.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ac18d-ef98-4af9-abbd-80fa8d1e33da",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Oklahoma City (23) vs. Minnesota (13) : 0-4 COMPLETE\n",
    "2. Miami (11) vs. Orlando (16) : 4-2 COMPLETE\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0b7b9248-5c2b-459f-aa63-a4cef648a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [11]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12b4159-240d-47a0-bf46-18de4be1aaa4",
   "metadata": {},
   "source": [
    "#### Game 7 (no games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883caf1e-d5cf-4ee1-a8b9-d5fd0973cb43",
   "metadata": {},
   "source": [
    "### Round 4 : Finals\n",
    "From these results, we get the following final matchups. \n",
    "1. Minnesota (13) vs. Miami (11) : Minnesota home first\n",
    "\n",
    "Games begin June 5 and have the following schedule : 6/5, 6/8, 6/11, 6/13, 6/16, 6/19, 6/22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab7e3f5-c654-42b2-959a-38dd19b649d1",
   "metadata": {},
   "source": [
    "#### Game 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2716722d-ffad-4eaa-9b62-5df1590b95d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[13, 11, pd.Timestamp('2025-06-05'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_four_one.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53976967-7626-4a3c-b6c6-c7378add9b6f",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Minnesota (13) vs. Miami (11) : 1-0\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1bb7594b-fed6-42e3-b43d-2ec601817635",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [13]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d3a8a7-77e5-40d1-bb40-75c9499f7655",
   "metadata": {},
   "source": [
    "#### Game 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e5597799-5909-4386-a388-63eefd535123",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[13, 11, pd.Timestamp('2025-06-08'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_four_two.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2948d0-b21b-42dc-8532-5b0b87f7e67a",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Minnesota (13) vs. Miami (11) : 2-0\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c69df657-c1e9-4c3d-9cdd-36a756f977bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [13]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b25f979-badd-46ab-98a7-4726d02e38cc",
   "metadata": {},
   "source": [
    "#### Game 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ea71e55c-32f5-4554-b9f2-7c9a1a4a04fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[13, 11, pd.Timestamp('2025-06-11'), 0]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_four_three.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b797ee-cfac-46d7-affe-1f4716c2c4ed",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Minnesota (13) vs. Miami (11) : 2-1\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a398a19d-b734-440c-a7c9-bda0ebad2675",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [11]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b46df-87ea-4723-8203-48e5b58694b9",
   "metadata": {},
   "source": [
    "#### Game 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4ef325a1-4b0c-4cb6-9fc9-156c78bcdbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[13, 11, pd.Timestamp('2025-06-13'), 0]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_four_four.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bcb458-fee0-42e7-84b2-1939711d251a",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Minnesota (13) vs. Miami (11) : 2-2\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1b8bcbb8-25c4-4cb1-8579-38bee2dcd079",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [11]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404dbbc5-e2b2-4478-b6c0-ddd6eaa4211e",
   "metadata": {},
   "source": [
    "#### Game 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5ed089bf-b5ad-4709-ad2c-98e3ba830e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[13, 11, pd.Timestamp('2025-06-16'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_four_five.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fb9f9a-873c-40d0-9107-9cfc59345d10",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Minnesota (13) vs. Miami (11) : 3-2\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ae188788-995f-4d09-b1a6-34b86ac2b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [13]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75ad2d5-6889-4800-8202-ffbef7a664dd",
   "metadata": {},
   "source": [
    "#### Game 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "050861d4-d1dd-4459-be47-204b14ceb329",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[13, 11, pd.Timestamp('2025-06-19'), 0]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_four_six.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31670ccf-60e9-459c-9722-d0f313d27ff7",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Minnesota (13) vs. Miami (11) : 3-3\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e0a975f7-2bf5-4781-82a0-c80c6dffe1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [11]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ce0a50-8586-4321-9ff4-9df6a3b66c50",
   "metadata": {},
   "source": [
    "#### Game 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "689d0755-ecdb-4b30-910e-0f842f730fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame([[13, 11, pd.Timestamp('2025-06-22'), 1]], columns = ['TEAM_ONE', 'TEAM_TWO', 'GAME_DATE', 'HOME_ONE'])\n",
    "preds, act_rows = playoff_predictions(act_values, games)\n",
    "preds.to_csv('playoffs_round_four_seven.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7725256-d850-4390-9de6-2b92ed7f921e",
   "metadata": {},
   "source": [
    "Running these predictions, we found the model predicted the following outcomes:\n",
    "1. Minnesota (13) vs. Miami (11) : 4-3\n",
    "\n",
    "We then assume the predicted values to be true and add them to our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a8506a4a-4223-4d62-a9a1-276760a545c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = [13]\n",
    "act_rows['WIN'] = [1 if team in winners else 0 for team in act_rows['TEAM_ID']]\n",
    "act_values = pd.concat([act_values, act_rows], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16dec64-4a86-4e3d-afed-1459c3499d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
